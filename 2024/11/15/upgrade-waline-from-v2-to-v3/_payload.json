[{"data":1,"prerenderedAt":357},["ShallowReactive",2],{"post-2024-11-15-upgrade-waline-from-v2-to-v3":3,"surround-2024-11-15-upgrade-waline-from-v2-to-v3":345,"randomIndex/2024/11/15/upgrade-waline-from-v2-to-v3/":356},{"id":4,"title":5,"body":6,"date":332,"description":30,"extension":333,"meta":334,"navigation":224,"path":335,"rawbody":336,"seo":337,"stem":338,"sticky":339,"tags":340,"__hash__":344},"posts/posts/upgrade-waline-from-v2-to-v3.md","将博客从 waline v2 更新到 waline v3",{"type":7,"value":8,"toc":328},"minimark",[9,16,24,47,52,55,61,67,78,94,102,105,111,115,118,123,132,137,140,143,148,151,154,159,162,165,181,184,191,198,205,208,307,314,319,324],[10,11,12],"blockquote",{},[13,14,15],"p",{},"waline 更新到 V3 版本已经是九个月前的事情了，眼瞅着 hexo fluid 主题并没有带我更新的意思，我就打算自己更新到最新版，结果遇到了两个坑，写文供大家参考。",[13,17,18,19,23],{},"在 Hexo 目录下的 ",[20,21,22],"code",{},"_config.fluid.yml"," 文件中找到 waline 的 cdn，将版本号指向最新版。",[25,26,31],"pre",{"className":27,"code":28,"language":29,"meta":30,"style":30},"language-diff shiki shiki-themes one-light one-dark-pro","-  waline: https://registry.npmmirror.com/@waline/client/2.15.8/files/dist/\n+  waline: https://registry.npmmirror.com/@waline/client/^3/files/dist/\n","diff","",[20,32,33,41],{"__ignoreMap":30},[34,35,38],"span",{"class":36,"line":37},"line",1,[34,39,40],{},"-  waline: https://registry.npmmirror.com/@waline/client/2.15.8/files/dist/\n",[34,42,44],{"class":36,"line":43},2,[34,45,46],{},"+  waline: https://registry.npmmirror.com/@waline/client/^3/files/dist/\n",[48,49,51],"h2",{"id":50},"插曲一waline-不加载","插曲一——waline 不加载",[13,53,54],{},"再次部署博客，我遇到了第一个坑：waline 没有在页面上正常加载。",[13,56,57,58],{},"打开控制台一看，报错给得很明白：",[20,59,60],{},"Waline is not defined",[13,62,63],{},[64,65],"img",{"alt":30,"src":66},"https://static.031130.xyz/uploads/2024/11/16/663e910db29b7.webp",[13,68,69,70,77],{},"根据 ",[71,72,76],"a",{"href":73,"rel":74},"https://github.com/walinejs/waline/issues/2483",[75],"nofollow","issue#2483","，",[10,79,80,87],{},[13,81,82,86],{},[71,83,84],{"href":84,"rel":85},"https://unpkg.com/@waline/client@3.1.3/dist/waline.umd.js",[75]," 用这个地址",[13,88,89,90,93],{},"本质是 ...... 没有使用 ES Module 的加载方式 ",[20,91,92],{},"\u003Cscript type=\"module\">","，所以需要使用 UMD 的模块",[13,95,96,97],{},"那么按照正常的脑回路，我们应该修改主题中的引入 waline 部分的 js 文件，把针对 waline.js 的引用改成 waline.umd.js，具体的修改处",[71,98,101],{"href":99,"rel":100},"https://github.com/fluid-dev/hexo-theme-fluid/blob/94049b2e6da5ae865f5cf7088f0c53917a6dc8bc/layout/_partials/comments/waline.ejs#L5-L6",[75],"在这里",[13,103,104],{},"但是，我是使用 npm 安装的主题，方便在主题更新时直接同步上游的更改，如果使用这种修改源文件引用的方式将会导致我不得不放弃原有的主题安装方式，改用下载主题源码的方式。",[13,106,107,108,110],{},"那么有没有办法，既能够成功加载带 umd 的 js，又不用改动主题源码呢？还真有，我自己部署 cdn 就好了。从 npmjs 下载带 umd 的 waline.umd.js，重命名成 waline.js，和 waline.css 一起放在同一路径下，在把自己的 cdn 链接前缀填入 ",[20,109,22],{}," 中，就可以实现移花接木——表面上访问的是 waline.js，实际上内容是 waline.umd.js 。",[48,112,114],{"id":113},"插曲二重复显示的","插曲二——重复显示的 @",[13,116,117],{},"更新到 v3 版本以后，我发现所有的评论都出现了重复两遍的 @",[13,119,120],{},[64,121],{"alt":30,"src":122},"https://static.031130.xyz/uploads/2024/11/16/f6fbaa99a784e.webp",[13,124,125,126,131],{},"我去群里提问，管理员 ",[71,127,130],{"href":128,"rel":129},"https://imnerd.org/",[75],"li zheming"," 给出了这样的答复:",[10,133,134],{},[13,135,136],{},"这个是 feature 了，早版本 @ 是渲染在评论内容里的，这块后来重构了下，@ 是 Waline 自己渲染了。不过历史数据我们并没有处理，所以会出现这种情况。如果比较介意的话可以手动去数据库里删除下。",[13,138,139],{},"那么很显然，我很介意这点，我需要删除数据库中的 @ 信息。",[13,141,142],{},"打开 waline 的后台管理站点，我发现我有整整 30 页的评论——很显然我是 waline 的牢用户了，我不太可能一个一个手动去掉评论中的 @",[13,144,145],{},[64,146],{"alt":30,"src":147},"https://static.031130.xyz/uploads/2024/11/16/c4487502542e5.webp",[13,149,150],{},"我的 waline 数据库是 leancloud，对方的 webui 没办法帮助我批量去除 html 或者 markdown 形式的内容（就算对方支持 sql 语句，处理这个问题都够呛），我需要一个脚本来直接处理数据库中的信息。",[13,152,153],{},"首先，我们需要导出数据库数据，自然是登陆 leancloud，然后找到 数据存储 - 导入导出 - 数据导出，选择 Comment 单个 Class，单击导出按钮。",[13,155,156],{},[64,157],{"alt":30,"src":158},"https://static.031130.xyz/uploads/2024/11/16/d2cd564739120.webp",[13,160,161],{},"err，我寻思凌晨 1 点应该是 16 点前吧，怎么导出不了，而我昨晚 23 点反而可以导出，leancloud 到底是哪门子时区。所以我直接拿了 23 点时导出的数据进行处理。",[13,163,164],{},"leancloud 导出的数据是 jsonl 格式的，我们对需要去除的 @ 信息进行归纳总结，发现一共有两种 @ 的渲染方式",[166,167,168,175],"ul",{},[169,170,171,174],"li",{},[20,172,173],{},"\u003Ca class=\"at\" href=\"#id\">@username\u003C/a>","  的 html 风格（有时 class 和 href 顺序还会反过来）",[169,176,177,180],{},[20,178,179],{},"[@username](#id)"," 的 markdown 风格",[13,182,183],{},"而 html 风格还有两种结尾方式，",[13,185,186,187,190],{},"一种是如 ",[20,188,189],{},"\u003Ca class=\"at\" href=\"#id\">@username\u003C/a> , "," 这样以 空格 + 半角逗号 + 空格 结尾的形式，",[13,192,193,194,197],{},"令一种是如 ",[20,195,196],{},"\u003Ca class=\"at\" href=\"#id\">@username\u003C/a>: "," 这样以 半角冒号 + 空格结尾的形式。",[13,199,200,201,204],{},"markdown 风格的结尾方式我就只看到一种，如 ",[20,202,203],{},"[@username](#id): ","这样以 半角冒号 + 空格结尾的形式。",[13,206,207],{},"因此，我们需要对三种形式分别编写正则表达式进行匹配并删除，参考代码如下",[25,209,213],{"className":210,"code":211,"language":212,"meta":30,"style":30},"language-python shiki shiki-themes one-light one-dark-pro","import re\n\nwith open('Comment.0.jsonl', 'r') as f:\n    s = f.read()\n\npatterns = [\n    r'\u003Ca class=\\\\\"at\\\\\" href=\\\\\"#(?:.*?)\\\\\">@(?:.*?)\u003C/a>: ',\n    r'\u003Ca class=\\\\\"at\\\\\" href=\\\\\"#(?:.*?)\\\\\">@(?:.*?)\u003C/a> , ',\n    r'\\[@(?:.*?)\\]\\(#(?:.*?)\\):'\n]\n\nfor pattern in patterns:\n    s = re.sub(pattern, \"\", s)\n\nwith open('Comment.1.jsonl', 'w') as f:\n    f.write(s)\n","python",[20,214,215,220,226,232,238,243,249,255,261,267,273,278,284,290,295,301],{"__ignoreMap":30},[34,216,217],{"class":36,"line":37},[34,218,219],{},"import re\n",[34,221,222],{"class":36,"line":43},[34,223,225],{"emptyLinePlaceholder":224},true,"\n",[34,227,229],{"class":36,"line":228},3,[34,230,231],{},"with open('Comment.0.jsonl', 'r') as f:\n",[34,233,235],{"class":36,"line":234},4,[34,236,237],{},"    s = f.read()\n",[34,239,241],{"class":36,"line":240},5,[34,242,225],{"emptyLinePlaceholder":224},[34,244,246],{"class":36,"line":245},6,[34,247,248],{},"patterns = [\n",[34,250,252],{"class":36,"line":251},7,[34,253,254],{},"    r'\u003Ca class=\\\\\"at\\\\\" href=\\\\\"#(?:.*?)\\\\\">@(?:.*?)\u003C/a>: ',\n",[34,256,258],{"class":36,"line":257},8,[34,259,260],{},"    r'\u003Ca class=\\\\\"at\\\\\" href=\\\\\"#(?:.*?)\\\\\">@(?:.*?)\u003C/a> , ',\n",[34,262,264],{"class":36,"line":263},9,[34,265,266],{},"    r'\\[@(?:.*?)\\]\\(#(?:.*?)\\):'\n",[34,268,270],{"class":36,"line":269},10,[34,271,272],{},"]\n",[34,274,276],{"class":36,"line":275},11,[34,277,225],{"emptyLinePlaceholder":224},[34,279,281],{"class":36,"line":280},12,[34,282,283],{},"for pattern in patterns:\n",[34,285,287],{"class":36,"line":286},13,[34,288,289],{},"    s = re.sub(pattern, \"\", s)\n",[34,291,293],{"class":36,"line":292},14,[34,294,225],{"emptyLinePlaceholder":224},[34,296,298],{"class":36,"line":297},15,[34,299,300],{},"with open('Comment.1.jsonl', 'w') as f:\n",[34,302,304],{"class":36,"line":303},16,[34,305,306],{},"    f.write(s)\n",[13,308,309,310,313],{},"随后删除 Comment 表中所有数据，把生成的 ",[20,311,312],{},"Comment.1.jsonl"," 导入 leancloud，就算是大功告成了。",[13,315,316],{},[64,317],{"alt":30,"src":318},"https://static.031130.xyz/uploads/2024/11/16/d248ae2eac74c.webp",[13,320,321],{},[64,322],{"alt":30,"src":323},"https://static.031130.xyz/uploads/2024/11/16/c3875dcde1d97.webp",[325,326,327],"style",{},"html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}",{"title":30,"searchDepth":43,"depth":43,"links":329},[330,331],{"id":50,"depth":43,"text":51},{"id":113,"depth":43,"text":114},"2024-11-15 23:49:43","md",{},"/2024/11/15/upgrade-waline-from-v2-to-v3","---\ntitle: 将博客从 waline v2 更新到 waline v3\ndate: 2024-11-15 23:49:43\nsticky:\ntags:\n- Python\n- waline\n- Hexo\n---\n\n> waline 更新到 V3 版本已经是九个月前的事情了，眼瞅着 hexo fluid 主题并没有带我更新的意思，我就打算自己更新到最新版，结果遇到了两个坑，写文供大家参考。\n\n在 Hexo 目录下的 `_config.fluid.yml` 文件中找到 waline 的 cdn，将版本号指向最新版。\n\n```diff\n-  waline: https://registry.npmmirror.com/@waline/client/2.15.8/files/dist/\n+  waline: https://registry.npmmirror.com/@waline/client/^3/files/dist/\n```\n\n## 插曲一——waline 不加载\n\n再次部署博客，我遇到了第一个坑：waline 没有在页面上正常加载。\n\n打开控制台一看，报错给得很明白：`Waline is not defined`\n\n![](https://static.031130.xyz/uploads/2024/11/16/663e910db29b7.webp)\n\n根据 [issue#2483](https://github.com/walinejs/waline/issues/2483)，\n\n> https://unpkg.com/@waline/client@3.1.3/dist/waline.umd.js 用这个地址\n>\n> 本质是 ...... 没有使用 ES Module 的加载方式 `\u003Cscript type=\"module\">`，所以需要使用 UMD 的模块\n\n那么按照正常的脑回路，我们应该修改主题中的引入 waline 部分的 js 文件，把针对 waline.js 的引用改成 waline.umd.js，具体的修改处[在这里](https://github.com/fluid-dev/hexo-theme-fluid/blob/94049b2e6da5ae865f5cf7088f0c53917a6dc8bc/layout/_partials/comments/waline.ejs#L5-L6)\n\n但是，我是使用 npm 安装的主题，方便在主题更新时直接同步上游的更改，如果使用这种修改源文件引用的方式将会导致我不得不放弃原有的主题安装方式，改用下载主题源码的方式。\n\n那么有没有办法，既能够成功加载带 umd 的 js，又不用改动主题源码呢？还真有，我自己部署 cdn 就好了。从 npmjs 下载带 umd 的 waline.umd.js，重命名成 waline.js，和 waline.css 一起放在同一路径下，在把自己的 cdn 链接前缀填入 `_config.fluid.yml` 中，就可以实现移花接木——表面上访问的是 waline.js，实际上内容是 waline.umd.js 。\n\n## 插曲二——重复显示的 @\n\n更新到 v3 版本以后，我发现所有的评论都出现了重复两遍的 @\n\n![](https://static.031130.xyz/uploads/2024/11/16/f6fbaa99a784e.webp)\n\n我去群里提问，管理员 [li zheming](https://imnerd.org/) 给出了这样的答复:\n\n> 这个是 feature 了，早版本 @ 是渲染在评论内容里的，这块后来重构了下，@ 是 Waline 自己渲染了。不过历史数据我们并没有处理，所以会出现这种情况。如果比较介意的话可以手动去数据库里删除下。\n\n那么很显然，我很介意这点，我需要删除数据库中的 @ 信息。\n\n打开 waline 的后台管理站点，我发现我有整整 30 页的评论——很显然我是 waline 的牢用户了，我不太可能一个一个手动去掉评论中的 @\n\n![](https://static.031130.xyz/uploads/2024/11/16/c4487502542e5.webp)\n\n我的 waline 数据库是 leancloud，对方的 webui 没办法帮助我批量去除 html 或者 markdown 形式的内容（就算对方支持 sql 语句，处理这个问题都够呛），我需要一个脚本来直接处理数据库中的信息。\n\n首先，我们需要导出数据库数据，自然是登陆 leancloud，然后找到 数据存储 - 导入导出 - 数据导出，选择 Comment 单个 Class，单击导出按钮。\n\n![](https://static.031130.xyz/uploads/2024/11/16/d2cd564739120.webp)\n\nerr，我寻思凌晨 1 点应该是 16 点前吧，怎么导出不了，而我昨晚 23 点反而可以导出，leancloud 到底是哪门子时区。所以我直接拿了 23 点时导出的数据进行处理。\n\nleancloud 导出的数据是 jsonl 格式的，我们对需要去除的 @ 信息进行归纳总结，发现一共有两种 @ 的渲染方式\n\n- `\u003Ca class=\"at\" href=\"#id\">@username\u003C/a>`  的 html 风格（有时 class 和 href 顺序还会反过来）\n- `[@username](#id)` 的 markdown 风格\n\n而 html 风格还有两种结尾方式，\n\n一种是如 `\u003Ca class=\"at\" href=\"#id\">@username\u003C/a> , ` 这样以 空格 + 半角逗号 + 空格 结尾的形式，\n\n令一种是如 `\u003Ca class=\"at\" href=\"#id\">@username\u003C/a>: ` 这样以 半角冒号 + 空格结尾的形式。\n\nmarkdown 风格的结尾方式我就只看到一种，如 `[@username](#id): `这样以 半角冒号 + 空格结尾的形式。\n\n因此，我们需要对三种形式分别编写正则表达式进行匹配并删除，参考代码如下\n\n```python\nimport re\n\nwith open('Comment.0.jsonl', 'r') as f:\n    s = f.read()\n\npatterns = [\n    r'\u003Ca class=\\\\\"at\\\\\" href=\\\\\"#(?:.*?)\\\\\">@(?:.*?)\u003C/a>: ',\n    r'\u003Ca class=\\\\\"at\\\\\" href=\\\\\"#(?:.*?)\\\\\">@(?:.*?)\u003C/a> , ',\n    r'\\[@(?:.*?)\\]\\(#(?:.*?)\\):'\n]\n\nfor pattern in patterns:\n    s = re.sub(pattern, \"\", s)\n\nwith open('Comment.1.jsonl', 'w') as f:\n    f.write(s)\n```\n\n随后删除 Comment 表中所有数据，把生成的 `Comment.1.jsonl` 导入 leancloud，就算是大功告成了。\n\n![](https://static.031130.xyz/uploads/2024/11/16/d248ae2eac74c.webp)\n\n![](https://static.031130.xyz/uploads/2024/11/16/c3875dcde1d97.webp)\n",{"title":5,"description":30},"posts/upgrade-waline-from-v2-to-v3",false,[341,342,343],"Python","waline","Hexo","V3VluHwXAwxbIleNz0RrpkI04s9brEx4195FLKpVKs0",[346,351],{"title":347,"path":348,"stem":349,"date":350,"children":-1},"小爱课程表适配不完全指北——以 ZJUT 本科正方教务系统为例","/2024/11/18/mi-ai-class-schedule-adapter-for-zjut","posts/mi-ai-class-schedule-adapter-for-zjut","2024-11-18 21:13:56",{"title":352,"path":353,"stem":354,"date":355,"children":-1},"给家里云装上 Fedora 41 KDE 后，我是如何配置的","/2024/11/01/my-config-for-fedora-kde-41","posts/my-config-for-fedora-kde-41","2024-11-01 23:35:08",23,1761897610306]