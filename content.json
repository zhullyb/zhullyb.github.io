{"meta":{"title":"竹林里有冰的博客","subtitle":"zhullyb's blog","description":"竹林里有冰的博客","author":"竹林里有冰","url":"https://zhul.in","root":"/"},"pages":[{"title":"","date":"2024-10-02T15:40:31.750Z","updated":"2024-09-23T02:59:45.000Z","comments":false,"path":"custom.js","permalink":"https://zhul.in/custom.js","excerpt":"","text":"const url = window.location.href if ( !url.includes('zhul.in') && !url.includes('localhost') && !url.includes('127.0.0.1') ) { document.body.innerHTML = [ '', '当前页面并非本文作者的主页，将在五秒后跳转。', '', '请此站点持有者联系我: zhullyb@outlook.com', '', ].join('') document.body.style = [ 'background-color: white;', 'color: black;', 'text-align: center;', 'font-size: 50px;', 'width: 100vw;', 'height: 100vh;', 'display: flex;', ].join('') window.location.href = 'https://zhul.in' } else { (window => { const { screen: { width, height }, navigator: { language }, location, localStorage, document, history, } = window; const { hostname, pathname, search } = location; const { currentScript } = document; if (!currentScript) return; const _data = 'data-'; const _false = 'false'; const attr = currentScript.getAttribute.bind(currentScript); const website = attr(_data + 'website-id'); const hostUrl = attr(_data + 'host-url'); const autoTrack = attr(_data + 'auto-track') !== _false; const dnt = attr(_data + 'do-not-track'); const domain = attr(_data + 'domains') || ''; const domains = domain.split(',').map(n => n.trim()); const root = 'https://umami.zhul.in' const endpoint = `${root}/api/send`; const screen = `${width}x${height}`; const eventRegex = /data-umami-event-([\\w-_]+)/; const eventNameAttribute = _data + 'umami-event'; const delayDuration = 300; /* Helper functions */ const hook = (_this, method, callback) => { const orig = _this[method]; return (...args) => { callback.apply(null, args); return orig.apply(_this, args); }; }; const getPath = url => { try { return new URL(url).pathname; } catch (e) { return url; } }; const getPayload = () => ({ website, hostname, screen, language, title, url: currentUrl, referrer: currentRef, }); /* Tracking functions */ const doNotTrack = () => { const { doNotTrack, navigator, external } = window; const msTrackProtection = 'msTrackingProtectionEnabled'; const msTracking = () => { return external && msTrackProtection in external && external[msTrackProtection](); }; const dnt = doNotTrack || navigator.doNotTrack || navigator.msDoNotTrack || msTracking(); return dnt == '1' || dnt === 'yes'; }; const trackingDisabled = () => (localStorage && localStorage.getItem('umami.disabled')) || (dnt && doNotTrack()) || (domain && !domains.includes(hostname)); const handlePush = (state, title, url) => { if (!url) return; currentRef = currentUrl; currentUrl = getPath(url.toString()); if (currentUrl !== currentRef) { setTimeout(track, delayDuration); } }; const handleClick = () => { const trackElement = el => { const attr = el.getAttribute.bind(el); const eventName = attr(eventNameAttribute); if (eventName) { const eventData = {}; el.getAttributeNames().forEach(name => { const match = name.match(eventRegex); if (match) { eventData[match[1]] = attr(name); } }); return track(eventName, eventData); } return Promise.resolve(); }; const callback = e => { const findATagParent = (rootElem, maxSearchDepth) => { let currentElement = rootElem; for (let i = 0; i < maxSearchDepth; i++) { if (currentElement.tagName === 'A') { return currentElement; } currentElement = currentElement.parentElement; if (!currentElement) { return null; } } return null; }; const el = e.target; const anchor = el.tagName === 'A' ? el : findATagParent(el, 10); if (anchor) { const { href, target } = anchor; const external = target === '_blank' || e.ctrlKey || e.shiftKey || e.metaKey || (e.button && e.button === 1); const eventName = anchor.getAttribute(eventNameAttribute); if (eventName && href) { if (!external) { e.preventDefault(); } return trackElement(anchor).then(() => { if (!external) location.href = href; }); } } else { trackElement(el); } }; document.addEventListener('click', callback, true); }; const observeTitle = () => { const callback = ([entry]) => { title = entry && entry.target ? entry.target.text : undefined; }; const observer = new MutationObserver(callback); const node = document.querySelector('head > title'); if (node) { observer.observe(node, { subtree: true, characterData: true, childList: true, }); } }; const send = (payload, type = 'event') => { if (trackingDisabled()) return; const headers = { 'Content-Type': 'application/json', }; if (typeof cache !== 'undefined') { headers['x-umami-cache'] = cache; } return fetch(endpoint, { method: 'POST', body: JSON.stringify({ type, payload }), headers, }) .then(res => res.text()) .then(text => (cache = text)) .catch(() => { }); // no-op, gulp error }; const track = (obj, data) => { if (typeof obj === 'string') { return send({ ...getPayload(), name: obj, data: typeof data === 'object' ? data : undefined, }); } else if (typeof obj === 'object') { return send(obj); } else if (typeof obj === 'function') { return send(obj(getPayload())); } return send(getPayload()); }; const identify = data => send({ ...getPayload(), data }, 'identify'); /* Start */ if (!window.umami) { window.umami = { track, identify, }; } let currentUrl = `${pathname}${search}`; let currentRef = document.referrer; let title = document.title; let cache; let initialized; if (autoTrack && !trackingDisabled()) { history.pushState = hook(history, 'pushState', handlePush); history.replaceState = hook(history, 'replaceState', handlePush); handleClick(); observeTitle(); const init = () => { if (document.readyState === 'complete' && !initialized) { track(); initialized = true; } }; document.addEventListener('readystatechange', init, true); init(); } })(window); } const imgs = [ \"https://cdn.zhullyb.top/uploads/2024/08/12/62f373292129a.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f3732b562d8.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f3732d6ebe2.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f3732f6b225.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f37332b1c8b.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f37338661d8.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f3733c35741.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f3733deca7f.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f373406909e.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f373423b6c0.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f37343c5254.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f37345532e7.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f373479efcf.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f3734a2de90.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f3734bea5a7.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f3734dc3404.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f3734fe20d3.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f37351bae52.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f373539bd9f.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f37354f1ec7.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f373569f4ef.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f3735851795.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f37359a2c36.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/5fd959de5f180.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/1ef8787039f53.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/fb261297a3570.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f374ea7b242.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/62f374ec8c14d.webp\", \"https://cdn.zhullyb.top/uploads/2024/08/12/6609df9b83ecd.webp\", ] const luck_img = imgs[Math.floor(Math.random() * imgs.length)] const banner = document.getElementById('banner') banner.style.background = `url(${luck_img}) center center / cover no-repeat`"},{"title":"","date":"2024-10-02T15:40:31.763Z","updated":"2024-10-02T15:40:08.000Z","comments":false,"path":"googlefc2a365851a9799a.html","permalink":"https://zhul.in/googlefc2a365851a9799a.html","excerpt":"","text":"google-site-verification: googlefc2a365851a9799a.html"},{"title":"404","date":"2021-05-01T16:48:01.000Z","updated":"2021-10-13T13:48:10.000Z","comments":false,"path":"/404.html","permalink":"https://zhul.in/404.html","excerpt":"","text":"// 404 page not found.if (!found) { throw (“(╯°□°)╯︵ ┻━┻”);}"},{"title":"Hello, it's zhullyb here.","date":"2021-05-01T15:53:19.000Z","updated":"2024-09-28T15:21:27.000Z","comments":false,"path":"about/index.html","permalink":"https://zhul.in/about/index.html","excerpt":"","text":"About Me咱是一只大三的大本钟，日常全靠摆，就读于浙江工学院。 要吃不起饭了，来个实习救救我吧（ Fedora 用户又双叒叕叛变到 Archlinux 了，也在维护某些 AUR 和 archlinuxcn 的包，dipper 机型的 crDroid Official Maintainer 周更（月更（年更（月更博主 About This Blog这个博客主要就是用于记录一些技术性的原创内容，初衷是为了帮助遇到相同问题的用户们节约些自己的时间。 因此这个域名我将尽我可能续费下去，而如果后期服务器费用无法承担的话我也做好诶迁移到 serverless 的准备。 本站的访问情况统计: https://umami.zhul.in/share/bBTFefk1/blog My Websites博客(本站): https://zhul.in 反代服务: https://r.zhullyb.top Contact Me * 在联系我之前，请务必确保你提出的问题经过一轮搜索引擎查找 + ChatGPT 问询后依然没有结果，否则恕不回答。付费咨询可以忽略此条 回复速度最快的是邮件：&#x7a;&#104;&#x75;&#x6c;&#x6c;&#x79;&#x62;&#x40;&#x6f;&#x75;&#116;&#x6c;&#111;&#x6f;&#x6b;&#x2e;&#99;&#x6f;&#x6d; 当然，如果你喜欢某即时通信软件，你也可以在 @zhullyb 找到我，长时间没有回复的话可能是我不在线，可以发个 email 提醒我看一下。"},{"title":"归档","date":"2021-05-01T15:55:12.000Z","updated":"2021-10-13T13:48:10.000Z","comments":false,"path":"archives/index.html","permalink":"https://zhul.in/archives/index.html","excerpt":"","text":""},{"title":"收藏","date":"2021-05-01T15:53:19.000Z","updated":"2022-06-20T03:25:44.000Z","comments":false,"path":"collections/index.html","permalink":"https://zhul.in/collections/index.html","excerpt":"","text":"教程类VirtualBox启动安装于物理硬盘上的其他系统 Arch Linux devtools 简介 – 在干净的环境里编译软件包 [筆記]如何使用 youtube-dl 下載 YouTube 會員限定的影片 Windows Thin PC 汉化+激活 工具类PDF转换 TPD Quick Fix cloudflare mirror 资源类Firefox最新国际版完整包下载地址 Firefox国际版FTP服务器 chrome离线安装包 VLC vlc安卓版 IDM破解 Winrar烈火汉化版 VmwareWorkstationPro官方下载 15系列激活码： YG5H2-ANZ0H-M8ERY-TXZZZ-YKRV8 UG5J2-0ME12-M89WY-NPWXX-WQH88 UA5DR-2ZD4H-089FY-6YQ5T-YPRX6 GA590-86Y05-4806Y-X4PEE-ZV8E0 ZF582-0NW5N-H8D2P-0XZEE-Z22VA YA18K-0WY8P-H85DY-L4NZG-X7RAD 16系列激活码： ZF3R0-FHED2-M80TY-8QYGC-NPKYF #软碟通激活码： Guanjiu A06C-83A7-701D-6CFC #简体中文版Home 4BA9-0D54-214A-C938 #多语言版"},{"title":"Tags","date":"2021-05-01T15:53:19.000Z","updated":"2021-10-13T13:48:10.000Z","comments":false,"path":"tags/index.html","permalink":"https://zhul.in/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"基于 JavaScript 的 Hexo Fluid 主题 banner 随机背景图实现","slug":"random-banner-backgroud-image-implement-for-hexo-fluid-with-javascript","date":"2024-09-24T16:00:42.000Z","updated":"2024-09-24T16:25:58.000Z","comments":true,"path":"2024/09/25/random-banner-backgroud-image-implement-for-hexo-fluid-with-javascript/","link":"","permalink":"https://zhul.in/2024/09/25/random-banner-backgroud-image-implement-for-hexo-fluid-with-javascript/","excerpt":"","text":"为什么要换掉随机图片 API因为 API 太慢了。根据 PageSpeed 的测速，使用 API 的图片加载时间来到了整整 2.5s，这似乎有些不可忍受。 Vercel 冷启动问题当初年少无知，为了实现 banner 随机背景图，选择了使用 vercel 创建随机图片 API。这带来了一些问题，首先 vercel 在站点一段时间没人访问以后会进入一种类似休眠的模式，下一次启动将会经历一个冷启动（cold start）的过程。我认为这对于一个图片背景的随机 API 而言是不可忍受的。 观察图上就可以发现，第一次访问时花费了 1.9 秒，第二次只需要 0.5 秒，这是因为第一次是冷启动，需要花费更多时间。 多一次网络请求抛开冷启动不谈，引入 API 就会导致一次额外的网络请求。访客的浏览器将会先请求随机图片 API，然后根据 API 返回的 302 相应去请求真正的图片，而且这一过程是没法并行的，只能串行执行，这会浪费更多的等待时间。 Vercel 在大陆境内的访问质量Vercel 在大陆境内的访问质量其实并不算好，即使是使用了所谓的优选节点，也不一定能保证整个大陆境内大部分访客都有不错的访问质量，因此使用 Vercel 搭建 API 的行为并不是最优解。 转向 JavaScript 实现这个方案本身没多少复杂的，只不过是三年前的我对前端一无所知不敢操刀罢了。 删除原有的背景图在 _config.fluid.yml 中，将所有的 banner_img: 字段全部置空，防止其加载默认的 /img/default.png 而白白浪费用户的流量。这个字段一共在配置文件中出现了九次。 添加 js我们的目标是修改 id 为 banner 的 div 块的 backgroud 的 css 属性，Hexo Fluid 默认的生成内容是这样的 1&lt;div id=&quot;banner&quot; class=&quot;banner&quot; parallax=true style=&quot;background: url(&#x27;/img/default.png&#x27;) no-repeat center center; background-size: cover;&quot;&gt; 我们可以通过 id 来定位这个元素，修改其 style.background 属性。 可以在任何地方引入下面的 js 代码，在这篇名为《Fluid -23- 添加 Umami 统计》 的文章里的方案是可供参考的。 1234567891011121314151617181920212223242526const imgs = [ &quot;https://example.com/1.jpg&quot;, &quot;https://example.com/2.jpg&quot;, &quot;https://example.com/3.jpg&quot;, &quot;https://example.com/4.jpg&quot;, &quot;https://example.com/5.jpg&quot;, &quot;https://example.com/6.jpg&quot;, &quot;https://example.com/7.jpg&quot;, &quot;https://example.com/8.jpg&quot;, &quot;https://example.com/9.jpg&quot;, &quot;https://example.com/10.jpg&quot;, &quot;https://example.com/11.jpg&quot;, &quot;https://example.com/12.jpg&quot;, &quot;https://example.com/13.jpg&quot;, &quot;https://example.com/14.jpg&quot;, &quot;https://example.com/15.jpg&quot;, &quot;https://example.com/16.jpg&quot;, &quot;https://example.com/17.jpg&quot;, &quot;https://example.com/18.jpg&quot;, &quot;https://example.com/19.jpg&quot;, &quot;https://example.com/20.jpg&quot;,]const luck_img = imgs[Math.floor(Math.random() * imgs.length)]const banner = document.getElementById(&#x27;banner&#x27;)banner.style.background = `url($&#123;luck_img&#125;) center center / cover no-repeat` 成果博客能够在不引入外部 api 的情况下通过 js 自主实现随机的 banner 背景图，但 pagespeed 的测速结果并没有明显好转，因为 pagespeed 模拟了低速 4G 的访问速度，无论如何都无法提升大文件的加载速度。不过避免了多一次网络请求后，打开页面时的加载速度确实有提升。 参见 How can I improve function cold start performance on Vercel?","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://zhul.in/tags/JavaScript/"},{"name":"Hexo","slug":"Hexo","permalink":"https://zhul.in/tags/Hexo/"}]},{"title":"使用向日葵智能插座 C2 用电记录推算宿舍上次烧水时间","slug":"log-last-water-boiling-water-with-sunlogin-adapter-power-consumption","date":"2024-09-23T21:17:47.000Z","updated":"2024-09-23T22:33:17.000Z","comments":true,"path":"2024/09/24/log-last-water-boiling-water-with-sunlogin-adapter-power-consumption/","link":"","permalink":"https://zhul.in/2024/09/24/log-last-water-boiling-water-with-sunlogin-adapter-power-consumption/","excerpt":"","text":"我宿舍里入口处有一张公用的桌子，上面有一个烧水壶。根据生活经验，当用手摸烧水壶外壳能感受到明显热量时，水壶内的水大概是两小时内烧的，绝对能喝；但如果用手摸烧水壶外壳感受不到明显热量时，水壶内的水就不知道是什么时候烧的了，可能是三小时前，也可能是三天前。此时，在不寻求外部科学仪器介入的情况下，唯一能做的是询问寝室成员上一次水是谁烧的，是什么时候烧的。但寝室成员并不总是能够及时回答，可能在睡觉，也可能不在寝室里，还有可能出现记忆错乱。 因此，我们需要一种可靠的方案获取上一次烧水时间。 前两天陪黄老板出门吃宵夜的时候和他提到了这个难题，我提出在烧水壶附近加装物理按钮，按动时向局域网内的 HomeServer 发送请求记录准确的烧水时间。他提出可以在烧水壶前加装智能插座，使用智能插座的耗电量来推算上一次烧水时间。这是一个可行方案，上次烧水时间不需要分钟级的精准度，小时级的精准度在这个需求上完全够用，这是一个更好的方案。 在「使用 Root 后的安卓手机获取向日葵智能插座 C2 的开关 api」这篇文章中，我有过抓包向日葵官方 app 的流量数据的经验，这一次直接故技重施。很可惜，我发现用电量数据并不能直接从局域网内向智能插座获取，必须要从向日葵官方的服务器拉下来。其实想想也知道，用电数据一旦精确到小时级，日积月累下来会对硬件的存储提出一定的挑战，而比较合理的方案就是由硬件向官方的服务器每小时通信一次记录下来。 不过好消息是，官方服务器的这个接口并没有进行鉴权，不需要进行额外的操作，一条 curl 命令都能下载下来。 1https://sl-api.oray.com/smartplug/powerconsumes/$&#123;SN&#125; SN 码也不需要自己去抓包，直接在官方应用的设备关于页面就能看到。 json 数据的结构很明显，最外层是一个 Array，里面有若干个 object 123456789[ &#123; &quot;consume&quot;: 0, &quot;starttime&quot;: 1727125200, &quot;endtime&quot;: 1727128740, &quot;index&quot;: 0 &#125;,...] consume: 这段时间消耗的用电量，单位 Wh starttime: 开始时间，unix 时间戳 endtime: 结束时间，unix 时间戳 index: 智能插座的第几个孔位（为插排预留的参数，智能插座只有 0 这一个位置） 所以我们要做的就是每小时下载一次这个 json 文件，需要时从 json 中寻找上一次用电量较高的小时，取那个小时的 starttime 时间戳转换为东八区人类可读的时间即可。 1234567891011121314def last_water(): with open(&#x27;power.json&#x27;, &#x27;r&#x27;) as f: powers = json.load(f) for i in powers: if i.get(&#x27;consume&#x27;) &gt;= 30: t = i.get(&#x27;starttime&#x27;) break last_water_time = datetime.datetime.fromtimestamp(t) now = datetime.datetime.now() time_delta = now - last_water_time sec = time_delta.total_seconds() hours = sec / 3600 lwt_str = last_water_time.strftime(&#x27;%m月%d日%H点&#x27;) return f&quot;上次烧水时间为「&#123;lwt_str&#125;」，距离现在「&#123;hours:.2f&#125;」小时&quot; 至于每小时下载的任务，我这里是使用 crontab + curl 命令实现的，用 python 写个死循环跑也可以。 那么数据都取到了，剩下的就是人机交互的部分，这部分夸张点的可以写 web，写小程序，甚至写个安卓应用挂个桌面插件，想怎么做都可以。我这里就单纯将数据接入 qqbot 扔到了宿舍群，简单写了个关键词触发。","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"},{"name":"Hardware","slug":"Hardware","permalink":"https://zhul.in/tags/Hardware/"},{"name":"IoT","slug":"IoT","permalink":"https://zhul.in/tags/IoT/"}]},{"title":"使用 Caddy 反向代理 dockerhub 需要几步？","slug":"how-to-reverse-proxy-dockerhub-with-caddy","date":"2024-09-20T17:29:17.000Z","updated":"2024-09-20T20:44:48.000Z","comments":true,"path":"2024/09/21/how-to-reverse-proxy-dockerhub-with-caddy/","link":"","permalink":"https://zhul.in/2024/09/21/how-to-reverse-proxy-dockerhub-with-caddy/","excerpt":"","text":"几个月前，由于众所周知的原因，中国大陆境内失去了所有公共的 dockerhub 镜像（或者说是反代）。网上随即涌现了一批自建 dockerhub 反代的，有用 Cloudflare Workers 的，也有用 nginx 的，甚至还有自建 registry 的。我使用 caddy 的原因很简单，一是配置简单，而是通过一台国内访问质量良好的境外服务器进行反向代理的访问质量会比 Cloudflare 减速器好很多。 前一阵子在中国大陆境内想要从 dockerhub 拉取镜像的时候遇到了这方面的困扰，因此有自建 dockerhub 反代的想法。 遇事不决先抓包为了弄清楚 docker 从 dockerhub 拉取镜像的过程，需要先对网络请求进行抓包。具体的抓包方案我使用的是 mitmproxy，手动信任 ssl 证书的操作在「在 Linux 下使用 mitmproxy 抓取 HTTPS 流量」这篇文章中已经讲过了，只需要配置 dockerd 使用本机的 8080 端口进行代理即可。 docker pull 时，是调用 dockerd 进行镜像拉取，而 dockerd 在绝大多数发行版上都是由 systemd 进程直接启用了，在 shell 中直接设置环境变量的方式并不能进行代理，而透明代理的方案会引入大量无关请求，增加流量分析的难度。 比较好的方案是直接在 systemd 服务这一层设置好代理的环境变量，我这里参考的是「配置 HTTP/HTTPS 网络代理 | Docker — 从入门到实践」这篇文章。 12345$ cat /etc/systemd/system/docker.service.d/http-proxy.conf [Service]Environment=&quot;HTTP_PROXY=http://127.0.0.1:8080&quot;Environment=&quot;HTTPS_PROXY=http://127.0.0.1:8080&quot; 重启完 systemd 服务，万事俱备，我拉取了一个较小的 docker 镜像，顺利得到了预期的结果。 1docker pull svenstaro/miniserve:latest docker 先请求了 registry-1.docker.io 得到了 401 的 http 状态码后转去访问了 auth.docker.io，得到了 Authorization 字段以后重新请求 registry-1.docker.io，获取源数据后被 307 转发到了 production.cloudflare.docker.com 上。 其中，第一个 401 响应的响应头中，用 WWW-Authenticate 字段标注了 auth 鉴权的域 而 307 响应的响应头中，使用 Location 字段标注了被转发到的 url 三个域名都需要反向代理嘛？首先，作为我们提供反代服务的入口，registry-1.docker.io 一定是需要代理的，否则就无法提供反代后的服务。 auth.docker.io 只出现了一次，需要反代嘛？根据它在境内的访问质量，恐怕是需要反代的。 最后就是 production.cloudflare.docker.com ，这也是我们最终下载镜像文件的地方，99% 以上的流量都是打到这里去的，而 cloudflare 在境内的访问质量是知名的减速器，完全不可以信赖。 因此，三个域名都需要反代。 如何反代分三个域名各自代理，在 registry-1.docker.io 那一块进行特殊处理，将响应头中的 WWW-Authenticate 和 location 字段进行关键词替换，将原域名替换为反代域名。 最后的成果大概就是这个样子: 12345678910111213141516171819dockerhub.example.com &#123; reverse_proxy https://registry-1.docker.io &#123; header_up Host &#123;http.reverse_proxy.upstream.hostport&#125; header_down WWW-Authenticate &quot;https://auth.docker.io&quot; &quot;https://auth.dockerhub.example.com&quot; header_down Location &quot;https://production.cloudflare.docker.com&quot; &quot;https://production.dockerhub.example.com&quot; &#125;&#125;auth.dockerhub.example.com &#123; reverse_proxy https://auth.docker.io &#123; header_up Host &#123;http.reverse_proxy.upstream.hostport&#125; &#125;&#125;production.dockerhub.example.com &#123; reverse_proxy https://production.cloudflare.docker.com &#123; header_up Host &#123;http.reverse_proxy.upstream.hostport&#125; &#125;&#125; PS: 推荐后两个域名使用 CNAME 解析到第一个域名，这样后面更改解析的时候更方便一些。 如何设置 docker 使用反代可以直接在 docker pull 和 docker run 的命令前加上域名，比如原本的 1docker run hello-world 改成 1docker run dockerhub.example.com/library/hello-world （如果原本的镜像由 dockerhub 官方提供，没有用户名，路径需要加上 “library”） 也可以选择以前的方案，创建或修改 /etc/docker/daemon.json： 12345678910sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123; &quot;registry-mirrors&quot;: [ &quot;https://dockerhub.example.com&quot; ]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 验证一般来说，能够在中国大陆境内的网络质量下较快地下拉镜像本身就代表反代成功了，但保险起见可以像本文的第一部分一样抓个包，看看是不是都走了自己的域名了。 参见国内的 Docker Hub 镜像加速器，由国内教育机构与各大云服务商提供的镜像加速服务 无障碍访问 Docker Hub 的各种方法（自建 registry、Cloudflare 加速、Nginx 反代、代理 Docker 网络） | 绅士喵","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"mitmproxy","slug":"mitmproxy","permalink":"https://zhul.in/tags/mitmproxy/"},{"name":"Caddy","slug":"Caddy","permalink":"https://zhul.in/tags/Caddy/"},{"name":"Docker","slug":"Docker","permalink":"https://zhul.in/tags/Docker/"}]},{"title":"将 Rustdesk 中继服务从 Arch Linux 迁移至 Debian","slug":"migrate-rustdesk-server-from-arch-to-debian","date":"2024-09-19T19:20:38.000Z","updated":"2024-09-19T20:28:28.000Z","comments":true,"path":"2024/09/20/migrate-rustdesk-server-from-arch-to-debian/","link":"","permalink":"https://zhul.in/2024/09/20/migrate-rustdesk-server-from-arch-to-debian/","excerpt":"","text":"这次迁移主要是两方面原因，一来是我安装了 Arch Linux 的 VPS 要过期了，续费价格过高，没有续费的动力；二来是手上的 VPS 越来越多，逐渐意识到 Arch Linux 作为滚动发行版，每次安装新的软件都要 Syu 甚至重启系统，实在没有太多的精力去维护，这也是为什么 Arch Linux 仅适合桌面发行版。 原本在 Arch Linux 上部署的 rustdesk server 我是按照这篇文章「(水文)在archlinux上部署rustdesk服务端」部署的。本身没什么技巧，直接从 AUR 安装现成的 rustdesk-server-bin，使用 systemctl 启用 rustdesk-server-hbbr.service 和 rustdesk-server-hbbs.service 两个服务即可。 Rustdesk 现在为 Debian 提供了官方的中继服务器的 deb 包，而谷歌搜了一圈都是下载 zip 包使用 pm2 管理进程，故写下此文。 备份原服务器的 rustdesk 密钥AUR 上的安装方案将密钥放在 /opt/rustdesk-server/data 直接用 sftp 获取 id_ed25519 和 id_ed25519.pub 两个文件就行。如果是新部署的没有这两个文件也没事，rustdesk 服务在启动时可以自动创建，只不过需要在客户端重新输入公钥。 12sftp&gt; get /opt/rustdesk-server/data/id_ed25519sftp&gt; get /opt/rustdesk-server/data/id_ed25519.pub 在新服务器上下载 deb 包，进行安装1234567891011121314apt install -y curl jqversion=$(curl -s https://api.github.com/repos/rustdesk/rustdesk-server/releases/latest | jq .tag_name)hbbr_deb=rustdesk-server-hbbr_$&#123;version:1:-1&#125;_amd64.debhbbs_deb=rustdesk-server-hbbs_$&#123;version:1:-1&#125;_amd64.debutils_deb=rustdesk-server-utils_$&#123;version:1:-1&#125;_amd64.debfor deb in $hbbr_deb $hbbs_deb $utils_debdo curl -L https://github.com/rustdesk/rustdesk-server/releases/download/$&#123;version:1:-1&#125;/$&#123;deb&#125; -o $&#123;deb&#125;donedpkg -i $hbbr_deb $hbbs_deb $utils_debrm $hbbr_deb $hbbs_deb $utils_deb 简单写了个脚本，仅适用 amd64，也没做异常处理，如果服务器在大陆境内需要自行解决 github 下载时可能出现的网络波动问题。 dpkg 安装结束后默认会启用两个 systemd 服务并开机自启，所以不需要使用 systemctl 手动启用。 替换密钥将刚刚备份的一个公钥和一个私钥放在 Debian 服务器的相应路径，问题是这个路径在哪里呢？ 通过翻看 rustdesk 的 service 文件，我们大概可以定位到是在 /var/lib/rustdesk-server/ 路径下的 直接对两个密钥文件进行替换，重启 rustdesk 相关的两个 service 服务即可。 开放服务器防火墙需要开放如下端口，记得 Linux 的防火墙和云服务供应商面板（如果有的话）上都要开放 TCP(21115, 21116, 21117, 21118, 21119) UDP(21116) 客户端设置id_ed25519.pub 对应客户端中需要输入的 Key，大概长成下面这个样子 1rdtxujYccRLXwXOu2KR3V9cGgP51lEdSmE0HJHGNkn4= ID 服务器直接输入中继服务器的 ip 或者解析到对应 ip 的域名即可，另外两个地址可以不填，RustDesk会自动推导（如果没有特别设定） 成果展示 参见 Installation :: Documentation for RustDesk RustDesk Debian 自建中继服务器 (水文)在archlinux上部署rustdesk服务端","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Rustdesk","slug":"Rustdesk","permalink":"https://zhul.in/tags/Rustdesk/"},{"name":"Debian","slug":"Debian","permalink":"https://zhul.in/tags/Debian/"}]},{"title":"自建图床小记五——费用","slug":"self-host-cdn-expense","date":"2024-08-20T16:05:15.000Z","updated":"2024-08-20T16:16:45.000Z","comments":true,"path":"2024/08/21/self-host-cdn-expense/","link":"","permalink":"https://zhul.in/2024/08/21/self-host-cdn-expense/","excerpt":"","text":"自建的图床自 8 月 13 日正式启用以来，已经过去一周多了，具体的费用是多少呢？原先设计的 0 额外投入有没有实现呢？ 这是我的博客访问统计，在这一周多的时间内，一共有 1.27k 次页面访问，被 671 个访客访问了 769 次，平均下来每天也有一百多次的页面访问。 Cloudflare Workers 和 Cloudflare R2 的免费额度全部够用，用量全部小于免费额度的 1%。 又拍云联盟每年可以领取 67 元的代金券，平均每天控制在 0.18 元内即可实现白嫖。 可以看到，这一套图床在我博客当前和可见的未来的访客情况下，在不被人恶意刷流量的情况下，是不需要投入除域名续费以外的其他成本的。","categories":[],"tags":[{"name":"CDN","slug":"CDN","permalink":"https://zhul.in/tags/CDN/"},{"name":"图床","slug":"图床","permalink":"https://zhul.in/tags/%E5%9B%BE%E5%BA%8A/"}]},{"title":"自建图床小记四——上传脚本编写与图片迁移","slug":"picbed-upload-script-and-image-migration","date":"2024-08-20T15:12:30.000Z","updated":"2024-08-20T16:00:00.000Z","comments":true,"path":"2024/08/20/picbed-upload-script-and-image-migration/","link":"","permalink":"https://zhul.in/2024/08/20/picbed-upload-script-and-image-migration/","excerpt":"","text":"前面三篇小记分别讲述了图床的整体架构、用 Workers 构建 Restful API 和 自动更新部署 SSL 证书，这一篇c处理由此带来的图片上传问题，主要是要为 Typora 编写自动上传脚本，并为博客原有的图片进行迁移。 自动上传脚本主要还是给 Typora 用，实现这种效果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#!/bin/bashHOST=&quot;upload.example.com&quot;CDN_HOST=&quot;cdn.example.com&quot;UPLOAD_PATH=&quot;uploads/$(date +%Y/%m/%d)&quot;AUTH_TOKEN=&quot;1145141919810&quot;webp=falsemarkdown=falseforce=falsekeep=falsewhile getopts &quot;:mwfkp:&quot; opt; do case $opt in m|markdown) markdown=true ;; w|webp) webp=true ;; f|force) force=true ;; k|keep) keep=true ;; p|path) UPLOAD_PATH=$OPTARG ;; \\?) echo &quot;Invalid option: -$OPTARG&quot; ;; esacdoneshift $((OPTIND - 1))UPLOAD_URL=&quot;https://$HOST/$UPLOAD_PATH&quot;if [[ &quot;$UPLOAD_URL&quot; == */ ]]; then UPLOAD_URL=&quot;$&#123;UPLOAD_URL%?&#125;&quot;fifor image in &quot;$@&quot;; do if [ &quot;$webp&quot; = true ]; then cwebp -quiet &quot;$image&quot; -o &quot;$&#123;image%.*&#125;.webp&quot; image=&quot;$&#123;image%.*&#125;.webp&quot; fi if [ &quot;$keep&quot; = true ]; then FILENAME=$(basename &quot;$image&quot;) else FILENAME=&quot;$(md5sum $image | cut -c 1-13).$(basename $image | cut -d. -f2)&quot; fi if [ &quot;$force&quot; = true ]; then UPLOAD_RESPONSE=$(curl -s -X PUT &quot;$&#123;UPLOAD_URL&#125;/$FILENAME&quot; \\ -w &quot;%&#123;http_code&#125;&quot; \\ --data-binary @&quot;$image&quot; \\ -H &quot;X-Custom-Auth-Key: $AUTH_TOKEN&quot; \\ -H &quot;Overwrite: true&quot; \\ ) else UPLOAD_RESPONSE=$(curl -s -X PUT &quot;$&#123;UPLOAD_URL&#125;/$FILENAME&quot; \\ -w &quot;%&#123;http_code&#125;&quot; \\ --data-binary @&quot;$image&quot; \\ -H &quot;X-Custom-Auth-Key: $AUTH_TOKEN&quot; \\ ) fi UPLOAD_HTTP_CODE=$(echo &quot;$UPLOAD_RESPONSE&quot; | tail -n1) if [ -n &quot;$UPLOAD_PATH&quot; ]; then CDN_URL=&quot;https://$CDN_HOST/$UPLOAD_PATH/$FILENAME&quot; else CDN_URL=&quot;https://$CDN_HOST/$FILENAME&quot; fi if [ &quot;$UPLOAD_HTTP_CODE&quot; != &quot;200&quot; ]; then echo &quot;上传失败: $UPLOAD_RESPONSE&quot; continue fi if [ &quot;$markdown&quot; = true ]; then echo &quot;![]($&#123;CDN_URL&#125;)&quot; else echo &quot;$&#123;CDN_URL&#125;&quot; fidone 这一次使用 Cloudflare Workers 构建的 Restful API 很有意思，使用了 GET、PUT 和 DELETE 三个请求类型。GET 请求很常见，是用来获取图片的，PUT 和 DELETE 在 web 开发就不如 GET 和 POST 常见了，这一次也是让我体会到了这两个 http verb 在 Storage Bucket 操作中是有多么形象了。 PUT - 从直观上来讲，就是将某个文件放到目标位置 打个比方，我向 https://cdn.example.com/img/avatar.webp 打了一个请求，并带上了要上传的文件，那就意味着我将这个文件放到了 Storage Bucket 的 /img/avatar.webp 这个位置，所以我在上传后，应该就能用 GET 请求我刚才 PUT 的那个 URL 获取我刚才上传的东西。如果那个路径存在文件，那么默认行为是直接覆盖。 DELETE - 删除目标路径的文件 和 PUT 一样，我在请求对应 URL 后，Storage Bucket 中对应 URL 路径的资源应该被删除。 PUT 和 DELETE 这两个 Http Verb 让我们更像是在对一个真实的文件系统进行操作，而非那种传统的使用 POST 上传的图床那样，我们并不通过 POST 请求上传一个文件，然后获取资源最终被放置位置的 URL —— 我们自己决定资源被存放的位置。 在这个 Shell 脚本中，引入了四个可选选项 12345m|markdown) markdown=true ;;w|webp) webp=true ;;f|force) force=true ;;k|keep) keep=true ;;p|path) UPLOAD_PATH=$OPTARG ;; markdown 选项决定返回值是否以 ![]() 这种 URL 格式返回 webp 决定上传过程中是否将图片转为 webp 后再上传 force 决定如果遇到文件路径冲突，是否强制覆盖云端的文件 keep 决定是否保留文件原有的文件名进行上传 path 决定文件具体被存放的路径（或者使用默认的路径） HOST 是图床用于上传的地址，CDN_HOST 是图床用于被方可访问的地址。 由于急着用，也没考虑协程的处理方式，等等看后期有没有时间用 Python 重写吧。 博客图床迁移脚本因为只用一次，所以也没使用协程或者多线程的方式去上传文件——毕竟图片不多，也就两三百张。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import osimport reimport requests# 哪些后缀的文件需要检测是否存在老图床的 URL 并进行迁移？file_extension = [ &#x27;.md&#x27;, &#x27;.yml&#x27;, &#x27;.html&#x27;]pic_urls = []_files = []# 用于匹配老图床的正则表达式，这里是按照 lsky pro 的格式编写的pattern = r&#x27;https://cdn.example.com/\\d&#123;4&#125;/\\d&#123;2&#125;/\\d&#123;2&#125;/[a-z0-9]&#123;13&#125;\\.[a-z]&#123;3,4&#125;&#x27;# 图片的上传部分，需要先从原 url 中下载图片，在上传到新图床中，如果需要的话可以在中途转换为 webp 格式def upload(url): &quot;&quot;&quot; 此处的返回值应该是新的 url &quot;&quot;&quot;# 遍历目标后缀文件名的文件，如果存在老图床的 url，则将 url 加入到 pic_urls 列表中，并将这个文件的文件名（相对路径）添加到 _files 列表中for root, dirs, files in os.walk(&quot;.&quot;): for file in files: if file.endswith(tuple(file_extension)): file_name = os.path.join(root, file) with open(file_name, &#x27;r&#x27;) as f: content = f.read() urls = re.findall(pattern, content) if urls: pic_urls.extend(urls) _files.append(file_name)# 先转为集合，再转回列表，进行去重pic_urls = list(set(pic_urls))print(&quot;共找到图片：&quot;, len(pic_urls))url_dict = &#123;&#125;# 将列表中的图片进行上传，每张图片最多尝试三次上传，如果三次都失败，则保留原连接for i,u in enumerate(pci_urls, start=1): for t in range(1,4): try: new_u = upload(u) continue except: if t == 3: new_u = u print(f&quot;&#123;u&#125; 无法上传：&#123;e&#125;&quot;) url_dict[u] = new_u print(f&quot;&#123;i&#125; / &#123;len(pic_urls)&#125;&quot;)# 对 _files 列表中的文件一一完成替换for file in _files: with open(file, &#x27;r&#x27;) as f: content = f.read() for k, v in url_dict.items(): content = content.replace(k, v) with open(file, &#x27;w&#x27;) as f: f.write(content) print(&quot;完成替换：&quot;, file)","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"图床","slug":"图床","permalink":"https://zhul.in/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"Shell Script","slug":"Shell-Script","permalink":"https://zhul.in/tags/Shell-Script/"},{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"}]},{"title":"自建图床小记三—— SSL 证书的自动更新与部署","slug":"auto-renew-ssl-certificate-and-deploy-to-upyun-with-github-action","date":"2024-08-14T02:35:18.000Z","updated":"2024-08-14T08:46:30.000Z","comments":true,"path":"2024/08/14/auto-renew-ssl-certificate-and-deploy-to-upyun-with-github-action/","link":"","permalink":"https://zhul.in/2024/08/14/auto-renew-ssl-certificate-and-deploy-to-upyun-with-github-action/","excerpt":"","text":"为什么要自动更新？众所周知，为站点开启 https 访问需要获得对应 host 的 ssl 证书，而如果希望证书被访客的浏览器所信任，需要拿到由 Certificate Authority (CA) 签发的 ssl 证书。在前一阵子那波 BAT 等大厂提供的云服务停止发放免费的由 TrustAsia/DigiCert 签发的一年有效期免费 ssl 证书之后，市面上已经没有被广泛信任的 CA 签发的免费的一年有效期的 ssl 证书了，于是不得不用回由 Let’s Encrypt/ZeroSSL 等 CA 签发三个月免费证书。 但话又说回来，三个月有效期确实不太够，一年有效期的证书就一年一更，手动申请部署也不麻烦；三个月有效期的证书手动就有点麻烦了——我一般会在证书到期的前 15 天进行更新，防止最后几天自己太忙了没时间管。 这套图床架构的自动更新有没有困难？境外通过 Cloudflare SaaS 接入的域名通过验证后会自动获得由 Cloudflare 提供的由 Google Trust Services 签发的证书，不需要我们操心。 境内咱选用的又拍云 CDN 提供了免费的 Let’s Encrypt 证书及其自动续期服务，但需要我们把图床访问域名的 DNS CNAME 解析到他们家。 这里有个问题，我们这套图床架构在境外的解析是解析到 Cloudflare 的，不可能通过 Let’s Encrypt 的 acme challenge。如果使用 upyun 申请 ssl 证书，则意味着每次更新都要我们手动将境外的 dns 解析记录暂时解析到又拍云，待证书更新成功后再解析回 Cloudflare，非常麻烦。 使用 Github Action 跑 acme.sh 获取 ssl 证书本着「能使用长期免费稳定服务就使用长期免费稳定服务」的思想，决定使用 Github Action 申请 ssl 证书。 在 Github Action 跑 acme.sh 获取 ssl 证书意味着不能使用 http 文件检验的方式检验域名所有权，需要使用 dns 检验。截至本文写作时间，acme.sh 已经支持了 150+ 个主流的 DNS 解析商（Managed DNS providers）的 api，针对不支持 api 修改 dns 解析记录的，还可以使用 DNS alias 模式——即将需要申请 ssl 证书的域名先 cname 到一个工具人域名上，将工具人域名通过 NS 解析到 acme.sh 支持的 DNS 解析商，进而实现 CA 对域名所有权的验证。 先在本地跑起来我采用的是 Cloudflare，直接在个人资料页创建一个具有编辑 DNS 权限的 API 令牌 随后在自己的域名页面，找到区域 ID 和 账户 ID 在自己的本机安装 acme.sh,设置好 Cloudflare DNS 的几个变量 123export CF_Token=&quot;&quot;export CF_Account_ID=&quot;&quot;export CF_Zone_ID=&quot;&quot; 随后可以尝试使用 acme.sh 签发 ssl 证书 1acme.sh --issue --dns dns_cf -d cdn.example.com 上 Github Action原本是打算直接用 Menci/acme 这个 Action的，可惜遇到了点问题。 在我本地，Cloudflare 相关的 Token 和 ID 并没有被写入到 account.conf，而是被写在 cdn.example.com_ecc/cdn.exampe.com.conf，大概就没办法直接用这个 Action 了，不得不转去手搓。不过好在 Menci/acme 中还是能抄到不少的。 压缩本地的 ca 文件夹1cd $HOME/.acme.sh/ &amp;&amp; tar cz ca | base64 -w0 安装 acme.sh12- name: Install acme.sh run: curl https://get.acme.sh | sh 解压 ca 文件夹123- name: Extract account files for acme.sh run: | echo &quot;$&#123;&#123; secrets.ACME_SH_ACCOUNT_TAR &#125;&#125;&quot; | base64 -d | tar -C ~/.acme.sh -xz 执行 acme.sh 申请证书1234567- name: Issue Certificate run: | export CF_Token=&quot;$&#123;&#123; secrets.CF_TOKEN &#125;&#125;&quot; export CF_Zone_ID=&quot;$&#123;&#123; secrets.CF_ZONE_ID &#125;&#125;&quot; export CF_Account_ID=&quot;$&#123;&#123; secrets.CF_ACCOUNT_ID &#125;&#125;&quot; mkdir -p output ~/.acme.sh/acme.sh --issue --dns dns_cf --force -d $&#123;&#123; env.domain &#125;&#125; --fullchain-file output/fullchain.pem --key-file output/key.pem 压缩证书123- name: zip Certificate run: | zip -j output/$&#123;&#123; env.domain &#125;&#125;_$(date +%Y%m%d).zip output/fullchain.pem output/key.pem 通过 tg bot 发送压缩包给自己12345- name: Push Certificate run: | TG_BOT_TOKEN=&quot;$&#123;&#123; secrets.TG_BOT_TOKEN &#125;&#125;&quot; TG_CHAT_ID=&quot;$&#123;&#123; secrets.TG_CHAT_ID &#125;&#125;&quot; curl -s -X POST https://api.telegram.org/bot$&#123;TG_BOT_TOKEN&#125;/sendDocument -F chat_id=$&#123;TG_CHAT_ID&#125; -F document=&quot;@output/$&#123;&#123; env.domain &#125;&#125;_$(date +%Y%m%d).zip&quot; 部署到又拍云这里使用的是 menci/deploy-certificate-to-upyun。由于又拍云没有提供上传 ssl 证书的 api，因此只能通过模拟用户登陆的方式实现。 12345678910- name: Deploy To Upyun uses: Menci/deploy-certificate-to-upyun@beta-v2 with: subaccount-username: $&#123;&#123; secrets.UPYUN_SUBACCOUNT_USERNAME &#125;&#125; subaccount-password: $&#123;&#123; secrets.UPYUN_SUBACCOUNT_PASSWORD &#125;&#125; fullchain-file: output/fullchain.pem key-file: output/key.pem domains: | $&#123;&#123; env.domain &#125;&#125; delete-unused-certificates: true 参见 使用 GitHub Actions 自动申请与部署 ACME SSL 证书 （续）acme.sh脚本使用新cloudflare api令牌申请证书 acmesh-official/acme.sh","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Bot","slug":"Bot","permalink":"https://zhul.in/tags/Bot/"},{"name":"CDN","slug":"CDN","permalink":"https://zhul.in/tags/CDN/"},{"name":"Github Action","slug":"Github-Action","permalink":"https://zhul.in/tags/Github-Action/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"SSL certificates","slug":"SSL-certificates","permalink":"https://zhul.in/tags/SSL-certificates/"},{"name":"图床","slug":"图床","permalink":"https://zhul.in/tags/%E5%9B%BE%E5%BA%8A/"}]},{"title":"自建图床小记二——使用 Workers 为 R2 构建 Restful API","slug":"build-restful-api-for-cloudflare-r2-with-cloudflare-workers","date":"2024-08-13T14:58:26.000Z","updated":"2024-08-13T16:30:25.000Z","comments":true,"path":"2024/08/13/build-restful-api-for-cloudflare-r2-with-cloudflare-workers/","link":"","permalink":"https://zhul.in/2024/08/13/build-restful-api-for-cloudflare-r2-with-cloudflare-workers/","excerpt":"","text":"访问 R2 的两种方式一般来说，想要访问 Cloudflare R2 中的文件，会有两种方式。 一种是在 R2 的设置界面设置自定义域 另一种是通过 Cloudflare Workers 进行访问 那么应该选择哪种？选择 Cloudflare Workers！ 为什么是 Cloudflare Workers？要回答这个问题比较困难，但可以回答另一个问题——「为什么不设置自定义域实现直接访问？」 自定义域的访问存在限制设置自定义域的访问方式存在较多的限制，让我们先来复习一下上一篇博客中提到的 DNS 解析方案 1 在这里，我们需要将图床访问域名通过 NS 接入 DnsPod 实现境内外的分流，但 R2 所允许设置的自定义域必须是通过 NS 接入 Cloudflare 的，这存在冲突。那如果我们先将自定义域设置为通过 NS 接入 Cloudflare 的工具人域名，再将图床访问域名通过 CNAME 解析到工具人域名会不会有问题呢？恭喜你获得 403 Forbidden。 如果通过上一篇文章中的 DNS 解析方案 2 来进行 DNS 解析，能不能成功设置为 Cloudflare R2 的自定义域呢？也不行，Cloudflare R2 的自定义域会占用域名的解析，这意味着你无法将图床访问域名解析到用于分流的工具人域名。 结论：截至本文写作时间，设置自定义域的方案不适用于 DNS 分流的图床架构。 如何上传文件到 Cloudflare R2？网页端直接上传最简单的上传方式是直接在 Cloudflare 进行网页上传，但这种方案不适合自动化脚本，也没法接入 Typora 使用 Amazon S3 的兼容 API手动调用 S3 APICloudflare R2 被设计为兼容 Amazon S3 的存储方案，自然兼容 Amazon S3 的上传 API，在 Cloudflare Docs 中有关于 S3 API 的实现情况记载，大部分接口功能都是实现了的。但。。。但 S3 使用的是 AWS Signature 作为鉴权，你不会希望在每个自动化程序中都自己实现一次的。。。 使用 aws-cli 等 SDK使用 aws-cli 可以自动实现计算 AWS Signature，这是一种可行的方案，但我可能会在别的服务中使用到我的图床，不是所有的服务所处的环境都能够执行 shell 命令，也不是所有的编程语言都有现成的 SDK 可用。 使用 Cloudflare Workers 构建 Restful API在 Cloudflare Docs 中明确提出可以使用 Cloudflare Workers 访问 Cloudflare R2 Bucket，通过 Workers 设置界面的按钮，可以非常方便的将 R2 Bucket 作为一个 R2Object 绑定到 JavaScript 的一个变量中，这里有相关的开发文档。 结论: 从易用性上来看，使用 Cloudflare Workers 构建 Restful API 这种上传文件的方案是最为合适的。 使用 Cloudflare Workers 构建 Restful API 的方案有没有什么缺点？有。 Cloudflare Workers 的每日额度是有限的，在极端的流量下可能会用完（应该不会吧？） Cloudflare Workers 的内存限制为 128MB，在上传下载 &gt; 100MB 的文件时可能会出错。有这种体积上传需求的场景建议使用别的上传方案。 如何构建？直接贴代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566const hasValidHeader = (request, env) =&gt; &#123; return request.headers.get(&#x27;X-Custom-Auth-Key&#x27;) === env.AUTH_KEY_SECRET;&#125;;function authorizeRequest(request, env, key) &#123; switch (request.method) &#123; case &#x27;PUT&#x27;: case &#x27;DELETE&#x27;: return hasValidHeader(request, env); case &#x27;GET&#x27;: return true; default: return false; &#125;&#125;export default &#123; async fetch(request, env) &#123; const url = new URL(request.url); const key = decodeURI(url.pathname.slice(1)); if (!authorizeRequest(request, env, key)) &#123; return new Response(&#x27;Forbidden\\n&#x27;, &#123; status: 403 &#125;); &#125; switch (request.method) &#123; case &#x27;PUT&#x27;: const objectExists = await env.MY_BUCKET.get(key); if (objectExists !== null) &#123; if (request.headers.get(&#x27;Overwrite&#x27;) !== &#x27;true&#x27;) &#123; return new Response(&#x27;Object Already Exists\\n&#x27;, &#123; status: 409 &#125;); &#125; &#125; await env.MY_BUCKET.put(key, request.body); return new Response(`Put $&#123;key&#125; successfully!\\n`); case &#x27;GET&#x27;: const object = await env.MY_BUCKET.get(key); if (object === null) &#123; return new Response(&#x27;Object Not Found\\n&#x27;, &#123; status: 404 &#125;); &#125; const headers = new Headers(); object.writeHttpMetadata(headers); headers.set(&#x27;etag&#x27;, object.httpEtag); return new Response(object.body, &#123; headers, &#125;); case &#x27;DELETE&#x27;: await env.MY_BUCKET.delete(key); return new Response(&#x27;Deleted!\\n&#x27;); default: return new Response(&#x27;Method Not Allowed\\n&#x27;, &#123; status: 405, headers: &#123; Allow: &#x27;PUT, GET, DELETE&#x27;, &#125;, &#125;); &#125; &#125;,&#125;; 代码的大部分都是基于 Cloudflare Docs 中给出的样例，修改了几个小的优化点 删除了 ALLOW_LIST 部分代码，默认所有文件都是可以被访问的 在上传一个文件时，如果目标路径存在同名文件，则不直接覆盖，而是返回 409 的异常 HTTP 相应，如果想要强制覆盖，则需要在 Http Header 中加入 Overwrite: true 解出请求路径时，使用 decodeURI( ) 方法先进行解码，解决文件路径中含有中文时会导致请求失败的问题。 填入代码后，还需要绑定两个变量，一个是 R2 Bucket 另一个是自己的管理密码 如何使用 Cloudflare Workers 构建的 Restful API 进行文件操作？上传以 python 为例，上传一个文件 1MB.bin 到 /example/ 目录下，上传的 url 就是文件最终的存在路径。 1234567891011121314import requestsAUTH_KEY_SECRET=&#x27;1145141919810&#x27;with open(&#x27;1MB.bin&#x27;, &#x27;&#x27;rb) as f: file_content = f.read() requests.put( &#x27;https://r2.example.workers.dev/example/1MB.bin&#x27;, headers=&#123; &#x27;X-Custom-Auth-Key&#x27;: AUTH_KEY_SECRET, &#x27;Overwrite&#x27;: True # 如果不需要强制覆盖可以删除这一行 &#125;) 访问通过浏览器直接访问 https://r2.example.workers.dev/example/1MB.bin 应该就能访问到 删除仍然以 python 为例，删除刚才的文件 12345678910111213import requestsAUTH_KEY_SECRET=&#x27;1145141919810&#x27;with open(&#x27;1MB.bin&#x27;, &#x27;&#x27;rb) as f: file_content = f.read() requests.delete( &#x27;https://r2.example.workers.dev/example/1MB.bin&#x27;, headers=&#123; &#x27;X-Custom-Auth-Key&#x27;: AUTH_KEY_SECRET &#125;) 参见 用 cloudflare 的 R2 和 worker 来做文件托管 Workers API reference Use R2 from Workers 创建已签名的 AWS API 请求","categories":[],"tags":[{"name":"图床","slug":"图床","permalink":"https://zhul.in/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"Cloudflare","slug":"Cloudflare","permalink":"https://zhul.in/tags/Cloudflare/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://zhul.in/tags/JavaScript/"},{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"}]},{"title":"自建图床小记一——图床架构与 DNS 解析","slug":"new-picbed-based-on-cloudflare-and-upyun","date":"2024-08-12T09:07:11.000Z","updated":"2024-08-13T16:37:23.000Z","comments":true,"path":"2024/08/12/new-picbed-based-on-cloudflare-and-upyun/","link":"","permalink":"https://zhul.in/2024/08/12/new-picbed-based-on-cloudflare-and-upyun/","excerpt":"","text":"一直以来，我使用的都是使用付费的第三方图床，可惜最近几年为了节省成本，境内的稳定性出现了一些问题。过去一年中光是我本人遇到的无法访问的情况就有三四次，其中两次持续时间超过 2 小时，甚至有网友特意来 at 我告知我博客使用的图床出问题了，还有两次是在我作品验收前 24 小时内出现，幸亏我及时切换了资源链接。此外，境外 CDN 也从原先的 Cloudflare 换掉了，目前海外的解析结果似乎只有一个在美国的节点，其余地区（尤其是日本香港新加坡等常用的落地地区）的访问质量不佳，Google 的 page speed test 甚至提示我的图片拖慢了网站加载速度。 基于上述种种原因，我开始选择自建图床，前前后后折腾了快一周后，新图床终于投入使用，目前我的博客已经完成了所有图片资源的切换。 架构设计 这一套架构使用 Dnspod 免费版实现在境内外的解析分流，将境内的流量导向又拍云 CDN 为境内的访客提供服务，在境外使用量大管饱的 Cloudflare CDN 节省成本，为全球提供加速访问。 为什么是又拍云如你所见，我的博客底部挂了又拍云的 logo。又拍云联盟为个人开发者提供了每个月 10GB 存储和 15GB 的免费 CDN 流量，在每年通过申请后会以 67 元无门槛代金券的形式发放到账号，也不用担心某个月超了一点点而付出额外的费用。 相比之下，七牛云虽然控制台的前端 UI 不错，但出了这种事情导致其在我心里印象分极差: 「从山西联通到组播IP：七牛云的奇怪视角（附分析和后日谈）」Archived Here 为什么是 Cloudflare R2作为自己的图床，必须要保证稳定性，境内访问的稳定性可以先放到一边，最重要的就是保证源文件的稳定性。不同于在自己的 VPS 上存储图片的方案，使用 Cloudflare R2 作为储存不需要关注 VPS 到期以后的图片迁移问题。使用 Cloudflare R2 作为储存，免费用量对于个人站点来说绰绰有余，在 10GB 存储容量超出之前不用考虑别的问题，也不用担心资金支持不下去导致的麻烦。而不使用又拍云提供的 10GB 存储也可以节省这部分的代金券金额，让代金券尽可能多的抵扣境内 CDN 流量带来的费用。 需要的东西 两个或两个以上的域名（其中一个需要备案） Cloudflare 所支持的境外支付方式（PayPal 账号 / Visa Card / Master Card），用于开通 Cloudflare R2 和 Cloudflare SaaS 接入 很多很多钱（其实没有很多，又拍云联盟每年的 67 元抵用券在我这里看来完全是够用的） 聪明的大脑，能够快速敲击键盘的双手，能够支持你熬夜的心脏 * 在这一套架构中引入了香港 VPS 进行反向代理，一来是防止国内 CDN 与 Cloudflare 的网络连接质量过差导致的回源失败，二来也是方便我在没有国际联网的情况下进行图片的上传，但如果没有条件其实是可以去掉的。 DNS 解析 如上图，将图床域名 NS 接入 DnsPod，工具人域名 NS 接入 Cloudflare 即可实现境内外分流的效果。 图床访问域名在境外 CNAME 解析到工具人域名 图床访问域名在境内 CNAME 解析到境内 CDN 服务商 工具人域名在 Cloudflare 上解析到任何站点都行，只需点亮解析时 Cloudflare CDN 代理按钮即可生效。 但如果你的备案域名已经通过 NS 接入了 Cloudflare，可以采用下面这套架构。 * 解析方案 2 中的图床访问域名和工具人域名可以是同属于同一二级域名的不同子域名 这种方案要多一步，把图床访问域名 CNAME 解析到用于分流的工具人域名。 Cloudflare SaaS 接入 SaaS 接入大概就是如图所示，此外还要配置 Cloudflare Workers 的域名访问 这样就能保证在境外访问图床域名时将请求打到 Cloudflare Workers 上了，关于使用 Cloudflare Workers 构建图床 Restful API 相关的内容我放在下一篇博客讲。 参见 图床 CDN CNAME 接入 Cloudflare SaaS 实现分流","categories":[],"tags":[{"name":"CDN","slug":"CDN","permalink":"https://zhul.in/tags/CDN/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"图床","slug":"图床","permalink":"https://zhul.in/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"Cloudflare","slug":"Cloudflare","permalink":"https://zhul.in/tags/Cloudflare/"}]},{"title":"在 Linux 下使用 mitmproxy 抓取安卓手机上的 HTTPS 流量","slug":"capture-android-https-traffic-on-linux-with-mitmproxy","date":"2024-07-31T08:02:28.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/07/31/capture-android-https-traffic-on-linux-with-mitmproxy/","link":"","permalink":"https://zhul.in/2024/07/31/capture-android-https-traffic-on-linux-with-mitmproxy/","excerpt":"","text":"纵使安卓下有小黄鸟 HttpCanary 这种抓包神器，但手机一块 6 英寸的小屏实在是不方便分析流量情况，还得是 PC 的屏幕更大一些，处理起流量信息来更得心应手一些。 把话说在前面，目前的安卓抓包有不小的限制 Android 7 以下的版本: 直接以普通用户的权限安装 ssl 证书即可被信任 Android 7 以上的版本: 安全性较低的应用: 需要使用 root 权限将证书移动至 /system/etc/security/cacerts使证书被系统信任 安全性较高的应用（比如微信 7.0 以上的版本）: 在满足上一条条件的情况下，需要阻止第三方应用使用自带的 ssl 证书信任范围（绕过 SSL Pinning）。通常情况下需要额外的手段对目标应用进行篡改，比如使用 justTrustMe 这个 xposed 模块，或者 frida。 除此之外，Linux 版本 &gt;= 5.5 的安卓设备也可以使用 eCapture 这款基于 eBPF Linux 内核模块实现的抓包软件，算是种奇技淫巧。 本文只讨论 Android 7 以上版本中安全性较低的应用，因为我当前的抓包目标局限于一款安全性不高的外包软件。 基本操作见「在 Linux 下使用 mitmproxy 抓取 HTTPS 流量」 安装 ssl 证书1cp $HOME/.mitmproxy/mitmproxy-ca-cert.pem $(openssl x509 -subject_hash_old -in $HOME/.mitmproxy/mitmproxy-ca-cert.pem | head -n 1).0 此时我们就可以在家目录下找到一个以 .0 结尾的证书文件，我们的目标是将其放到手机的 /system/etc/security/cacerts 路径下。 对于一些出厂安卓版本较低、system 分区采用可变文件系统的手机，我们可以很轻松的使用带有 root 权限的文件管理器将证书文件移动到对应的目录（我这里就是）；而对于出厂版本较高的手机，system 分区可能是不可写的，需要采用额外的奇技淫巧。 1、通过 ADB 将 HTTP Toolkit CA 证书推送到设备上。 2、从 /system/etc/security/cacerts/ 中复制所有系统证书到临时目录。 3、在 /system/etc/security/cacerts/ 上面挂载一个 tmpfs 内存文件系统。这实际上将一个可写的全新空文件系统放在了 /system 的一小部分上面。 将复制的系统证书移回到该挂载点。 4、将 HTTP Toolkit CA 证书也移动到该挂载点。 5、更新临时挂载点中所有文件的权限为 644，并将系统文件的 SELinux 标签设置为 system_file，以使其看起来像是合法的 Android 系统文件。 ——《安卓高版本安装系统证书 HTTPS 抓包 - 终极解决方案》 「archived here」 让被抓包的应用流量经过 mitm 代理服务器mitmproxy 默认会在 pc 端的 8080 端口开启一个 http 代理服务器，我们要做的就是想办法让待抓包的应用流量被这个 http 代理服务器所代理。 12345[zhullyb@Archlinux ~]$ ip -br alo UNKNOWN 127.0.0.1/8 ::1/128 enp0s31f6 UP 172.16.0.255/25 fe80::2df9:2927:cd44:65c/64 wlp0s20f3 UP 192.168.20.212/24 fe80::a6bc:919:281e:dcab/64 docker0 DOWN 172.17.0.1/16 fe80::42:d1ff:febe:d513/64 在这里我们能看到本机的无线网卡地址是 192.168.20.212，所以 http 代理服务器的地址就是 http://192.168.20.212:8080。（如果你的有线网卡和手机在同一局域网下，当然也可以用有线网卡的 ip 地址） 我们当然可以在安卓手机的 WIFI 连接页面填入 http 代理地址。 但这对我来说似乎并不是一个好主意：一来并不是所有的应用都会默认使用 http 代理服务器，二来这回导致抓包目标不明确，非目标应用的流量也会经过代理服务器。 我选择了 Nekobox 这个常见的代理软件，它支持 http 代理服务器，且允许分应用代理。 可以看到能正常抓取 https 流量 参见 安卓应用防抓包机制及一些绕过 安卓7.0+系统抓包方案 frida抓包 gojue/ecapture 安卓高版本安装系统证书 HTTPS 抓包 - 终极解决方案","categories":[],"tags":[{"name":"Android","slug":"Android","permalink":"https://zhul.in/tags/Android/"},{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"mitmproxy","slug":"mitmproxy","permalink":"https://zhul.in/tags/mitmproxy/"}]},{"title":"为中柏 N100 小主机开启来电自启","slug":"enable-ac-power-loss-for-jumper-n100","date":"2024-07-22T15:31:51.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2024/07/22/enable-ac-power-loss-for-jumper-n100/","link":"","permalink":"https://zhul.in/2024/07/22/enable-ac-power-loss-for-jumper-n100/","excerpt":"","text":"因为收到通知，寝室过两天要断电 20 分钟，所以需要打开 N100 家里云的来电自启功能。 正常关机短暂等待数秒后，开机，狂按 Delete 键进入 BIOS。 在 Advanced 选项中选择「OEM Configuration」 可以在最后一行「AC Power Loss」中选择模式。 Power Off: 关闭相关功能。 Power On: 传统意义上的来电自启，只要接通电源就会自启动。 Last State: 只有在上次关机是意外断电导致时，接通电源才会自启动。","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Hardware","slug":"Hardware","permalink":"https://zhul.in/tags/Hardware/"},{"name":"HomeServer","slug":"HomeServer","permalink":"https://zhul.in/tags/HomeServer/"}]},{"title":"我的博客被完整地反向代理，并自动翻译成了繁体中文","slug":"my-blog-is-completely-proxied-and-translated-into-traditional-chinese","date":"2024-07-18T03:22:37.000Z","updated":"2024-08-20T04:55:39.000Z","comments":true,"path":"2024/07/18/my-blog-is-completely-proxied-and-translated-into-traditional-chinese/","link":"","permalink":"https://zhul.in/2024/07/18/my-blog-is-completely-proxied-and-translated-into-traditional-chinese/","excerpt":"","text":"2024.08.20更新我将境外的 Github Pages 解析停了，所有流量全部指向我的 HK 的 vps。 访问对方站点 /?about/ 时，在我服务器 /about/ 收到了一个奇怪的请求，访问对方别的路径时也会在我服务器的对应路径收到请求，UA 伪装成了 Google 家的爬虫: （关于为什么有 Mozilla 字段，可以参见 《是的，所有现代浏览器都假装自己是火狐》） 这个 ip 的归属地是新加坡 Cogent，合理怀疑是对方的源站 IP（也有可能只是对方用于请求的爬虫 ip）。直接通过 ip 访问对方站点，发现是 lnmp 的安装成功提示: 我注意到对方站点在 html 结尾处加了如下字段 1&lt;!-- freevslinks --&gt;&lt;div style=&quot;display:none&quot;&gt;&lt;a href=&quot;http://www.xxfseo.com/?time=1721267439&quot;&gt;xxfseo.com&lt;/a&gt;&lt;/div&gt;&lt;!-- /freevslinks --&gt; 似乎是专业产生互联网垃圾的组织。 我目前已经屏蔽了来自 154.39.149.128 这个 ip 的访问请求，对方的站点暂时性崩盘，以后可能会换用别的 ip 来爬也说不准，先到此为止吧。 现象今早打开我的流量统计网站，发现我的博客有一个神奇的 referer 顶着我博客用的 favicon，但竟然不是我的域名。点进去一看，发现我的博客被翻译成了繁体中文，而且语句读上去也不是很通畅。Archived here. 再打开关于页一看，把我的博客域名给干掉了，只留下一个反代域名。Archived here. 随机打开一个幸运页面，使用 F12 控制台查看流量情况，发现 umami 统计和 waline 评论都用的我个人部署的 查询 ip 归属地，是老朋友 Cloudflare 泛播 结合 url 上不明所以的问号，推测应该是 cloudflare workers 反向代理 + 调用翻译 api + 关键词替换。我小小更新了某个页面，发现对方站点也立马更新了，基本可以确定是反向代理。 whois 查询没有获得任何有用信息，一眼望去全是隐私保护。 事先声明，我的博客采用CC BY-NC-SA 4.0，我个人是非常欢迎任何人注明出处的情况下搬运甚至翻译我的文章的，甚至允许搬运到 csdn——只要你不开收费访问。但这种反代行为我是非常抵触的。 文章被翻译成了繁体中文，但没有注明是翻译稿，直接把我本人的网名用繁体写了上去，这并不符合 CC BY-NC-SA 4.0 的要求。 翻译质量很差，就连机翻都不应有这种奇怪的同义词替换，问了问熟悉繁中的朋友说是港台也没有这种用法，像是故意洗稿。 反向代理了我的整个网站，但把我关于页上的博客链接给去掉了，我不认为这是善意的反代行为。Archived here. 仍然在使用我的 waline 评论和 umami 统计。 没有给我任何事先的邮件说明或者评论留言，whois 开隐私保护的情况下，我找不到任何方法去联系这位域名的持有者。 怎么办？植入 js 进行跳转因为对方同步的及时性很强，高度怀疑是 cloudflare workers 反向代理，且评论和流量统计都直接原模原样用的是我的 js，我就注入一个 js 检测 host，如果不是我的域名或者本地调试时使用的 127.0.0.1 or localhost，则清空页面内容，给出文字提示，五秒后跳转到我的博客。代码如下: 12345678910111213141516171819202122const host = window.location.hostif (host !== &#x27;zhul.in&#x27; &amp;&amp; ! host.startsWith(&#x27;localhost&#x27;) &amp;&amp; ! host.startsWith(&#x27;127.0.0.1&#x27;)) &#123; document.body.innerHTML = [ &#x27;&lt;div style=&quot;margin: auto;&quot;&gt;&#x27;, &#x27;&lt;h1&gt;当前页面并非本文作者的主页，将在五秒后跳转。&lt;/h1&gt;&#x27;, &#x27;&lt;br /&gt;&#x27;, &#x27;&lt;h1&gt;请此站点持有者联系我: zhullyb@outlook.com&lt;/h1&gt;&#x27;, &#x27;&lt;/div&gt;&#x27;, ].join(&#x27;&#x27;) document.body.style = [ &#x27;background-color: white;&#x27;, &#x27;color: black;&#x27;, &#x27;text-align: center;&#x27;, &#x27;font-size: 50px;&#x27;, &#x27;width: 100vw;&#x27;, &#x27;height: 100vh;&#x27;, &#x27;display: flex;&#x27;, ].join(&#x27;&#x27;) setTimeout(() =&gt; &#123; window.location.href = &#x27;https://zhul.in&#x27; &#125;, 5000)&#125; 给 waline 和 umami 设置限制我博客使用的 waline 和 umami 均是我自己在 vercel 上架设的，我自然可以根据访客的 referer 来判断请求的来源。不过看了下，vercel.json 文件并不能直接实现这个需求，可能需要我们自己来编写一些简易的中间件。 Walinewaline 文档中有明确提到，waline 基于 Koa 框架开发，可以自行编写中间件。 1234567891011121314151617181920212223242526272829// example/index.cjsconst Application = require(&#x27;@waline/vercel&#x27;);module.exports = Application(&#123; plugins: [ &#123; middlewares: [ async (ctx, next) =&gt; &#123; const referer = ctx.request.headers[&#x27;referer&#x27;]; if (referer) &#123; if ( !referer.include(&#x27;localhost&#x27;) &amp;&amp; !referer.include(&#x27;127.0.0.1&#x27;) &amp;&amp; !referer.include(&#x27;zhul.in&#x27;) ) &#123; ctx.status = 403 ctx.body = &#x27;Forbidden&#x27; return &#125; &#125; await next(); &#125;, ] &#125; ], async postSave(comment) &#123; // do what ever you want after comment saved &#125;,&#125;); 成效立竿见影 umami对 umami 的第一次请求是 script.js，这个请求是因为 html 头部添加了 umami 的 script 链接，这一次请求是不带有 referer 的，因此，对方站点使用我的 umami 统计并不会给我的博客访问统计造成错乱——umami 能够自行分辨对方的站点是否是当初添加网站时填写的站点。但我不能忍的地方在与 umami 的数据库会记录对方站点的流量情况，这占用了我的数据库空间。 umami 使用 nextjs 开发，似乎并没有给我留可供自定义的接口，贸然修改源码则可能会在下次 merge 官方代码时遇到麻烦。为了给自己省点事，我选择不再让博客加载 https://umami.zhul.in/script.js ，而是将其中的内容复制保存下来，添加基于 host 的判断条件来决定是否向自建的 umami 服务发起请求。 尝试向 cloudflare 举报滥用行为cloudflare 是允许提交滥用举报的，这个域名正在使用 cloudflare 提供服务，因此我可以尝试举报，链接在这里: https://www.cloudflare.com/zh-cn/trust-hub/reporting-abuse/ 类别就可以选 DCMA，因为对方没有遵守 CC BY-NC-SA 4.0 协议给我的文章做出合理的署名，且我的博客关于页面不属于 CC BY-NC-SA 4.0 的范畴，对方是没有理由去对这一页做出二次分发的行为的。 不过我暂时还没这么做，我期待着我前面的几个方案能够奏效，我仍寄希望于对方会及时和我沟通，我也不太想为此去填一张额外的烦人的表单。 最终效果","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Cloudflare","slug":"Cloudflare","permalink":"https://zhul.in/tags/Cloudflare/"},{"name":"Blog","slug":"Blog","permalink":"https://zhul.in/tags/Blog/"}]},{"title":"尝试体验 Fedora COPR 中的 allow SSH 功能","slug":"try-ssh-connection-in-fedora-copr","date":"2024-07-15T03:14:12.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/07/15/try-ssh-connection-in-fedora-copr/","link":"","permalink":"https://zhul.in/2024/07/15/try-ssh-connection-in-fedora-copr/","excerpt":"","text":"在今年的早些时候，我在 COPR 看到了一个新出现的名为「allow SSH」的按钮。 我在 COPR 的 User Documentation 中找到了对应的描述。 Sometimes it is useful to manually debug failed builds not locally but within the Copr infrastructure. That’s why it is possible to allow SSH access to a copr builder. More information in the SSH access to Copr builders blog post. COPR 的这项功能允许包维护者远程访问自己没有的 CPU 架构或 Linux 发行版的 Linux 环境，大大减少打包时的痛点。 开始使用尝试点击按钮，获得如下界面，可以填写自己的 ssh 公钥，最多可以选择两台设备，如果选择的设备数量大于 2，则剩下的人物会维持在 pending 状态，直到被你 ssh 连接的构建机完成对应的构建任务。 在该次构建的详情页面，等待 backend.log 按钮出现 在这个 url 对应的文件中，我们可以找到需要的 ssh 命令 使用对应的 ssh 命令即可连上构建服务器 先跑个 neofetch 看看，双核 16G，看着还行。 随手跑了个 speedtest，竟然是千兆上下传对等的网速。 在这台机子上，我们可以使用 builder-live.log 中的命令手动触发一次构建（不过我这里跑了一半就报错了，疑似是系统不够完善） 不过很可惜，COPR 似乎并没有给我们中途去干预/调试构建过程的方案，仅仅是提供了一个可供自由操作的 Linux 环境。使用 copr-rpmbuild 命令可以进行对应的构建，但构建过程依然是在沙箱内进行，且没有给中途暂停/调试的机会。如果需要一步步手动的构建，还是建议使用 rpmbuild 命令进行。 杂项 使用 copr-builder help 命令可以获取打包机的提示信息 使用 copr-builder show 命令查看剩余时间 使用 copr-builder prolong 可以延长打包机的有效时长 使用 copr-builder release 可以销毁当前的打包机环境 限制 由于安全原因，构建结束后，只有 spec 文件和日志可以被存储到 copr 对应项目的服务器。打包机会使用一个独特的沙箱防止其构建产物被二次使用，哪怕是同一个用户都不行。 为了避免资源艾琳娜贵妃，同一用户在同一时刻最多只能使用两台具有 ssh 访问权限的打包机。 由于上面的两套规定，当 copr 构建失败时并不能自动启动 SSH 访问权限，需要用户手动在面板上 resubmit 当前任务并选择使用 SSH 访问权限。 打包机在默认情况下 1 小时后自动销毁，除非你手动申请延长时间，最长为 48 小时。 有些打包机只有 IPv6 的访问地址，你没得选。如果你无法连接 IPv6 网络，你可以取消当前的任务并重新发布并期待能给你下发一台具有 IPv4 访问地址的打包机（其实非常少），或者使用代理。 如果 SRPM 构建失败，则不能 resubmit 当前任务。这是 COPR 的实现逻辑问题，未来可能得到改善。 参考「SSH access to Copr builders」","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Fedora","slug":"Fedora","permalink":"https://zhul.in/tags/Fedora/"},{"name":"Experience","slug":"Experience","permalink":"https://zhul.in/tags/Experience/"}]},{"title":"在 Arch Linux 下配置使用 HP Laser 103w 打印机无线打印","slug":"config-hp-laser-103w-printer-for-archlinux","date":"2024-07-14T10:30:33.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/07/14/config-hp-laser-103w-printer-for-archlinux/","link":"","permalink":"https://zhul.in/2024/07/14/config-hp-laser-103w-printer-for-archlinux/","excerpt":"","text":"我寝室有一台使用 wifi 连接的 HP Laser 103w 打印机，这些天刚好布置了新的 HomeServer，因此来记录一下这台打印机的配置过程，根据 HP 官网驱动包的名字「HP Laser 100 and HP Color Laser 150 Printer series Print Driver」推断，此过程应该能适用于所有的 HP Laser 100 及 HP Color Laser 150 系列的打印机。 打印机联网首先使用 Windows 操作系统完成打印机的联网工作，在路由器的网页管理界面可以看到这台打印机的局域网 ip 是 192.168.123.20 ，记录备用。如果有条件的话，尽量将打印机的 MAC 地址与 IP 地址绑定，避免路由器将该 IP 分配给别的设备。 安装 CUPS随后按照 ArchWiki 的 CUPS 页面进行相关配置，CUPS 是苹果公司开源的打印系统，是目前 Linux 下最主流的打印方案。 首先安装 cups ，如果需要「打印为 pdf」的功能，可以选装 cups-pdf。 1pacman -S cups 1pacman -S cups-pdf 接着需要启动 cups 的服务，如果需要使用 cups 自带的 webui，可以直接启用 cups.service，这样就能在 http://localhost:631 看到对应的配置页面。 1systemctl enable cups.service --now 而如果你正在使用一些集成度较高的 DE 如 KDE 或 GNOME，可以安装 DE 对应的打印机管理程序。在 Arch Linux 下，KDE 自带的打印机管理程序包名为 print-manager，此外还需要安装安装 system-config-printer 打印机功能支持软件包。这种方案则不需要启动 cups.service，只需要启动 cups.socket 即可。 12pacman -S print-manager system-config-printersystemctl enable cups.socket 杂项在常规的流程中，通常会安装 ghostscript 来适应 Non-PDF 打印机，这台 HP Laser 103w 也不例外。 1pacman -S ghostscript 如果是 PostScript 打印机可能还需要安装 gsfonts 包，但我这里不需要。 安装驱动OpenPrinting 维护的 foomatic 为很大一部分打印机提供的驱动文件，Gutenprint 维护的 gutenprint 包也包含了佳能(Canon)、爱普生(Epson)、利盟(Lexmark)、索尼(Sony)、奥林巴斯(Olympus) 以及 PCL 打印机的驱动程序。如果你的打印机型号和我的不同，可以尝试安装这些组织维护的驱动。具体的安装方法同样可以在 ArchWiki 的 CUPS 页面找到。我上一台打印机 HP LaserJet 1020 所需的驱动是在 AUR/foo2zjs-nightly 中取得的。 但 HP Laser 103w 的驱动程序都不在这些软件包中，在 HP 的官网我们可以找到这个页面，包含了 HP Laser 103w 的 Linux 驱动下载地址（已在 web.archive.org 存档）。通过下载下来的文件名，我们可以看见名字为 uld-hp，理论上可以直接通过压缩包内的安装脚本进行安装，但我通过这个名字顺藤摸瓜，找到了 AUR/hpuld 可以直接进行安装。 1yay -S hpuld 添加打印机打开设置中的打印机设置后，选择添加打印机，CUPS 直接帮我们找到了局域网下的打印机，并自动开始搜索驱动程序（虽然没搜到）。 但如果没能自动检测到打印机，也可以使用手动选项中的 AppSocket/HP JetDirect 手动输入打印机的 ip 地址进行配置。 紧接着就到了选择驱动程序的阶段，厂商选择 HP，能够找到「HP Laser 10x Series」的选项，直接选择。 接着就可以完成打印机的添加。 随后便能正常打印文件啦！","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Hardware","slug":"Hardware","permalink":"https://zhul.in/tags/Hardware/"},{"name":"Printer","slug":"Printer","permalink":"https://zhul.in/tags/Printer/"},{"name":"HomeServer","slug":"HomeServer","permalink":"https://zhul.in/tags/HomeServer/"}]},{"title":"使用动态公网 ip + ddns 实现 rustdesk 的 ip 直连","slug":"dynamic-public-ip-and-ddns-for-rustdesk","date":"2024-06-30T10:15:00.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/06/30/dynamic-public-ip-and-ddns-for-rustdesk/","link":"","permalink":"https://zhul.in/2024/06/30/dynamic-public-ip-and-ddns-for-rustdesk/","excerpt":"","text":"最近跟风整了一台 n100 的迷你主机装了个 Archlinux 当 HomeServer，搭配上了显卡欺骗器，平常一直远程使用，因此需要实现稳定的远程桌面连接。开源软件 Rustdesk 本身对 Linux 的适配尚可，可惜官方提供的服务器位于境外，且前一阵子因为诈骗相关的风波使得官方对连接做出了一些限制，应当使用自建服务器或者 ip 直连。 单从网络安全的角度出发，最佳实践应该是通过 wireguard 或者别的协议先接入局域网，然后使用局域网内的 ip 直连，这是最稳妥的，但我有点懒，而且我可能会在多个设备上都有控制 HomeServer 的需求，给所有设备配置 wireguard 是一件挺麻烦的事情，因此我决定放弃安全性，直接公网裸奔。 在学校宿舍的电信宽带提供了一个动态公网 ip，因此只需要设置好 ddns 和端口转发就可以拿到一个固定的 domain + port 提供给 rustdesk 直连。 在被控端 Rustdesk 允许直连访问在「设置」中的「安全」一栏选择「解锁安全设置」，拉到最下面的「安全」栏，勾选「允许 IP 直接访问」，并选择一个端口，范围在 1000 ~35535 之间且不要被本地的其他程序占用，Rustdesk 的默认值为 21118。 可以直接在局域网内的另一台设备进行测试，直接在 Rustdesk 中输入被控端的局域网 ip 和刚刚设置的端口，看看能不能访问得通，如果不行可能需要排查一下被控端访问墙设置的问题。 ddns由于我的域名是交给 cloudflare 进行解析的，就找了个支持 cloudflare 的 ddns 脚本，大致的部署过程可以参考 「自建基于Cloudflare的DDNS」，不过我小改了一下脚本中获取公网 ipv4 的方式，直接 ssh 到路由器上获取当前的 ipv4 地址，不依赖外部的服务。 1WAN_IP=`ssh -o HostKeyAlgorithms=+ssh-rsa -o PubkeyAcceptedKeyTypes=+ssh-rsa root@192.168.1.1 &#x27;ip -br a&#x27; | grep pppoe-wan | awk &#x27;&#123;print $3&#125;&#x27;` 理论上来说，有不少路由器自身就支持不少域名解析商 端口转发端口转发需要在路由器的后台设置进行，我这里路由器使用的是 openwrt 系统，大部分路由器应该都支持这个操作。 在「网络」-「防火墙」 选择「端口转发」 新建端口转发，共享名随便填，外部端口是你最终要在主控端输入的端口，内部 IP 地址是被控机 的 IP 地址，可以用 ip -br a 命令看到，内部端口就是上文在 Rustdesk 指定的端口号。 效果可以直接在主控端口输入 ddns 的域名和端口号，实现远程控制","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Shell Script","slug":"Shell-Script","permalink":"https://zhul.in/tags/Shell-Script/"},{"name":"HomeServer","slug":"HomeServer","permalink":"https://zhul.in/tags/HomeServer/"},{"name":"Router","slug":"Router","permalink":"https://zhul.in/tags/Router/"},{"name":"OpenSource Project","slug":"OpenSource-Project","permalink":"https://zhul.in/tags/OpenSource-Project/"},{"name":"Rustdesk","slug":"Rustdesk","permalink":"https://zhul.in/tags/Rustdesk/"}]},{"title":"使用 Windows 虚拟机运行虚拟专用网客户端为 Linux 提供内网环境","slug":"setup-network-environment-for-non-linux-vpn-client-with-virtual-machine","date":"2024-05-22T17:07:44.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/05/23/setup-network-environment-for-non-linux-vpn-client-with-virtual-machine/","link":"","permalink":"https://zhul.in/2024/05/23/setup-network-environment-for-non-linux-vpn-client-with-virtual-machine/","excerpt":"","text":"起因最近在某家公司实习，公司内部的 git 部署在内网环境上，需要通过虚拟专用网的客户端（天翼云的 AONE）才能够正常访问。很可惜，客户端只提供了 Windows 和 MacOS 的版本。 工作的代码总是要提交的，我也不想改变我的开发环境，又不希望在 Windows 上使用 git-for-windows 这个近乎简陋的工具进行代码提交，更别说还有一些别的内网服务接下来可能也会用到。所以最好的办法就是在 Linux 下也配置好能够访问内网的环境。 理论在 Windows 下使用 AONE 的网络拓扑是这样的 而我的方案则是使用 Windows 虚拟机开启 AONE，并在这台虚拟机上开一个 socks5 server 负责代理 Linux 宿主机需要打到内网服务的流量。网络拓扑如下 根据 bilibili 上技术蛋老师的视频总结，我们应该选择使用网卡桥接的网络配置，只有这个配置方式同时支持「宿主-&gt;虚拟机」和 「虚拟机-&gt;互联网」的网络。 实操在 Windows 虚拟机中开启虚拟专用网客户端开启 AONE，不做赘述 开启 socks server，监听地址为 0.0.0.0 （或者设置为宿主机的 IP 地址）在「熊孩子(BearChild)」的推荐下，我这里采用的是大名鼎鼎的二级射线（某 V 字开头的常见软件），直接从 GIthub Release 中下载 Windows X64 的压缩包，简单配置下即可，如果没有什么特殊需求的话可以只修改图中的两处配置。 在终端中通过该软件的 run 命令即可开启服务 在宿主机进行测试我这里使用的是 mzz2017 编写的 gg 命令进行代理，代理服务器的 ip 地址使用虚拟机下 ipconfig 命令获得的 ip 地址，端口号则对应上面配置文件中的 port 参数。 这里 curl 百度得到了正确的相应，说明通道是通的，gg 也可以用于代理浏览器。经实测能够正常访问公司内网服务，不便在博客中展示。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Windows","slug":"Windows","permalink":"https://zhul.in/tags/Windows/"},{"name":"Virtual Machine","slug":"Virtual-Machine","permalink":"https://zhul.in/tags/Virtual-Machine/"}]},{"title":"以 Archlinux 中 makepkg 的方式打开 rpmbuild","slug":"open-rpmbuild-in-the-way-of-archlinux-makepkg","date":"2024-05-03T14:48:39.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/05/03/open-rpmbuild-in-the-way-of-archlinux-makepkg/","link":"","permalink":"https://zhul.in/2024/05/03/open-rpmbuild-in-the-way-of-archlinux-makepkg/","excerpt":"","text":"在 Redhat 系的发行版上打包软件的时候，会发现与 Archlinux 完全不同的思路。 Fedora 所代表的 Redhat 阵营一看就是那种宏大叙事的大型发行版，rpmbuild 在默认情况下会在 $HOME/rpmbuild 下的一系列文件夹进行构建过程。使用 rpmdev-setuptree 命令会创建好下面这些目录进行构建。 12345678$ tree rpmbuildrpmbuild├── BUILD├── BUILDROOT├── RPMS├── SOURCES├── SPECS└── SRPMS Fedora 将所有的软件的构建都集中在一个 rpmbuild 目录中，BUILD 是编译时使用的，BUILDROOT 是最终安装目录，RPMS 是存放最终产物的，SOURCES 是存放源码等文件的，SPECS 是存放指导构建过程的 spec 文件的，而 SRPMS 是 RH 系为了 reproducibility 而单独将 spec 和源文件打包的产物。除了 rpmbuild 命令以外，Fedora 还有一套使用容器构建 rpm 包的 mock 构建系统，与 Archlinux 的 devtools 类似，这里不作过多叙述。 反观 Arch 的构建目录，就有一股浓浓的小作坊气味。每个软件包自己拥有一个目录，指导构建过程的 PKGBUILD 文件、源文件和最终的产物都放在这个目录下，目录下的 src 和 pkg 文件夹分别对应 rpm 的 BUILD 和 BUILDROOT，前者是源文件被解压的目录和编译过程进行的目录，后者是软件最终的安装目录。 12345$ tree reporepo├── src├── pkg└── PKGBUILD 好巧不巧，我偏偏习惯这个小作坊气息的 arch build system，每个软件包独享一个自己的目录，干净又卫生。我自然也希望在 Fedora 下打 rpm 包的时候能够使用类似 Archlinux 下 makepkg 使用的目录结构。 简单了解在了解一系列 rpmbuild 中宏（macros）相关的知识后，我意识到这并非不可能。 使用如下的命令可以获取目前系统中定义的所有宏 1rpm --showrc 而可以使用如下命令检查某一个宏目前被定义成了什么值 1rpm --eval &quot;%&#123;_topdir&#125;&quot; 更多关于宏的描述可以在 https://rpm-software-management.github.io/rpm/manual/macros.html 获取 修改路径我们可以把定义成 $HOME/rpmbuild 的 %_topdir 重新定义成当前目录。 在 $HOME/.rpmmacros 中，去除顶部对 %_topdir 的定义，重新填上以下这些定义，即可初步完成我想要的效果。 1234567%_topdir %(pwd)%_builddir %&#123;_topdir&#125;/src%_buildrootdir %&#123;_topdir&#125;/pkg%_rpmdir %&#123;_topdir&#125;%_sourcedir %&#123;_topdir&#125;%_specdir %&#123;_topdir&#125;%_srcrpmdir %&#123;_topdir&#125; 现在在任何一个目录下执行 rpmbuild 相关命令，都会把 src 认为是构建目录，pkg 是最后安装目录，spec 文件和源文件早当前文件夹下，构建产物在当前文件夹下的 x86_64（或者别的架构名，这一层目录我还没有找到应该如何去掉）下。 自动安装依赖文件Fedora 中的 rpmbuild 不带有 makepkg -s 的功能，不能自动安装依赖。不过这也不意味着需要自己傻傻地去翻 spec 看看需要哪些构建依赖。可以使用 dnf 的 builddep 命令实现 1sudo dnf builddep ./*.spec 不过 dnf 没有什么完成构建后自动卸载依赖的选项。这些依赖装完以后就一辈子赖在你的电脑上了，才不是，可以在构建完成后使用 dnf 自带的后悔药功能撤销上一条命令执行的效果。 1sudo dnf history undo 0 不过如果在 builddep 过程中，dnf 从 updates 源里更新了一些软件，那么它在 undo 时可能就没法获取更新前的软件版本。会有 Cannot find rpm nevra 的提示 可以使用 --skip-broken 命令跳过那些没法找到老版本的软件，继续卸载其余的软件。 自动下载源文件很多使用 spec 中会在 source 里写上下载地址，而不是附上源码文件。rpm 似乎因为一些原因禁止了 rpmbuild 自动下载源文件的功能。可以通过在使用 rpmbuild 的时候带上 --undefine=_disable_source_fetch 取消定义这个行为，或者干脆在调用 rpmbuild 之前执行一遍 1spectool -gR *.spec 这样也能自动下载源文件。 构建行为makepkg 的默认构建行为就是只构建最终的安装包，Archlinux 中并没有 Fedora 那样打 source rpm 保证 reproduceability 的行为，这在 rpmbuild 中对应的是 -bb 选项。 使用 rpmbuild -bb *.spec 即可 上面介绍完了 rpmbuild 和 makepkg 的主要差异，应该可以自己搓一个 rpmbuild-wrapper 去实现以 makepkg 的方式打开 rpmbuild 的目标了，具体的 wrapper 脚本我就不放出来献丑了。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Fedora","slug":"Fedora","permalink":"https://zhul.in/tags/Fedora/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"RPM Package","slug":"RPM-Package","permalink":"https://zhul.in/tags/RPM-Package/"}]},{"title":"使用 Github Action 更新用于 rpm 打包的 spec 文件","slug":"update-a-rpm-spec-by-github-action","date":"2024-04-29T11:19:54.000Z","updated":"2024-05-03T14:23:23.000Z","comments":true,"path":"2024/04/29/update-a-rpm-spec-by-github-action/","link":"","permalink":"https://zhul.in/2024/04/29/update-a-rpm-spec-by-github-action/","excerpt":"","text":"有一些软件包的上游本身就是使用 Github Action 发版的，每次 commit 都会触发 Github Action 去构建并分发新版本，使用构建时的时间日期作为版本号。针对这种包，手动更新费时费力，而规范的 specfile 应当是更新 %changelog 的，因此应当是使用 rpmdev-bumpspec 命令。只不过 rpmdev-bumpspec 需要在 rpm 系发行版或者装有 rpm 系列依赖包的发行版下执行，这不是随随便便一个 Linux 环境就能运行的。 我找到了 netoarmando/rpmdev-bumpspec-action 这个 Github Action，它通过启动一个 Fedora 的 docker 实现了使用 rpmdev-bumpspec 的效果。虽然 release 中只有一个 2021 年构建的 v1 版本，但 Fedora 的版本高低不影响 rpmdev-bumpspec 的效果。但每次 Github Action 执行时都会使用 fedora:latest 的 docker 重新构建一遍，不用担心 fedora 版本过低。 于是我们便解决了最核心的问题——处理 spec 文件。接下来只要补充好头尾的步骤即可。 首先使用 actions/checkout 释出仓库内的文件 1234- name: Checkout uses: actions/checkout@v2 with: fetch-depth: 0 通过 shell 命令获取仓库内 spec 文件的版本号，存入 $GITHUB_ENV 1234- name: Get Current Version run: | CURRENT_VERSION=`grep -E &#x27;^Version:&#x27; *.spec | awk &#x27;&#123;print $2&#125;&#x27;` echo &quot;CURRENT_VERSION=$CURRENT_VERSION&quot; &gt;&gt; $GITHUB_ENV 通过 Github API 获取目标软件的最新版本号，存入 $GITHUB_ENV 1234- name: Export latest geoip version run: | NEW_VERSION=`curl -s https://api.github.com/repos/&#123;user_name&#125;/&#123;repo_name&#125;/releases/latest | jq -r &#x27;.tag_name&#x27; | sed &#x27;s/v//g&#x27;` echo &quot;NEW_VERSION=$NEW_VERSION&quot; &gt;&gt; $GITHUB_ENV 当仓库内 spec 版本号与软件最新版本号不一致时，运行 rpmdev-bumpspec 1234567- name: Run rpmdev-bumpspec action if: $&#123;&#123; env.CURRENT_VERSION != env.NEW_VERSION &#125;&#125; uses: netoarmando/rpmdev-bumpspec-action@v1 with: specfile: &#x27;&#123;filename&#125;&#x27; new: $&#123;&#123; env.NEW_VERSION &#125;&#125; userstring: &quot;username &lt;username@mail.com&gt;&quot; 当仓库内 spec 版本号与软件最新版本号不一致时，保存更改，推入仓库。 12345678- name: Commit changes if: $&#123;&#123; env.CURRENT_VERSION != env.NEW_VERSION &#125;&#125; run: | git config --local user.email &quot;zhullyb@outlook.com&quot; git config --local user.name &quot;zhullyb&quot; git add . git commit -m &quot;upgpkg: v2ray-geoip@$&#123;&#123; env.NEW_VERSION &#125;&#125;&quot; git push （可选）当仓库内 spec 版本号与软件最新版本号不一致时，通过 curl 语句触发 copr 的 webhook，让 copr 进行构建。 1234- name: trigger copr webhook if: $&#123;&#123; env.CURRENT_VERSION != env.NEW_VERSION &#125;&#125; run: | curl -X POST $&#123;&#123; secrets.COPR_HOOK_URL &#125;&#125;v2ray-geoip/ 最终的 yml 文件可以参考这里","categories":[],"tags":[{"name":"Fedora","slug":"Fedora","permalink":"https://zhul.in/tags/Fedora/"},{"name":"Github Action","slug":"Github-Action","permalink":"https://zhul.in/tags/Github-Action/"},{"name":"RPM Package","slug":"RPM-Package","permalink":"https://zhul.in/tags/RPM-Package/"}]},{"title":"使用 Python 生成甘特图(Gantt Chart)","slug":"generate-gantt-chart-with-python","date":"2024-04-24T04:02:58.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/04/24/generate-gantt-chart-with-python/","link":"","permalink":"https://zhul.in/2024/04/24/generate-gantt-chart-with-python/","excerpt":"","text":"在写操作系统的作业的时候有几道题给出了几个进程的相关信息，要求我们画出几种简单调度的甘特图。操作系统的作业一直是电子版，上传 pdf 即可的。我觉得手画甘特图拍照嵌入 pdf 中不太优雅，过于掉价，因此就想直接生成甘特图嵌入。 在谷歌搜寻了一番，我发现现在的甘特图生成网站都太现代化了，根本不是操作系统课上教的样子了。 所幸我找到了 gao-keyong/matplotlib-gantt，虽然只有两个 star（没事，加上我就 3 stars 了），但确实能用，README 中的样例也是我期望的样子。 项目中自带了一个 jupyter 的示例，算得上是非常简单易上手的了，依赖方面只要装好 matplotlib 就可以使用，不存在依赖地狱。尽管是三年前的项目，在我本机的 Python 3.11 上仍然能够正常运行。 tuple 中的第一个数字表示从当前时间开始，第二个数字表示持续时间。每一个表示 category 的 list 中可以存在多个 tuple。 给一些咱生成的例子。 1234567891011121314from gantt import *category_names = [&#x27;P1&#x27;, &#x27;P2&#x27;, &#x27;P3&#x27;, &#x27;P4&#x27;, &#x27;P5&#x27;]results = &#123; &#x27;FCFS&#x27;: [[(0,2)], [(2,1)], [(3,8)], [(11,4)], [(15,5)]], &#x27;SJF&#x27;: [[(1,2)], [(0,1)], [(12,8)], [(3,4)], [(7,5)]], &#x27;non-compreemptive priority&#x27;: [[(13,2)],[(19,1)],[(0,8)],[(15,4)],[(8,5)]], &#x27;RR (quantum=2)&#x27;: [[(0,2)], [(2,1)],[(3,2),(9,2),(15,2),(18,2)], [(5,2),(11,2)], [(7,2),(13,2),(17,1)]]&#125;arrival_t = [0, 0, 0, 0]gantt(category_names, results, arrival_t).show() 1234567891011from gantt import *category_names = [&#x27;P1&#x27;, &#x27;P2&#x27;, &#x27;P3&#x27;, &#x27;P4&#x27;, &#x27;P5&#x27;, &#x27;P6&#x27;]results = &#123; &#x27;&#x27;: [[(0,20)], [(25,10),(45,10),(75,5)], [(35,10),(55,5),(80,10)], [(60,15)], [(100,5),(115,5)],[(105,10)]],&#125;arrival_t = [0]gantt(category_names, results, arrival_t).show()","categories":[],"tags":[{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"}]},{"title":"uniapp 中的图片预加载","slug":"image-preload-in-uniapp","date":"2024-03-31T21:31:25.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/04/01/image-preload-in-uniapp/","link":"","permalink":"https://zhul.in/2024/04/01/image-preload-in-uniapp/","excerpt":"","text":"最近在做微信小程序的时候遇到了图片资源过大无法正常打包的问题，没什么太好的方法，只能是使用图床托管这些图片资源。但部分图片的体积实在太大，即使是采用了境内 cdn 的图床，即使是采用 webp 对图片进行了压缩，部分图片都需要小几秒去把图片加载出来，这导致的用户体验就不是很好了，因此我们需要实现图片预加载的功能。 在 uniapp 的官方文档中，我找到了 uni.preloadPage(OBJECT) 方法。很可惜，这个方法并不支持微信小程序，自然不能完成被预加载页面的图片资源预加载。 经过搜索，在一篇奇奇怪怪的文章中提到： 在UniApp中，图片预加载可以通过使用uni.getImageInfo方法来实现。这个方法可以获取图片的信息，包括宽度、高度等。可以在应用启动时就开始加载图片，以提高后续图片显示的速度。 很遗憾，经过实测，提前使用 getImageInfo() 方法并不能实现图片的预加载。getImageInfo() 获取时的 Type 是 xhr，而后续图片加载时的 Type 为 webp，图片会被重复下载，并没有实现预加载的作用。 上图中，蓝色部分是 getImageInfo() 的网络请求，红色部分是真正的图片加载请求，可谓是一点用都没有，该加载慢还是加载慢。 那有没有什么办法能够实现预加载呢？我没找到优雅的方法，选择在应用的首页创建一个 display: none 的 view 将所有的图片先加载一遍。 1234567891011121314151617&lt;template&gt; &lt;view style=&quot;display: none;&quot;&gt; &lt;image v-for=&quot;image in imageToPreload&quot; :src=&quot;image&quot; /&gt; &lt;/view&gt;&lt;/template&gt;&lt;script setup lang=&quot;ts&quot;&gt;const imageToPreload = [ &quot;https://http.cat/100&quot;, &quot;https://http.cat/200&quot;, &quot;https://http.cat/300&quot;, &quot;https://http.cat/400&quot;, &quot;https://http.cat/500&quot;]&lt;/script&gt; 可以看到，红色部分的资源在 size 那一栏变成了 (disk cache)，加载时间也明显降低，虽然方法不优雅，但起码实现了图片资源的预加载。","categories":[],"tags":[{"name":"Vue.js","slug":"Vue-js","permalink":"https://zhul.in/tags/Vue-js/"},{"name":"uniapp","slug":"uniapp","permalink":"https://zhul.in/tags/uniapp/"}]},{"title":"小记 - 尝试拼凑出 apt 仓库中的 deb 包下载地址","slug":"try-to-compose-download-links-of-deb-packages-in-apt-repository","date":"2024-03-13T13:55:04.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/03/13/try-to-compose-download-links-of-deb-packages-in-apt-repository/","link":"","permalink":"https://zhul.in/2024/03/13/try-to-compose-download-links-of-deb-packages-in-apt-repository/","excerpt":"","text":"大概一周前，有一个来源不明的 Linux 微信，从包的结构来看是基于 qt 实现的图形化界面，deb 包中的 control 信息表明是腾讯团队官方出品的。今天听人说 UOS 的商店上架了最新的微信，便尝试从 UOS 的官方仓库提取下载链接，帮助 AUR Maintainer 获取到新的地址。 在我的《deepin-elf-verify究竟是何物？》这篇文章中，我成功从 uos.deepin.cn 下载到了来自 UOS 中的软件包。可惜，当我采用同样的方法搜索 weixin 或者 wechat 字样时，没有得到任何结果。 UOS 上的软件来源起码来自两个仓库，一个是与系统有关的软件，比如 Linux Kernel，GCC 一类开源软件，应该就是来自我之前下载到 deepin-elf-verify 的那个源。除此之外，还有一个 appstore 源，里面存放的都是应用商店中上架的软件（大部分可能是闭源的）。 在 chinauos.com 下载到最新的 ISO 安装镜像后，直接在虚拟机中走完正常的安装流畅，然后直捣黄龙。 可以看出，/etc/apt/sources.list.d/appstore.list 文件中列出的源很有可能就是我们要找的新版微信的所在源。 可惜直接访问的时候，源地址给出了 403。他们似乎不愿意公开源地址的 filelist index。 不过没关系，既然 UOS Desktop 目前仍然依赖 APT 实现软件安装，那它的源应该仍然符合 Debian 的 APT Repository 目录结构。 根据 DebianWiki 中的描述 gives an example: 1deb https://deb.debian.org/debian stable main contrib non-free An archive can have either source packages or binary packages or both but they have to be specified separately to apt. The uri, in this case https://deb.debian.org/debian specifies the root of the archive. Often Debian archives are in the debian/ directory on the server but can be anywhere else (many mirrors for example have it in a pub/linux/debian directory, for example). The distribution part (stable in this case) specifies a subdirectory in $ARCHIVE_ROOT/dists. It can contain additional slashes to specify subdirectories nested deeper, eg. stable/updates. distribution typically corresponds to Suite or Codename specified in the Release files. FIXME is this enforced anyhow? To download packages from a repository apt would download an InRelease or Release file from the $ARCHIVE_ROOT/dists/$DISTRIBUTION directory. 我尝试了访问 https://pro-store-packages.uniontech.com/appstore/dists/eagle-pro/Release，获得了一系列索引文件的索引。 第一段中就能看到熟悉的 Packages 文件。根据我 deepin-elf-verify 相关博客中记载，这个文件中会保存 deb 文件的相对路径。我们先拼出 amd64 架构的 Packages 文件下载链接: https://pro-store-packages.uniontech.com/appstore/dists/eagle-pro/appstore/binary-amd64/Packages 这里可以看到源中每一个 deb 包的信息。图中红色方框框出的便是其中一个 deb 包在源中的相对路径。 我们可以使用 grep 命令去检索 weixin 或者 wechat 关键词 1curl -sL https://pro-store-packages.uniontech.com/appstore/dists/eagle-pro/appstore/binary-amd64/Packages | grep -E &quot;weixin|wechat&quot; 在这个路径前加上之前 appstore.list 文件中给出的 url 前缀，即可拼凑出 deb 包的完整下载地址: https://pro-store-packages.uniontech.com/appstore/pool/appstore/c/com.tencent.wechat/com.tencent.wechat_1.0.0.236_amd64.deb 放到浏览器中尝试，果然可以正常下载","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"deepin","slug":"deepin","permalink":"https://zhul.in/tags/deepin/"},{"name":"Apt","slug":"Apt","permalink":"https://zhul.in/tags/Apt/"}]},{"title":"在 Linux 下使用 mitmproxy 抓取 HTTPS 流量","slug":"capture-https-traffic-on-linux-with-mitmproxy","date":"2024-02-29T14:03:58.000Z","updated":"2024-09-19T20:28:28.000Z","comments":true,"path":"2024/02/29/capture-https-traffic-on-linux-with-mitmproxy/","link":"","permalink":"https://zhul.in/2024/02/29/capture-https-traffic-on-linux-with-mitmproxy/","excerpt":"","text":"作为部分 AUR Package 的 maintainer，一直以来我都有在 Linux 下抓取 https 流量的需求，比如抓取应用内的更新检测时访问的 url 地址。之前一直没有空去研究，趁着最近课少，总算是完成了这个目标。 在这里我使用的 mitmproxy，基于 python 和 webui 的一款开源简洁的流量代理软件，可以用于抓取 https 流量信息。 安装 mitmproxy在 Arch Linux 下，官方 extra 源中已经打包好了这款软件，直接使用下面的命令即可完成安装。 1sudo pacman -S mitmproxy 尝试运行 mitmweb安装完成后，我们将会获得三个新的命令可用： mitmdump mitmproxy mitmweb 我们只要使用 mitmweb 即可同时打开 8080 的代理端口和 8081 端口的 webui。访问 http://127.0.0.1:8081 即可看到 mitmproxy 的网页。 当然，也可以在 mitmweb 命令后面追加 -p 和 –web-port= 分别设置代理端口和 webui 的端口。 首先，我们先运行一次 mitmweb 安装 ca 证书为了解密 https 流量，我们需要为系统安装上 mitmproxy 自己的证书文件，让系统信任我们的证书。 先来看看 /usr/share/ca-certificates/trust-source/README 这个文件 1234567891011121314151617181920This directory /usr/share/ca-certificates/trust-source/ contains CA certificatesand trust settings in the PEM file format. The trust settings found here will beinterpreted with a low priority - lower than the ones found in /etc/ca-certificates/trust-source/ .=============================================================================QUICK HELP: To add a certificate in the simple PEM or DER file formats to the list of CAs trusted on the system: Copy it to the /usr/share/ca-certificates/trust-source/anchors/ subdirectory, and run the update-ca-trust command. If your certificate is in the extended BEGIN TRUSTED file format, then place it into the main trust-source/ directory instead.=============================================================================Please refer to the update-ca-trust(8) manual page for additional information. 这份文件告诉我们可以在 /usr/share/ca-certificates/trust-source/anchors/ 路径下放置 PEM 证书文件，并使用 update-ca-trust 命令更新系统的信任。 mitmproxy 软件第一次运行时，将会在当前用户的 $HOME/.mitmproxy/ 文件夹下生成证书，我们打开这个文件夹，发现一共有六个文件： mitmproxy-ca-cert.cer mitmproxy-ca-cert.p12 mitmproxy-ca-cert.pem mitmproxy-ca.p12 mitmproxy-ca.pem mitmproxy-dhparam.pem 我们这里需要将 mitmproxy-ca-cert.pem 文件复制到 /usr/share/ca-certificates/trust-source/anchors/ 路径下 1sudo cp $HOME/.mitmproxy/mitmproxy-ca-cert.pem /usr/share/ca-certificates/trust-source/anchors/ 随后执行 update-ca-trust 1sudo update-ca-trust 这样便完成了 ca 证书的安装 使目标软件使用 8080 端口通信其实我试过使用透明代理进行抓包，只不过我的 Archlinux 是作为日常主力机使用的，系统无时无刻不在向外通信，透明代理以后 mitmproxy 的 webui 各种刷屏，便放弃了这个想法，选择指定目标软件使用 8080 端口通信。 网上比较常见的做法是使用 proxychains-ng 代理目标软件。这个方案是可行的，只不过我这边测试下来，部分软件使用 proxychains 代理以后出现了仍然不使用代理、无法联网、甚至直接崩溃的情况。 因此我转向了 gg。gg 和 proxychains-ng 的定位相同，都是使目标命令通过指定的代理进行通信，只不过 gg 解决了部分 golang 编写的软件无法被 proxychains 代理的问题，并支持一些常见的用来国际联网的协议。 在不对 gg 进行配置的情况下，每次启动时，gg 都会要求我们输入代理地址，这正合我意。 此时，软件正常启动，流量全部经过 mitmproxy，可以在 webui 上看到具体情况 抓包成功 我们可以看到 mitmproxy 成功捕获并解密的 https 流量，针对图片等信息甚至可以直接实现预览。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"mitmproxy","slug":"mitmproxy","permalink":"https://zhul.in/tags/mitmproxy/"}]},{"title":"如何使用 docker 部署 onemanager","slug":"how-to-deploy-onemanager-with-docker","date":"2024-02-11T08:30:29.000Z","updated":"2024-09-20T20:44:48.000Z","comments":true,"path":"2024/02/11/how-to-deploy-onemanager-with-docker/","link":"","permalink":"https://zhul.in/2024/02/11/how-to-deploy-onemanager-with-docker/","excerpt":"","text":"部署方法如果你只是想找一个 OneManager-php 的 Docker 部署方法，直接看 https://github.com/zhullyb/OneManager-php-docker 一直以来，我都是 OneManager-php 的忠实用户。这些年来，尽管有 alist 这种 UI 好看，多种网盘高度聚合的项目逐渐取代了 onemanager 的生态位，但 onemanager 支持文件分片上传、上传流量不经服务器的特点还是让我非常满意。前一阵子，glitch 暂停了针对项目自定义域名的支持，因此在我手贱地取消了项目原本绑定的域名后，迫切地需要寻找一个新的部署的平台，只不过 onemanager 项目现在列出的方案都不太让我满意，因此我就萌生出了在 vps 上自己部署的想法。 Docker 镜像选用vps 上自己部署 php 项目，最简单的方法是使用 Docker，使用 Docker 就可以免去配置 nginx 或者同类产品的 php-fpm 配置才怪。我打开 Docker 提供的 php 官方镜像，最小的镜像是带-cli后缀的，这个镜像就不适合进行部署，php 内置的开发服务器是单线程的，当同时打开两个网页访问开发服务器的时候，其中一个网页就会卡住；以-fpm结尾的镜像变体很明显，仍然需要去 nginx 或同类产品的配置文件那边去配置 fpm，这给部署了好几次 php 项目的我带来的心理阴影；剩下一个就是-apache后缀、使用 apache server 提供 php 服务的镜像，体积虽然大了点，但好在操作简单，只需要将 php 文件放进 /var/www/html，启用 php 的相关拓展，启用 apache 的相关功能即可。 php 拓展php 的拓展可以使用镜像自带的 docker-php-ext-install 和 docker-php-ext-enable 命令进行操作，此外还有一个 docker-php-ext-configure 命令可以配置相关的拓展，不过我并不是 php 开发者，不熟悉拓展有什么好配置的。 OneManager-php 没有依赖任何的 php 拓展，因此这个步骤可以直接跳过。 Apache Server 配置和 php 拓展一样，镜像内也提供了几个命令进行 Apache Server 的配置，分别为 a2disconf、a2dismod、a2dissite、a2enconf、a2enmod、a2ensite、a2ensite。 OneManager-php 在部署的时候依赖于 Apache Server 的 rewrite 的模块，因此在 Dockerfile 中需要使用 a2enmod rewrite 开启 rewrite 支持。至于别的 Apache Server 配置，都可以通过项目中的 .htaccess 文件进行配置。 .htaccess 文件纠错在 OneManager-php 仓库中，.htaccess 文件有一些小问题。 1RewriteRule ^(.*) index.php?/$1 [L] 这行配置原本是将访问的路径追加到 index.php?/ 后面的意思，但 一旦路径中出现了 [、] 或者空格等字符时，会触发 Apache 自带的保护，因此我们将这行改成下面这个样子即可。 1RewriteRule ^(.*) index.php [QSA,L] 原项目合并了我的 PR，因此这一过程不再需要。 处理文件权限问题OneManager-php 在运行过程中，会有针对配置文件的读写操作，此外还内置了一键更新的功能，因此会对路径内的文件进行读写，我们需要确保 php 在运行过程中有权限对这些文件进行读写。 可以直接将 /var/www/html 路径的所有权转给 www-data 用户。 1chown -R www-data:www-data /var/www/html 最终的 Dockerfile1234FROM php:8-apacheRUN a2enmod rewriteCOPY OneManager-php /var/www/htmlRUN chown -R www-data:www-data /var/www/html 其实一共就 4 行，还是挺简单的。","categories":[],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://zhul.in/tags/PHP/"},{"name":"OpenSource Project","slug":"OpenSource-Project","permalink":"https://zhul.in/tags/OpenSource-Project/"},{"name":"OneDrive","slug":"OneDrive","permalink":"https://zhul.in/tags/OneDrive/"},{"name":"Docker","slug":"Docker","permalink":"https://zhul.in/tags/Docker/"}]},{"title":"crontab 中简单的@语法糖","slug":"extra-usage-for-crontab","date":"2024-02-08T09:21:31.000Z","updated":"2024-02-08T10:21:51.000Z","comments":true,"path":"2024/02/08/extra-usage-for-crontab/","link":"","permalink":"https://zhul.in/2024/02/08/extra-usage-for-crontab/","excerpt":"","text":"说来惭愧，其实我用了这么久的 Linux，一直没有学会编写 crontab 脚本。一行的开头写上五位莫名其妙的数字或星号，后面跟上需要执行的命令，看上去很 kiss，但我确实记不住，以至于我现在每次写 crontab 都是让 ChatGPT 来帮我写。 不过我最近查阅 Linux 下设置开机自启脚本的方案的时候，意外地看到 crontab 中居然可以用 @reboot command 的方式去写，这让我意识到 crontab 也是有一些简单的语法糖的。在查阅了 crontab 的 manual 后，我发现一共有下面这么几种 @ 写法的语法糖。这是在全网大部分的 crontab 中文教程中是没有的。 语法糖 执行条件 等效表达式 @reboot 开机时候运行 @yearly 一年一次 0 0 1 1 * @annually 一年一次 0 0 1 1 * @monthly 一月一次 0 0 1 * * @weekly 一周一次 0 0 * * 0 @daily 一天一次 0 0 * * * @hourly 一小时一次 0 * * * * 这几个简单的语法糖可以满足大部分 crontab 的情况，免去了对使用者学习并记忆 crontab 的表达式的要求。 比如说，如果我希望我的系统在每次开机时都用 TG Bot 发送一条上线信息，那就是 1@reboot curl -s -X POST https://api.telegram.org/bot&#123;id&#125;:&#123;apikey&#125;/sendMessage -d chat_id=&#123;uid&#125; -d text=&quot;`date`&quot;","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"crontab","slug":"crontab","permalink":"https://zhul.in/tags/crontab/"}]},{"title":"备份 umami 数据库，并使用 TG Bot 保存 dump 文件","slug":"backup-umami-database-and-send-it-by-tg-bot","date":"2024-01-31T16:00:01.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/02/01/backup-umami-database-and-send-it-by-tg-bot/","link":"","permalink":"https://zhul.in/2024/02/01/backup-umami-database-and-send-it-by-tg-bot/","excerpt":"","text":"前一阵子看到点墨的博客「定时备份mysql/mariadb数据库并上传至tgbot」，我意识到个人站点的数据库 dump 使用 TG Bot 存放是一个非常合适的做法。个人站点的数据库体积本身就不大，TG Bot 又有官方提供的 api，非常适合自动化任务。我就寻思着给我的 umami 数据库也写个定时任务备份一下，也不至于之前做一次迁移数据全部爆炸的悲剧重演。 我的 umami 是「使用 vercel+supabase 免费部署 umami」部署出来的，数据库在 supabase 上，因此我们先打开 supabase 的 dashboard，获取到数据库的 url。 密码我自然是不记得了，不过好在 Firefox 的密码管理器帮我记住了，直接去设置里就能找到。即使密码忘了也不要紧，往下翻有重置密码的按钮。 随后就要开始编写我们的教本了，这是我的 1234567891011#!/bin/bashDATABASE_URL=&quot;postgres://&quot;DATE=$(date &#x27;+%F&#x27;)TG_BOT_TOKEN=&#x27;1145141919:ABCDEFGHIJKLVMNOPQRSTUVWXYZabcdefgh&#x27;TG_CHAT_ID=&#x27;9191415411&#x27;pg_dump $&#123;DATABASE_URL&#125; &gt; umami_dump_$&#123;DATE&#125;.sqlcurl -F document=@umami_dump_$&#123;DATE&#125;.sql https://api.telegram.org/bot$&#123;TG_BOT_TOKEN&#125;/sendDocument?chat_id=$&#123;TG_CHAT_ID&#125;rm umami_dump_$&#123;DATE&#125;.sql 将这段代码保存为 umami_db_dumper.sh，随后 chmod +x ./umami_db_dumper.sh 授予可执行权限。 可以先在命令行中执行命令试一下这段脚本是否正常工作 1./umami_db_dumper.sh 这段代码在我本机正常工作，可惜在我的 Ubuntu VPS 上报错 12pg_dump: error: server version: 14.1; pg_dump version: 12.17 (Ubuntu 12.17-0ubuntu0.20.04.1)pg_dump: error: aborting because of server version mismatch 看上去是 VPS 上的 PostgreSQL 版本过低，Google 搜索一顿后，我在一篇「Upgrade pg_dump version in ubuntu | by Anushareddy」 文章中找到了方案，添加 PostgreSQL 官方提供的 apt 源将 VPS 上的 PostgreSQL 更新到新版即可解决。 1234wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | apt-key add -echo &quot;deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release -cs)-pgdg main&quot; &gt; /etc/apt/sources.list.d/pgdg.listapt updateapt install postgresql-client 确保脚本正常工作后，使用 crontab -e 设置自动任务 10 2 * * * /root/umami_db_dumper.sh","categories":[],"tags":[{"name":"Bot","slug":"Bot","permalink":"https://zhul.in/tags/Bot/"},{"name":"umami","slug":"umami","permalink":"https://zhul.in/tags/umami/"},{"name":"Shell Script","slug":"Shell-Script","permalink":"https://zhul.in/tags/Shell-Script/"}]},{"title":"在 JavaScript 中，箭头函数中的 this 指针到底指向哪里？","slug":"where-does-this-refer-in-arrow-function-in-js","date":"2024-01-13T18:50:03.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/01/14/where-does-this-refer-in-arrow-function-in-js/","link":"","permalink":"https://zhul.in/2024/01/14/where-does-this-refer-in-arrow-function-in-js/","excerpt":"","text":"这学期期末复习的时候，学校里负责上 JavaScript 的老师给我们提出了一个问题。下面这段代码中，a.u2() 在 ES Module 下执行会抛出 TypeError 的异常，在 CommonJS 下运行则会输出 undefined，而 B 这个类的 u2 函数则能够在对象实例化以后正常运行。 12345678910111213141516171819202122232425262728293031const a = &#123; x: 3, u1: function () &#123; console.log(this.x) &#125;, u2: () =&gt; &#123; console.log(this.x) &#125;&#125;class b &#123; x = 3 u1 = function () &#123; console.log(this.x) &#125; u2 = () =&gt; &#123; console.log(this.x) &#125;&#125;a.u1()// 3a.u2()// undefinednew b().u1()// 3new b().u2()// 3 这个问题涉及到 JavaScript 中箭头函数的作用域以及 this 指向。 在 JS 中使用 function 关键字定义的普通函数中，this 指针遵循一个规则：谁调用指向谁。即 obj.func() 这种调用情况下，func 方法内部的this指向obj；如果没有调用者，则严格模式下 this 为 undefined，非严格模式下 this 指向window(浏览器)或者global(node环境)。 而箭头函数比较特殊，箭头函数的 this 在定义时就被绑定，绑定的是定义时所在作用域中的 this。 在老师给的示例代码中，第一行定义了 a 这个对象字面量，而定义对象字面量不会创建新的作用域，因此 a 中定义的 u2 的 this 指向的是全局对象。因此在 Es Module 默认启用 strict mode 的情况下，全局对象的 this 指向 undefined，进而导致 a 的 u2 内 this 也指向 undefined，this.x 就抛了 TypeError；而在 CommonJS 未启用 strict mode 的情况下，全局对象的 this 指向全局对象，因而 u2 内的 this 也指向全局对象，因此 this 存在，this.x 就不会抛 TypeError，只会报 undefined。 而 B 类在对象初始化阶段拥有一个新的作用域，因此箭头函数的 this 能够正确指向 B 被实例化出来的对象，因此也就能够正确读取到 this.x 的值。 理论上来说，我们可以给全局对象也赋一个不一样的 x 值，这样 a.u2() 就能够读取到全局对象中的 x 值，验证我们的结论。 在浏览器中，可以在代码的头部加一行 var x = 10 或者 window.x = 10，可以看到a.u2() 顺利的输出了 10，验证了我的结论。 但在 Node.js 中，直接使用 var x = 10 或者 global.x = 10 并不能达到我们想要的效果。因为Node.js 中的每个 CommonJS 模块都有其自己的模块作用域，即模块的顶层作用域不是全局作用域。在模块内部，this 关键字不是指向 global 对象，而是指向模块的导出对象。这是为了确保模块内部的作用域隔离和模块的封装性。 那么我们可以通过为模块的导出对象添加一个 x 属性来验证我们的结论，我们可以使用 exports.x = 10 来为模块的顶层作用域添加一个值为 10 的 x 属性。 参考文章箭头函数表达式 - JavaScript | MDN ES6箭头函数作用域的问题 ES6箭头函数的this指向详解","categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://zhul.in/tags/JavaScript/"}]},{"title":"结合 Vue.js 与 php 完成的 web 期末大作业，讲讲前后端分离站点开发与部署中可能遇到的 CORS 跨域问题","slug":"cors-when-using-splited-frontend-and-backend","date":"2024-01-10T15:55:36.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2024/01/10/cors-when-using-splited-frontend-and-backend/","link":"","permalink":"https://zhul.in/2024/01/10/cors-when-using-splited-frontend-and-backend/","excerpt":"","text":"在上一篇博客中，我讲到了 web 期末大作业的上云部署。整个项目是使用 Vue.js 作为前端，php 作为后端，mysql 作为数据库实现的。 在使用 Vue.js 开发前端界面时，我选择了使用 vite 脚手架帮助开发，这意味着我的作品将使用前后端分离的架构实现。因此在开发部署过程中均遇到了跨域的问题，故写下这篇博客记录下解决方案。 基于后端返回对应 http 响应头的解决方案开发阶段在我完成前后端的开发，并且经过 Apifox 的 mock 测试后，第一次在浏览器尝试前后端对接，遇到了 CORS Missing Allow Origin 的报错。 vite 启动的 dev 开发服务器使用的域是 http://localhost:5173 ，而 php 后端我指定的是 http://127.0.0.1:8080 ，前后端并不运行在一个域下，前端使用 Axios(AJAX) 向后端发送请求获取资源输入 CORS 跨域资源共享的范畴。 关于跨域资源共享 CORS 的相关内容，阮一峰老师在 2016 年就已经在他的博客中有过解释，看了下也是全网中文内容中解释得比较通俗易懂的，因此本文在这方面不过多做解释。错误的提示信息是 Missing Allow Origin，结合阮一峰老师的博文，我们应该在后端向前端发送的 http 响应头中添加 Access-Control-Allow-Origin 这一字段。 在一般的前后端分离项目（不涉及 cookie 等 Credentials 属性）中，我们可以将这一字段设置为 * 通配符，默认允许所有的域向自己发起跨域资源请求。php 可以通过下面这行代码很方便地进行设置: 1header(&#x27;Access-Control-Allow-Origin: *&#x27;); 但在用户的注册登录方面，我使用了 session 作为用户的登录凭据。阮一峰老师关于 CORS 的博文中有这样一句话: 需要注意的是，如果要发送Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传，且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。 因此，我们必须明确指定 Access-Control-Allow-Origin 字段为前端所使用的域，写上 http://localhost:5173 才行。 1header(&#x27;Access-Control-Allow-Origin: http://localhost:5173&#x27;); 再次刷新网页，获得了新的错误 CORS Missing Allow Credentials 这个问题处理起来也简单 1header(&#x27;Access-Control-Allow-Credentials: true&#x27;); 再次运行网页，跨域问题成功解决。 部署阶段顺着这个思路进行下去，我们在部署阶段解决跨域问题需要做的事情很简单。提前将前端部署起来，将前端的域写到后端返回给前端的 http 相应头中即可。需要注意的是，Access-Control-Allow-Origin 字段仅允许填写一个值，如果需要同时允许来自多个不同域的跨域资源共享，后端部分需要根据前端发来的请求头中的 Origin 字段相应地设置响应头中的 Access-Control-Allow-Origin 。当然，nginx 等先进的 static server 也支持劫持 http 请求，添加相关的 Access-Control 语句，也可以在这一层解决这个问题。 直接规避跨域的方案上面通过后端返回带有 Access-Control 语句相应头的解决方案确实可以解决问题，却显得不够优雅。开发和部署阶段都要手动的去指定前端的域来允许跨域资源共享，这一点过于麻烦了，因此引出了下面的解决方案。 开发阶段在 vite（或者其他同类开发服务器）的帮助下，我们可以使用前端的开发服务器去反向代理后端服务，也就是让前端的请求打到前端服务器上，由前端服务器去返回后端服务器返回的结果。 在 vite.config.ts 配置文件下，我将原本的 123export default defineConfig(&#123; plugins: [vue()],&#125;) 换成了 1234567891011121314151617export default () =&gt; &#123; process.env = &#123; ...process.env, ...loadEnv(process.cwd(),&#x27;&#x27;) &#125;; const config = &#123; plugins: [vue()], server: &#123; proxy: &#123; &#x27;/api&#x27;: &#123; target: http://127.0.0.1:8080, changeOrigin: true, secure: false, &#125; &#125; &#125; &#125; return defineConfig(config)&#125;; 同时将 Axios create 时的 baseURL 参数去除。 这样一套组合拳下来，将所有打向 /api* 的请求和响应通过前端的开发服务器作为中介做了中转，让浏览器以为并没有跨域（事实上也没有跨域），从而解决了相关的问题。 部署阶段在开发阶段，我们通过 vite 的开发服务器做反向代理规避了跨域请求，但在部署阶段就用不了了。由于 vite 服务器的性能太弱，一般情况下我们是不会在生产环境中使用 vite 作为正式的服务器的，而是使用 vite build 出网站的静态网页资源，通过 nginx 等 static server 去向用户提供前端网页。而通过 vite build 出来的静态网页资源本身是不具备反向代理的能力的，这意味着没法在前端侧规避跨域问题。此时，我们应该配置 nginx 规避跨域问题。我一向不怎么使用 nginx，使用的是它的平替品 caddy，因此 nginx 的配置文件需要大家自行搜索，我的 caddyfile 在上一篇博客中已经给出，仅供参考。","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Vue.js","slug":"Vue-js","permalink":"https://zhul.in/tags/Vue-js/"},{"name":"PHP","slug":"PHP","permalink":"https://zhul.in/tags/PHP/"}]},{"title":"vuejs、php、caddy 与 docker —— web 期末大作业上云部署","slug":"php-and-vuejs-project-deploy-on-caddy","date":"2023-12-27T14:09:00.000Z","updated":"2024-09-20T20:44:48.000Z","comments":true,"path":"2023/12/27/php-and-vuejs-project-deploy-on-caddy/","link":"","permalink":"https://zhul.in/2023/12/27/php-and-vuejs-project-deploy-on-caddy/","excerpt":"","text":"这学期修了一门叫《用HTML5 和 PHP编写JavaScript，jQuery 和 AJAX脚本》的 web 课（对，听起来很奇怪的名字）。期末大作业是写一个影评系统，前端允许使用框架，后端仅允许使用 php，具体的作业要求如下 （源码会在验收结束以后开源） 大作业写了得要有三个礼拜，工作时长加起来得有 30 个小时，想着验收之前上线一段时间积累一些评论数据，验收的时候也会更加顺利一些，于是就开始尝试在服务器上部署。部署的过程还是比较复杂的，所以写下这篇博客记录一下。 后端部分早前有《PicUploader使用系列（一）——在Archlinux上使用Caddy部署PicUploader》的经验，便觉得使用 Caddy + php-fpm 部署的方式多少有点麻烦了，这次便尝试了使用 Docker 部署、Caddy 反代的方式。 Dockerfile 如下: 12345FROM php:8-apacheRUN docker-php-ext-install mysqliRUN a2enmod rewriteCOPY . /var/www/htmlEXPOSE 80 在后端的根目录下有一个 .htaccess 文件，将所有的请求都交给 index.php 来处理，这样就可以根据我的上一篇博客中所提到的方式去构建不使用任何 php 框架实现的简易 router 效果 12RewriteEngine OnRewriteRule ^(.*) index.php [QSA,L] 构建 Docker 镜像时使用 docker build . -t mrs-php 命令，运行 docker 容器时使用命令 123456docker run -d \\ -p 7788:80 \\ --name mrs-php \\ -v /path/to/uploads:/var/www/html/uploads \\ --restart unless-stopped \\ mrs-php 这样，后端就在 7788 端口上开起来了，后续 Caddy 只要将打到 /api/* 和 /uploads/* 的请求转发到 7788 端口即可，避免了使用 php-fpm 时需要的配置。uploads 目录是用来存放图片的，我将这个路径挂在在宿主机的目录下，方便备份导入等操作。 mysql 连接时的小插曲需要注意的是，在 Docker 容器中运行的 php 如果想要访问宿主机上的 mysql，需要注意修改 mysql 服务器的 ip 地址，并允许 mysql 接收来自非本机的请求。 在宿主机中运行 ip -br a 命令可以看到 docker 所采用的虚拟网卡的 ip 地址 1docker0 UP 172.17.0.1/16 fe80::42:eff:febf:b26c/64 我这边得到的 ip 地址是 172.17.0.1，所以在 php 那边访问的数据库 ip 地址就应该是 172.17.0.1，而非 localhost 或者 127.0.0.1 此外，需要允许宿主机的 mysql 接收来自 Docker 容器的请求 使用 docker network inspect bridge 命令可以查到 docker 容器的 ip 地址，接着需要去允许来自这个 ip 的请求。建议去网上自行搜索，因为 mysql 语句我自己也不熟悉。我使用的 mysql 版本是 8，语句似乎和以前的版本不兼容？我使用下面三个命令轮着输就好了（有时候报错，有时侯又不报错），有大佬懂的话评论区讲讲。 1234use mysql;GRANT ALL ON *.* TO &#x27;root&#x27;@&#x27;%&#x27;;update user set host=&#x27;%&#x27; where user=&#x27;root&#x27;;GRANT ALL ON *.* TO &#x27;root&#x27;@&#x27;%&#x27;; 前端部分前端部分部署起来没什么难度 我使用的是 vite 开发的 vuejs 项目，直接使用 pnpm build 构建出静态文件，然后放入了 /var/www/mrs 目录，这部分没什么可说的 Caddy 配置Caddy 配置如下 123456789101112131415example.com &#123; handle /api/* &#123; reverse_proxy localhost:7788 &#125; handle /uploads/* &#123; reverse_proxy localhost:7788 &#125; handle /* &#123; root * /var/www/mrs file_server try_files &#123;path&#125; / &#125;&#125; 将打到 /api/* 和 /uploads/* 都交给 7788 端口的后端进行处理，前端部分要使用 try_files 将请求都指向 / 或 /index.html 交由 vue-router 处理，否则 caddy 就找不到对应的文件了。这里我尝试过使用 route 关键词代替 handle，但 try_files 的功能没有生效，这两者的区别官方文档中有提到，但我没看懂，等我以后看看有没有机会去折腾了。 参考:使用Caddy配置同一域名下的前后分离 Caddy 2","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Vue.js","slug":"Vue-js","permalink":"https://zhul.in/tags/Vue-js/"},{"name":"PHP","slug":"PHP","permalink":"https://zhul.in/tags/PHP/"},{"name":"Caddy","slug":"Caddy","permalink":"https://zhul.in/tags/Caddy/"},{"name":"Docker","slug":"Docker","permalink":"https://zhul.in/tags/Docker/"}]},{"title":"【翻译】使用 PHP 构建简单的 REST API","slug":"php-simple-rest-api","date":"2023-12-12T05:07:32.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2023/12/12/php-simple-rest-api/","link":"","permalink":"https://zhul.in/2023/12/12/php-simple-rest-api/","excerpt":"","text":"我这学期有一门偏向前端的 WEB 课程，期末大作业要求使用 PHP 作为后端语言实现一个简单的影评系统，应该是不允许使用框架，使用中文关键字在搜索引擎上搜了一阵子似乎没有可供参考的案例，后来就找到了这篇博客，当中的许多观点与我不谋而合，因此我将这篇博客翻译成中文，原文戳这里: https://amirkamizi.com/blog/php-simple-rest-api 介绍上周 @rapid_api 发了一个非常好的关于使用 nodejs 和 express 创建 REST API 的教程帖子。我想要帮助你使用 PHP 开发同样简单的 REST API。 首先，如果你不了解 REST API，请务必查看这个 Twitter 帖子。 目标在我们开始之前，我想提一句，当我写这篇帖子的时候，我想确保： 我使用单纯的 PHP，不使用框架 我使用最简单的函数和结构体以便所有人都可以理解并跟上 我将主体部分分开 现在让我们开始吧 准备在我本地的机器上，我创建了一个叫 api 的文件夹于 xampp &gt; htdocs，在里面有一个叫 index.php 的文件 如果你没有 xampp 或者你不知道如何把 php 跑起来，请务必查看这篇文章 现在，如果你尝试访问 localhost/api，你将得到一个空的响应，因为 index.php 文件是空的 优雅的 URL项目中，我们需要处理的第一件事是 url REST API 的关键特性之一是每一个 url 负责一个资源和一个操作 问题这时候如果我创建一个 users.php，我需要访问 1localhost/api/users.php 我需要为每一个 user id 创建一个新的文件 12localhost/api/users/1.phplocalhost/api/users/2.php 以此类推。 这种方案有两个问题 为每个用户创建一个新文件是非常无聊和耗时的 路由不优雅，每个路径后面都带有 .php 解决方案让我们解决这个问题。 正如我所提到的，我不想使用任何框架，并且我想使用最简单的、最让人能够理解的方案 让我们看看如何解决这个问题 在 api 文件夹下创建一个叫 .htaccess 的文件，并且将下面的文本复制进去 12345RewriteEngine OnRewriteBase /apiRewriteCond %&#123;REQUEST_FILENAME&#125; !-dRewriteCond %&#123;REQUEST_FILENAME&#125; !-fRewriteRule ^(.+)$ index.php [QSA,L] 我们告诉服务器，将所有指向 /api 的请求都转发到 index.php 文件 现在，所有的 url 都指向 index.php 了，比如下面的 url 都是指向 index.php 的 123api/usersapi/users/10api/users/5 现在我们同时解决了这两个问题 所有的 url 都被一个文件处理 url 都很优雅，结尾处没有 .php URI但如何知道用户请求的是哪个 uri 呢？ 很简单，使用 $_SERVER 超全局变量 让我们来看一些例子 1234567891011// url api/usersecho $_SERVER[&#x27;REQUEST_URI&#x27;];// /api/users// url api/users/5echo $_SERVER[&#x27;REQUEST_URI&#x27;];// /api/users/5// url apiecho $_SERVER[&#x27;REQUEST_URI&#x27;];// /api 看见了吗？这就是我们所需要的 现在，使用一个简单的 if 或者 switch 语句，我们就可以处理不同的路径了 如果你从来没有用过这些语句，去读这篇文章。 请求方法接下来，我们需要从请求中获取请求的方法，以查看它是GET、POST、PUT、PATCH还是DELETE。 你可以从 $_SERVER 超全局数组中获取这个信息。 1$_SERVER[&#x27;REQUEST_METHOD&#x27;] 让我们将这两个值存储在变量中： 12$uri = $_SERVER[&#x27;REQUEST_URI&#x27;];$method = $_SERVER[&#x27;REQUEST_METHOD&#x27;]; 我们可以在一个简单的 switch 语句中使用这两个变量来处理不同的请求。 我们需要判断以下请求 api/users 的 GET 请求 api/users/{id} 的 GET 请求 api/users 的 POST 请求 api/users/{id} 的 PUT 请求 api/users/{id} 的 DELETE 请求 让我们编写针对上述请求的 switch 语句 123456789101112131415161718192021222324252627282930313233343536373839switch ($method | $uri) &#123; /* * Path: GET /api/users * Task: show all the users */ case ($method == &#x27;GET&#x27; &amp;&amp; $uri == &#x27;/api/users&#x27;): break; /* * Path: GET /api/users/&#123;id&#125; * Task: get one user */ case ($method == &#x27;GET&#x27; &amp;&amp; preg_match(&#x27;/\\/api\\/users\\/[1-9]/&#x27;, $uri)): break; /* * Path: POST /api/users * Task: store one user */ case ($method == &#x27;POST&#x27; &amp;&amp; $uri == &#x27;/api/users&#x27;): break; /* * Path: PUT /api/users/&#123;id&#125; * Task: update one user */ case ($method == &#x27;PUT&#x27; &amp;&amp; preg_match(&#x27;/\\/api\\/users\\/[1-9]/&#x27;, $uri)): break; /* * Path: DELETE /api/users/&#123;id&#125; * Task: delete one user */ case ($method == &#x27;DELETE&#x27; &amp;&amp; preg_match(&#x27;/\\/api\\/users\\/[1-9]/&#x27;, $uri)): break; /* * Path: ? * Task: this path doesn&#x27;t match any of the defined paths * throw an error */ default: break;&#125; 当我们想要在 switch 语句中使用两个变量，我们可以使用 | 符号 如果你想知道 preg_match 是如何工作的，看这篇文章。 数据库现在是说说数据。储存数据的最好方法是将数据储存在数据库中。但在这篇教程中，我不想使用数据库。因此，我们使用一个 json 文件当作数据库来保证数据的持久性。 我的 json 文件看起来长成这个样子： 1234&#123; &quot;1&quot;: &quot;Pratham&quot;, &quot;2&quot;: &quot;Amir&quot;&#125; 如果你想知道如何使用 json，看这篇文章 我加载 json 数据并将其转换为数组，然后在 php 使用他们。如果我想要更改数据，我将数组转换回 json 并将其重新写入文件。 要将整个文件作为一个字符串读取并存储在变量中，我使用： 1file_get_contents($jsonFile); 而要将json写入文件，我使用： 1file_put_contents($jsonFile, $data); 好了，现在我们的数据库处理好了，让我们开始处理所有的路径。 我使用 Postman 发送请求并查看响应。 获取所有用户1234case ($method == &#x27;GET&#x27; &amp;&amp; $uri == &#x27;/api/users&#x27;): header(&#x27;Content-Type: application/json&#x27;); echo json_encode($users, JSON_PRETTY_PRINT); break; 获取单个用户123456789101112case ($method == &#x27;GET&#x27; &amp;&amp; preg_match(&#x27;/\\/api\\/users\\/[1-9]/&#x27;, $uri)): header(&#x27;Content-Type: application/json&#x27;); // get the id $id = basename($uri); if (!array_key_exists($id, $users)) &#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;user does not exist&#x27;]); break; &#125; $responseData = [$id =&gt; $users[$id]]; echo json_encode($responseData, JSON_PRETTY_PRINT); break; basename($uri) 会将 uri 的最后一部分给我。比如一个 api/users/10 这样的路径，它会返回 10. 然后我使用 array_key_exists 检查是否存在一个 id 为 10 的用户 添加一个新用户12345678910111213case ($method == &#x27;POST&#x27; &amp;&amp; $uri == &#x27;/api/users&#x27;): header(&#x27;Content-Type: application/json&#x27;); $requestBody = json_decode(file_get_contents(&#x27;php://input&#x27;), true); $name = $requestBody[&#x27;name&#x27;]; if (empty($name)) &#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;Please add name of the user&#x27;]); &#125; $users[] = $name; $data = json_encode($users, JSON_PRETTY_PRINT); file_put_contents($jsonFile, $data); echo json_encode([&#x27;message&#x27; =&gt; &#x27;user added successfully&#x27;]); break; 我使用 file_get_contents(‘php://input’) 以获取请求的 body 部分。由于在这个例子中我使用的是 json，我将会解码 json 以便我可以获取到名字。 更新一个用户1234567891011121314151617181920case ($method == &#x27;PUT&#x27; &amp;&amp; preg_match(&#x27;/\\/api\\/users\\/[1-9]/&#x27;, $uri)): header(&#x27;Content-Type: application/json&#x27;); // get the id $id = basename($uri); if (!array_key_exists($id, $users)) &#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;user does not exist&#x27;]); break; &#125; $requestBody = json_decode(file_get_contents(&#x27;php://input&#x27;), true); $name = $requestBody[&#x27;name&#x27;]; if (empty($name)) &#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;Please add name of the user&#x27;]); &#125; $users[$id] = $name; $data = json_encode($users, JSON_PRETTY_PRINT); file_put_contents($jsonFile, $data); echo json_encode([&#x27;message&#x27; =&gt; &#x27;user updated successfully&#x27;]); break; 删除一个用户1234567891011121314case ($method == &#x27;DELETE&#x27; &amp;&amp; preg_match(&#x27;/\\/api\\/users\\/[1-9]/&#x27;, $uri)): header(&#x27;Content-Type: application/json&#x27;); // get the id $id = basename($uri); if (empty($users[$id])) &#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;user does not exist&#x27;]); break; &#125; unset($users[$id]); $data = json_encode($users, JSON_PRETTY_PRINT); file_put_contents($jsonFile, $data); echo json_encode([&#x27;message&#x27; =&gt; &#x27;user deleted successfully&#x27;]); break; 最终文件现在我们的 index.php 文件看起来是这样的 在 70 行左右的代码中，我们使用 PHP 创建了一个 RESTful API，很神奇吧？ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?php$jsonFile = &#x27;users.json&#x27;;$data = file_get_contents($jsonFile);$users = json_decode($data, true);$uri = $_SERVER[&#x27;REQUEST_URI&#x27;];$method = $_SERVER[&#x27;REQUEST_METHOD&#x27;];switch ($method | $uri) &#123; case ($method == &#x27;GET&#x27; &amp;&amp; $uri == &#x27;/api/users&#x27;): header(&#x27;Content-Type: application/json&#x27;); echo json_encode($users, JSON_PRETTY_PRINT); break; case ($method == &#x27;GET&#x27; &amp;&amp; preg_match(&#x27;/\\/api\\/users\\/[1-9]/&#x27;, $uri)): header(&#x27;Content-Type: application/json&#x27;); $id = basename($uri); if (!array_key_exists($id, $users)) &#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;user does not exist&#x27;]); break; &#125; $responseData = [$id =&gt; $users[$id]]; echo json_encode($responseData, JSON_PRETTY_PRINT); break; case ($method == &#x27;POST&#x27; &amp;&amp; $uri == &#x27;/api/users&#x27;): header(&#x27;Content-Type: application/json&#x27;); $requestBody = json_decode(file_get_contents(&#x27;php://input&#x27;), true); $name = $requestBody[&#x27;name&#x27;]; if (empty($name)) &#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;Please add name of the user&#x27;]); &#125; $users[] = $name; $data = json_encode($users, JSON_PRETTY_PRINT); file_put_contents($jsonFile, $data); echo json_encode([&#x27;message&#x27; =&gt; &#x27;user added successfully&#x27;]); break; case ($method == &#x27;PUT&#x27; &amp;&amp; preg_match(&#x27;/\\/api\\/users\\/[1-9]/&#x27;, $uri)): header(&#x27;Content-Type: application/json&#x27;); $id = basename($uri); if (!array_key_exists($id, $users)) &#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;user does not exist&#x27;]); break; &#125; $requestBody = json_decode(file_get_contents(&#x27;php://input&#x27;), true); $name = $requestBody[&#x27;name&#x27;]; if (empty($name)) &#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;Please add name of the user&#x27;]); &#125; $users[$id] = $name; $data = json_encode($users, JSON_PRETTY_PRINT); file_put_contents($jsonFile, $data); echo json_encode([&#x27;message&#x27; =&gt; &#x27;user updated successfully&#x27;]); break; case ($method == &#x27;DELETE&#x27; &amp;&amp; preg_match(&#x27;/\\/api\\/users\\/[1-9]/&#x27;, $uri)): header(&#x27;Content-Type: application/json&#x27;); $id = basename($uri); if (empty($users[$id])) &#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;user does not exist&#x27;]); break; &#125; unset($users[$id]); $data = json_encode($users, JSON_PRETTY_PRINT); file_put_contents($jsonFile, $data); echo json_encode([&#x27;message&#x27; =&gt; &#x27;user deleted successfully&#x27;]); break; default: http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &quot;We cannot find what you&#x27;re looking for.&quot;]); break;&#125; 额外内容在这种情况下，我不希望删除我的所有用户，所以我加了一个新的语句，如果只剩下最后一个用户，它将不会被删除，像这样 12345if (sizeof($users) == 1)&#123; http_response_code(404); echo json_encode([&#x27;error&#x27; =&gt; &#x27;there is only one user left. you cannot delete it!&#x27;]); break;&#125; 源码你可以在原作者的 github 上看到完整注释的源代码以及 post man 集合 总结现在你知道如何在 PHP 中创建一个简单的 RESTful API。 我推荐你打开一个 PHP 文件并复习所有的这些我们进行的步骤，并且像本文一样添加一些额外的资源 如果你有任何的建议、问题或者观点，请联系文章原作者，他期待着听到你的声音。 要点 不使用框架，用 PHP 创建一个 RESTful API 在 PHP 中使用优雅的 URL 处理请求的 body 使用 Json 文件作为你的数据库 使用多个变量作为 switch 的关键词","categories":[],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://zhul.in/tags/%E7%BF%BB%E8%AF%91/"},{"name":"PHP","slug":"PHP","permalink":"https://zhul.in/tags/PHP/"}]},{"title":"在 Hexo Fluid 主题中使用霞鹜文楷","slug":"use-lxgw-wenkai-in-hexo-fluid","date":"2023-11-27T16:16:23.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2023/11/28/use-lxgw-wenkai-in-hexo-fluid/","link":"","permalink":"https://zhul.in/2023/11/28/use-lxgw-wenkai-in-hexo-fluid/","excerpt":"","text":"我的博客换到 fluid 主题已经有两年了，期间一直有为博客更换字体的想法，但之前没有前端开发的相关知识支撑我换字体的需求。不过现在，我已经有了一些 Vue.js 的开发经验，相信能支撑我完成这个目标。 我在谷歌搜索到了这篇文章——《Hexo博客Fluid主题，字体全局更改为霞鹜文楷体》。 文章中直接修改了 themes/fluid/layout/_partial/head.ejs 让文章生成时在 html 的 head 标签中引入 lxgw-wenkai-screen-webfont 的 css 文件，并使用自定义 css 方案。但这种方案我不喜欢，我的 fluid 主题是通过 npm 安装 hexo-theme-fluid 的方式引入的，这意味着我不能直接编辑 themes/fluid 下的文件，包括文章中需要编辑的 head.ejs 和 _config.yml 。 我翻阅了 lxgw-wenkai-webfont 的 README，找到了使用 cdn 引入的方式。我们需要在 html 的 head 标签中加上下面这段: 1&lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/lxgw-wenkai-screen-webfont@1.1.0/style.css&quot; /&gt; 但我注意到我想要的 lxgw-wenkai-screen-webfont 在 staticfile.org 上也有 cdn 提供，且该 cdn 有海外节点，是不错的选择，所以我要通过下面这段引入: staticfile 已经因为供应链投毒被各 adblock 插件屏蔽，已改用 npmmirror 1&lt;link rel=&quot;stylesheet&quot; href=&quot;https://registry.npmmirror.com/lxgw-wenkai-screen-web/latest/files/style.min.css&quot; /&gt; 但要如何引入呢？ 在 hexo 的官方文档中，我找到了一个方案。可以在博客的 workdir 下创建一个 scripts 文件夹，在当中放入需要执行的 js 脚本。 在这篇名为《Fluid -23- 添加 Umami 统计》 的文章里，我找到了在 hexo 生成静态文件时直接注入的方式。 在 scripts/font.js 中写入: 123hexo.extend.injector.register(&#x27;head_end&#x27;,&#x27;&lt;link rel=&quot;stylesheet&quot; href=&quot;https://registry.npmmirror.com/lxgw-wenkai-screen-web/latest/files/style.min.css&quot; /&gt;&#x27;,&#x27;default&#x27;); 这样一来，字体文件的 css 便被我们成功引入了，我们还需要指定页面使用霞鹜文楷作为默认字体。 在 fluid 主题的配置文件 _config.fluid.yml 中，有一个名为 font-family 的配置项，直接写上 font-family: &quot;LXGW Wenkai Screen&quot; 便可大功告成。","categories":[],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://zhul.in/tags/Hexo/"}]},{"title":"【翻译】GLWTPL——祝你好运开源许可证","slug":"a-introduce-of-GLWTPL","date":"2023-11-11T17:09:09.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2023/11/12/a-introduce-of-GLWTPL/","link":"","permalink":"https://zhul.in/2023/11/12/a-introduce-of-GLWTPL/","excerpt":"","text":"说实话，当我第一次看见 GLWTPL( Good Luck With That Public License ) 的时候，我差点把嘴里的饭给喷出来了，这是一个非常有意思的开源许可证。原文请直接戳原仓库 -&gt; https://github.com/me-shaon/GLWTPL 如果你对你的代码有这样的感觉: 12当我写下这段代码的时候，只有上帝和我知道我在写什么。现在只有上帝知道了。 那不如来考虑一下将这份开源许可证添加到你的项目中！ 并且，祝你未来的自己、人类同胞、外星人或人工智能机器人（可以编码并会毁灭人类）——实际上是任何敢于参与你的项目的人好运。 当然，它还有一个脏话版本。干杯！ 可能的使用场景 你写了一些你并不为此自豪的代码，但你想要将它开源。 你想要将你写的代码“放生”，但不想为此负任何责任。 “无论如何我都已经写完了”，并且你没有时间/意图对你的代码进行修复、修改或改进。 想要将自己参加的黑客马拉松/代码竞赛的代码打造成一个爆火的仓库？该使用什么开源许可证？这就是为你量身打造的开源许可证！ 你的大学课设或科研工作与这份许可证是天作之合。 一些翻译版本 Albanian - Shqip Arabic - العربية Bangla - বাংলা Cantonese - 廣東話 Catalan - Català Croatian - Hrvatski Danish - Dansk Dutch - Nederlands French - Français Galician - Galego Georgian - ქართული German - Deutsch Greek - Ελληνικά Hebrew - עברית Indonesian - Bahasa Indonesia Italian - Italiano Japanese - 日本語 Korea - 한국어 Latvian - Latviski Portuguese - Português (BR) Russian - Русский Simplified Chinese - 简体中文 Spanish - Español Swedish - Svenska Traditional Chinese - 正體中文 Turkish - Türkçe Vietnamese - Tiếng Việt 本译文翻译于 2023 年 11 月 12 日，日后大概率也不会对本文进行任何改进，故也采用 GLWTPL 向所有人授权。 附此协议的英文原版： 12345678910111213141516171819202122232425 GLWT(Good Luck With That) Public License Copyright (c) Everyone, except AuthorEveryone is permitted to copy, distribute, modify, merge, sell, publish,sublicense or whatever they want with this software but at their OWN RISK. PreambleThe author has absolutely no clue what the code in this project does.It might just work or not, there is no third option. GOOD LUCK WITH THAT PUBLIC LICENSE TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION, AND MODIFICATION 0. You just DO WHATEVER YOU WANT TO as long as you NEVER LEAVE ATRACE TO TRACK THE AUTHOR of the original product to blame for or holdresponsible.IN NO EVENT SHALL THE AUTHORS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHERLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISINGFROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHERDEALINGS IN THE SOFTWARE.Good luck and Godspeed. 此协议在 Github 上的中文翻译版本： 1234567891011121314151617181920GLWT（Good Luck With That，祝你好运）公共许可证版权所有© 每个人，除了作者任何人都被允许复制、分发、修改、合并、销售、出版、再授权或任何其它操作，但风险自负。作者对这个项目中的代码一无所知。代码处于可用或不可用状态，没有第三种情况。 祝你好运公共许可证 复制、分发和修改的条款和条件0 ：在不导致作者被指责或承担责任的情况下，你可以做任何你想要做的事情。无论是在合同行为、侵权行为或其它因使用本软件产生的情形，作者不对任何索赔、损害承担责任。祖宗保佑。","categories":[],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://zhul.in/tags/%E7%BF%BB%E8%AF%91/"},{"name":"Fun","slug":"Fun","permalink":"https://zhul.in/tags/Fun/"}]},{"title":"通过巴法云将向日葵智能插座接入米家，实现小爱同学远程控制","slug":"integrating-sunflower-smart-socket-with-mi-home-via-bemfa-cloud","date":"2023-11-02T02:17:02.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2023/11/02/integrating-sunflower-smart-socket-with-mi-home-via-bemfa-cloud/","link":"","permalink":"https://zhul.in/2023/11/02/integrating-sunflower-smart-socket-with-mi-home-via-bemfa-cloud/","excerpt":"","text":"在上一篇博客中，我们介绍了如何在本地局域网中通过发送 http 请求控制向日葵智能插座 C2 的开关状态。但这还远远不够，我自己是小米生态链的忠实用户，在宿舍里也接入了四五个米家的智能设备，因此我想把这个智能插座接入米家，实现离家时一键关闭。 在阅读小米IoT开发者平台的接入文档后，我发现米家对于个人开发者并不友好，接入文档大部分要完成企业认证以后才能实现。在谷歌一番搜索过后，我发现了通过假设 Home Assistant 后通过巴法云接入米家的方案。但我眼下就这一个非米家的智能家具，暂时还不想去碰 Home Assistant 那套体系。 因此我便找上了巴法云。在巴法云的官网中提到，他们是「专注物联网设备接入&amp;一站式解决方案」，对于个人开发者，目前平台免费使用。网站的文档虽然并不优雅美观，却透露出实用主义的气息，针对接入提供了 TCP 长连接和 MQTT 两种方案，看着就很适合实现我的需求。 在巴法云文档中的「五分钟入门」那一栏介绍了远程控制的业务逻辑: 如果单片机订阅了一个主题，手机往这个主题推送个消息指令，单片机由于订阅了这个主题，就可以收到发往这个主题的消息，就可以达到手机控制单片机的目的。 所以我需要在巴法云的控制台创建一个针对于智能插座的主题，让我局域网内的一台设备订阅这个主题。接入米家以后，米家需要控制向日葵的智能插座时就向巴法云的这个主题推送一条消息，局域网内的设备就能接收到推送消息，进而调用智能插座的 api 实现远程开关。在这里，我选择使用一台刷了 Armbian 的 N1 作为局域网内的转发器。整个控制流程看上去是下面这个样子: 我并不知道 tcp 长连接的数据传输应该如何实现，但看起来 MQTT 是一个比较成熟的协议，因此我选择使用 MQTT 作为巴法云和 N1 之间的通讯协议。 在巴法云的控制台，选择 MQTT 设备云，创建一个新的主题，注意需要以 001~009 结尾，否则在米家里看不见创建的这个主题。 当主题名字后三位是001时为插座设备。 当主题名字后三位是002时为灯泡设备。 当主题名字后三位是003时为风扇设备。 当主题名字后三位是004时为传感器设备。 当主题名字后三位是005时为空调设备。 当主题名字后三位是006时为开关设备。 当主题名字后三位是009时为窗帘设备。 当主题名字为其他时，默认为普通主题节点，不会同步到米家。 此时，我便可以在手机的米家中找到巴法云并接入这个插座。 至此，米家那边的接入已经完成了，虽然没法在米家中找到对应设备的卡片，但是可以在小爱同学的小爱训练计划中找到对应的设备。 我们还需要让本地的 N1 盒子使用 MQTT 协议订阅巴法云的消息。 参考代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/python3import paho.mqtt.client as mqttimport requests# 智能插座相关host = &#x27;&#x27;sn = &#x27;&#x27;key = &#x27;&#x27;time = &#x27;&#x27;# 巴法云相关client_id = &#x27;&#x27;theme = &#x27;&#x27;def set_adapter_status(status: bool): url = &#x27;http://&#x27; + host + &#x27;/plug&#x27; requests.get(url, params=&#123; &quot;status&quot;: 1 if status else 0, &quot;sn&quot;: sn, &quot;key&quot;: key, &quot;_api&quot;: &quot;set_plug_status&quot;, &quot;time&quot;: time, &quot;index&quot;: 0 &#125;)def on_connect(client, userdata, flags, rc): print(&quot;Connection returned with result code:&quot; + str(rc)) client.subscribe(theme, qos=1)def on_message(client, userdata, msg): if msg.payload.decode(&quot;utf-8&quot;) == &#x27;on&#x27;: set_adapter_status(True) elif msg.payload.decode(&quot;utf-8&quot;) == &#x27;off&#x27;: set_adapter_status(False)def on_subscribe(client, userdata, mid, granted_qos): print(&quot;Subscribed: &quot; + str(mid) + &quot; &quot; + str(granted_qos)) client = mqtt.Client(client_id=client_id, clean_session=False, protocol=mqtt.MQTTv311)client.on_connect = on_connectclient.on_message = on_messageclient.on_subscribe = on_subscribeclient.connect(&quot;bemfa.com&quot;, 9501, 60)client.loop_forever() 参考链接 巴法开放平台 Python MQTT客户端 paho-mqtt Python MQTT 客户端对比","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Fun","slug":"Fun","permalink":"https://zhul.in/tags/Fun/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"},{"name":"Hardware","slug":"Hardware","permalink":"https://zhul.in/tags/Hardware/"},{"name":"IoT","slug":"IoT","permalink":"https://zhul.in/tags/IoT/"},{"name":"MiAI","slug":"MiAI","permalink":"https://zhul.in/tags/MiAI/"}]},{"title":"使用 Root 后的安卓手机获取向日葵智能插座 C2 的开关 api","slug":"unveiling-sunflower-smart-adapter-api-intercepting-utilizing-api-android-packet-sniffing","date":"2023-11-01T15:46:28.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2023/11/01/unveiling-sunflower-smart-adapter-api-intercepting-utilizing-api-android-packet-sniffing/","link":"","permalink":"https://zhul.in/2023/11/01/unveiling-sunflower-smart-adapter-api-intercepting-utilizing-api-android-packet-sniffing/","excerpt":"","text":"之前看到 https.gs 上的一篇文章，发现可以抓取向日葵智能插座 C1Pro 的开关 api，并实现局域网或公网的控制。这样一来，我们其实就不需要依赖于向日葵自己家的 App 去实现智能插座的开关操作，还是比较方便的。今年趁着双十一，直接低价拿下来带有计电功能的 C2，便也来试一试能不能抓到接口。 首先，拿到插座以后肯定还是下载向日葵的官方 App，完成 wifi 的链接，这里就不再赘述。 然后就可以打开我们的抓包软件。需要注意的是，原博客中抓到的接口是 http 协议，但这个接口在新版的 App 上已经变为了 https 协议，因此我们需要找一台 Root 过后的安卓机去抓包。抓包的步骤没什么好说的，用 Root 权限给本地安装自己的 CA 证书，然后打开抓包模式，在向日葵的 App 那边开关几次插座，回来就能看到这一段时间内的请求。 点开可以看到，这是一个 GET 请求，一共有如下几个参数 status 这是状态设置，设置为 1 时为打开指令，0 为关闭指令 sn 这个应该是设备码 key 应该是用来操作设备的密钥 _api 操作类型，我只关心插座的打开关闭，所以设为 set_plug_status 即可 time 奇奇怪怪的而参数，也不是 unix 时间戳，反正照抄就行了 index 原博说是用来给插排操作指定第几个孔位的，我们智能插座直接设置为 0 即可 理论上你用抓出来的 url 已经可以实现公网访问了，但我测试下来并不行，可能是向日葵那边的服务器做了别的校验，比如说判断了 ua 之类的？不过无所谓，我本来就是打算局域网内操作。 登陆路由器后台，寻找疑似智能插座的设备，一般很容易就能找到。 使用 nmap 命令扫对应 ip 开放的端口。不知道是不是巧合，我和原博扫出来的端口都是 6767 端口。 将上面抓到的 url 的域名换成 ip:port，https 协议改成 http 协议，在浏览器中直接访问，获得了 0 的状态码，插座也正常开关。","categories":[],"tags":[{"name":"Android","slug":"Android","permalink":"https://zhul.in/tags/Android/"},{"name":"Fun","slug":"Fun","permalink":"https://zhul.in/tags/Fun/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Hardware","slug":"Hardware","permalink":"https://zhul.in/tags/Hardware/"},{"name":"IoT","slug":"IoT","permalink":"https://zhul.in/tags/IoT/"}]},{"title":"创建 b23.tv 追踪参数移除 bot","slug":"create-b23tv-remover-bot","date":"2023-10-28T16:35:48.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2023/10/29/create-b23tv-remover-bot/","link":"","permalink":"https://zhul.in/2023/10/29/create-b23tv-remover-bot/","excerpt":"","text":"前两天似乎有人高调宣称自己发 b23.tv 没问题，结果过两天就被拿下的消息。我自己并不是他的粉丝，但这个戏剧性的流言也又一次说明了注重隐私保护的重要性。 早前就有 b23.tf 和 b23.wtf 两个域名专门在做移除追踪参数的事情。只要将短链接中的 b23.tv 改成 b23.tf ，别人访问链接时就会被转到移除了追踪参数的链接。但这需要发送者在分享时手动更改域名。 因此，我也开始为自己的 bot 添加了 b23.tv 的 track id 移除功能。当用户的信息中包含 b23.tv 短链接，将会自动发送一条移除了 track id 的信息，用户就可以直接点击无追踪参数的链接。 当然，这两种方案并不能保护链接分享者的个人信息泄漏，因为 b23.tv 后面的参数是可以被别人看到的，通过这些参数就可以定位到链接分享者的个人信息，所以不能防止群里的内鬼倒查分享者的个人信息，但起码可以阻止大数据算法对群里的几个人产生关联。 b23 短链接将会泄漏哪些个人信息？通过 curl 命令，我们就可以看到 b23.tv 短链接重定向到了哪个页面。 这是所携带的 GET 请求参数 12345678910111213141516&#x27;buvid&#x27;: [&#x27;*************************************&#x27;],&#x27;from_spmid&#x27;: [&#x27;tm.recommend.0.0&#x27;],&#x27;is_story_h5&#x27;: [&#x27;false&#x27;],&#x27;mid&#x27;: [&#x27;************************&#x27;],&#x27;p&#x27;: [&#x27;1&#x27;],&#x27;plat_id&#x27;: [&#x27;116&#x27;],&#x27;share_from&#x27;: [&#x27;ugc&#x27;],&#x27;share_medium&#x27;: [&#x27;android&#x27;],&#x27;share_plat&#x27;: [&#x27;android&#x27;],&#x27;share_session_id&#x27;: [&#x27;************************************&#x27;],&#x27;share_source&#x27;: [&#x27;GENERIC&#x27;],&#x27;share_tag&#x27;: [&#x27;s_i&#x27;],&#x27;spmid&#x27;: [&#x27;united.player-video-detail.0.0&#x27;],&#x27;timestamp&#x27;: [&#x27;**********&#x27;],&#x27;unique_k&#x27;: [&#x27;*******&#x27;],&#x27;up_id&#x27;: [&#x27;*********&#x27;] 其中，我替换成星号的部分都是有可能涉及到信息泄漏的部分，甚至没打码的部分也可以用来推测你的平台信息。 QQ Bot尽管目前腾讯针对 go-cqhttp 的封杀力度挺大的，但我还在用。 在 QQ 中的 b23.tv 追踪参数移除主要有两个方面。一是用户发送的消息中可能含有 b23.tv 短链接，二是用户在手机端直接调用 bilibili 自带的「分享到QQ」的功能，这样的话在 QQ 中会显示为小程序，go-cqhttp 接收到的是一个 json 的 CQ Code。 针对第一种情况，处理起来就相对简单，首先判断用户的信息中是否存在 b23.tv 这一关键词，然后用正则表达式获取完整的 b23 链接，再使用 python 的 requests 库去请求对应链接，返回带有明文追踪参数的 url 后去除 GET 参数即可。 参考代码如下 12345678910if &#x27;https://b23.tv&#x27; in message: pattern = r&#x27;https://b23\\.tv/[^\\s]+&#x27; urls = re.findall(pattern, message) ret = &#x27;TrackID removed:&#x27; for i in urls: ret = ret + &#x27;\\n&#x27; + b23_to_bvid(i) def b23_to_bvid(url): tracked_url = requests.get(url,allow_redirects=False).headers[&#x27;location&#x27;] return tracked_url.split(&#x27;?&#x27;, 1)[0] 而针对第二种情况，则需要先解析对应的 json 信息，再参考第一种方法获取无追踪参数的链接。 参考代码如下 1234567891011121314if message.startswith(&#x27;[CQ:json,data&#x27;) and &#x27;b23.tv&#x27; in message: decoded_data = html.unescape(message) match = re.search(r&#x27;\\[CQ:json,data=(\\&#123;.*?\\&#125;)\\]&#x27;, decoded_data) json_str = match.group(1) json_data = json.loads(json_str) if json_data[&#x27;meta&#x27;].get(&#x27;detail_1&#x27;) is not None: raw_url = json_data[&#x27;meta&#x27;].get(&#x27;detail_1&#x27;).get(&#x27;qqdocurl&#x27;) elif json_data[&#x27;meta&#x27;].get(&#x27;news&#x27;) is not None: raw_url = json_data[&#x27;meta&#x27;].get(&#x27;news&#x27;).get(&#x27;jumpUrl&#x27;) clean_url = b23_to_bvid(raw_url) def b23_to_bvid(url): tracked_url = requests.get(url,allow_redirects=False).headers[&#x27;location&#x27;] return tracked_url.split(&#x27;?&#x27;, 1)[0] TG Bot这个平台是提供了 Bot 的 API 的，所以也不用担心会被官方封杀，可惜用户访问起来可能相对困难，也不能要求所有联系人都迁移到这个平台上。思路也是一样的，用 requests 去请求 b23 短链，返回去除跟踪参数的 url。 参考代码如下 123456789101112131415161718192021222324252627282930313233from telegram import Updatefrom telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filtersimport requestsimport reua = &#x27;Mozilla/5.0 (X11; Linux x86_64; rv:120.0) Gecko/20100101 Firefox/120.0&#x27;async def start(update: Update, context): await context.bot.send_message(chat_id=update.effective_chat.id, text=&quot;Hello World!&quot;) async def b23_remover(update: Update, context): seng_msg = &#x27;TrackID removed:&#x27; if &#x27;https://b23.tv&#x27; in update.message.text: pattern = r&#x27;https://b23\\.tv/[^\\s]+&#x27; urls = re.findall(pattern, update.message.text) for i in urls: seng_msg += &#x27;\\n&#x27; + await b23_to_bvid(i) await context.bot.send_message(chat_id=update.effective_chat.id, text=seng_msg) async def b23_to_bvid(url): tracked_url = requests.get(url,allow_redirects=False,headers=&#123;&#x27;User-Agent&#x27;: ua&#125;).headers[&#x27;Location&#x27;] return tracked_url.split(&#x27;?&#x27;, 1)[0] start_handler = CommandHandler(&quot;start&quot;, start)b23_remove_handler = MessageHandler(filters.TEXT, b23_remover)if __name__ == &#x27;__main__&#x27;: TOKEN=&#x27;**********************************************&#x27; application = ApplicationBuilder().token(TOKEN).build() application.add_handler(start_handler) application.add_handler(b23_remove_handler) application.run_polling() 代码编写参考了 柯罗krau的博客 | krau’s blog，使用时请注意以下问题: 你的机子是否拥有能访问到对应的 api 的网络环境 botfather 那边是否打开了 allow group botfather 那边是否关闭了 privacy mode","categories":[],"tags":[{"name":"Bot","slug":"Bot","permalink":"https://zhul.in/tags/Bot/"},{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"},{"name":"Privacy","slug":"Privacy","permalink":"https://zhul.in/tags/Privacy/"}]},{"title":"jinja2 中如何优雅地实现换行","slug":"jinja2-nl-to-br","date":"2023-09-03T05:37:35.000Z","updated":"2023-09-02T16:52:51.000Z","comments":true,"path":"2023/09/03/jinja2-nl-to-br/","link":"","permalink":"https://zhul.in/2023/09/03/jinja2-nl-to-br/","excerpt":"","text":"在使用 python 的 jinja2 模板引擎生成 html 的时候，会遇到 \\n 换行符无法被正常换行的问题。我本能的想法就是将 \\n 替换成 html 标签 &lt;br /&gt;，但失败了，jinja2 有自动转义的功能，直接将标签原模原样地渲染了出来，并没有生效。而为这一段代码块关闭自动转义则会有被 js 注入的风险，因此这也不是上策。 在 jinja2 的官方文档中，提出了使用 filter 的方案。也就是说，filter 将 \\n 识别出来，并自动替换成 &lt;br /&gt; 标签，并且使用 Markup 函数将这一段 html 文本标记成安全且无需转义的。见: https://jinja.palletsprojects.com/en/3.1.x/api/#custom-filters 1234567891011121314151617import refrom jinja2 import pass_eval_contextfrom markupsafe import Markup, escape@pass_eval_contextdef nl2br(eval_ctx, value): br = &quot;&lt;br&gt;\\n&quot; if eval_ctx.autoescape: value = escape(value) br = Markup(br) result = &quot;\\n\\n&quot;.join( f&quot;&lt;p&gt;&#123;br.join(p.splitlines())&#125;&lt;\\p&gt;&quot; for p in re.split(r&quot;(?:\\r\\n|\\r(?!\\n)|\\n)&#123;2,&#125;&quot;, value) ) return Markup(result) if autoescape else result 使用这段代码后，我遇到了连续两个换行符被识别成一个换行符的问题，依然不满意。 在 issue#2628 中，我找到了一个相对优雅的解决方案——使用 css 样式来完成这个任务。 通过设置 white-space: pre-line; 的 css 样式，html 在被渲染时将会不再忽略换行符，浏览器就能够在没有 br 标签标注的情况下实现自动换行。而如果设置为 white-space: pre-wrap; 则多个空格将不会再被合并成一个空格，直接治好了我在入门 html 时的各种不适。 此外，通过 word-break: break-word; 的 css 样式可以实现只有当一个单词一整行都显示不下时，才会拆分换行该单词的效果，可以避免 break-all 拆分所有单词或者 normal 时遇到长单词直接元素溢出的问题。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"},{"name":"jinja2","slug":"jinja2","permalink":"https://zhul.in/tags/jinja2/"},{"name":"CSS","slug":"CSS","permalink":"https://zhul.in/tags/CSS/"}]},{"title":"手动指定 python-selenium 的 driver path 以解决在中国大陆网络环境下启动卡住的问题","slug":"python-selenium-start-difficult-in-china-mainland","date":"2023-09-01T17:59:18.000Z","updated":"2023-10-28T17:48:04.000Z","comments":true,"path":"2023/09/02/python-selenium-start-difficult-in-china-mainland/","link":"","permalink":"https://zhul.in/2023/09/02/python-selenium-start-difficult-in-china-mainland/","excerpt":"","text":"之前因为学校社团迎新的需求，就临时写了一个 QQ Bot，最近又给 bot 加上了 /q 的功能，原理是通过 python 的 selenium 去启动一个 headless Firefox 去截由 jinja2 模板引擎生成的 html 的图。 每次这个 bot 重启的时候都因为 selenium 而需要花费好几秒的时间，甚至经常概率性启动失败。我就寻思者应该把这个图片生成的 generator 从 bot 中抽出来，这样就不至于每次重启 bot 都要遭此一劫。但就在我将 generator 打包成 docker 部署上云服务器的时候，发现居然无法启动。于是手动进 docker 的 shell 开 python 的交互式终端，发现在创建 firefox 的 webdriver 对象的时候异常缓慢，等了半分钟以后蹲到一个报错如下: 1234567891011121314151617181920212223Traceback (most recent call last): File &quot;/usr/local/lib/python3.11/site-packages/selenium/webdriver/common/driver_finder.py&quot;, line 38, in get_path path = SeleniumManager().driver_location(options) if path is None else path ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File &quot;/usr/local/lib/python3.11/site-packages/selenium/webdriver/common/selenium_manager.py&quot;, line 95, in driver_location output = self.run(args) ^^^^^^^^^^^^^^ File &quot;/usr/local/lib/python3.11/site-packages/selenium/webdriver/common/selenium_manager.py&quot;, line 141, in run raise WebDriverException(f&quot;Unsuccessful command executed: &#123;command&#125;.\\n&#123;result&#125;&#123;stderr&#125;&quot;)selenium.common.exceptions.WebDriverException: Message: Unsuccessful command executed: /usr/local/lib/python3.11/site-packages/selenium/webdriver/common/linux/selenium-manager --browser firefox --output json.&#123;&#x27;code&#x27;: 65, &#x27;message&#x27;: &#x27;error sending request for url (https://github.com/mozilla/geckodriver/releases/latest): connection error: unexpected end of file&#x27;, &#x27;driver_path&#x27;: &#x27;&#x27;, &#x27;browser_path&#x27;: &#x27;&#x27;&#125;The above exception was the direct cause of the following exception:Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;/usr/local/lib/python3.11/site-packages/selenium/webdriver/firefox/webdriver.py&quot;, line 59, in __init__ self.service.path = DriverFinder.get_path(self.service, options) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ File &quot;/usr/local/lib/python3.11/site-packages/selenium/webdriver/common/driver_finder.py&quot;, line 41, in get_path raise NoSuchDriverException(msg) from errselenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for firefox using Selenium Manager.; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location 我才发现 selenium 试图访问 https://github.com/mozilla/geckodriver/releases/latest 且访问失败了。仔细阅读了 selenium 项目的文档发现新版本的 selenium 会尝试自动下载 webdriver: As of Selenium 4.6, Selenium downloads the correct driver for you. You shouldn’t need to do anything. 表面上看上去我不需要做任何事情，但项目组忽略了中国大陆的网络环境。 服务是要在境内的云服务器上跑的，我也不敢开代理，现在比较靠谱的方案是我去手动指定 Firefox 的 geckodriver，避免 selenium 去帮我自动下载一份。在 python-selenium 的官方文档中是让我们创建 Firefox 的 webdriver 时去传入一个 executable_path=&#39;geckodriver&#39; 的关键词参数，可惜这是过时的用法，应该是维护者还没来得及更新文档。 随后便在 stackoverflow 上找到了新版 selenium 手动指定 Chrome 的 chromedriver 的方法 12345678&gt;from selenium import webdriver&gt;from selenium.webdriver.chrome.service import Service&gt;service = Service(executable_path=&#x27;chromedriver.exe&#x27;) &gt;options = webdriver.ChromeOptions()&gt;driver = webdriver.Chrome(service=service, options=options)&gt;# ...&gt;driver.quit() 原文给的是 chrome 的方案，但 Firefox 的方案基本也是一致的，应该也是去创建一个 service 对象，猜一猜就能猜到。 123456789from selenium import webdriverfrom selenium.webdriver.firefox.service import Servicefrom selenium.webdriver.firefox.options import Optionsservice = Service(executable_path=&#x27;/root/geckodriver&#x27;) # 我这里是 docker 打包，懒得创建一个普通用户了，就直接用了 root 用户的 home 目录options = Options(&quot;--headless&quot;)driver = webdriver.Firefox(service=service, options=options)# ...driver.quit() 手动指定 geckodriver 后，在我 1 核 1 G 的小主机上创建 webdriver 对象，基本都可以秒完成。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"},{"name":"selenium","slug":"selenium","permalink":"https://zhul.in/tags/selenium/"}]},{"title":"从零开始的静态网页部署（到个人云服务器）","slug":"static-webpage-deployment-for-a-beginner","date":"2023-08-03T17:19:22.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2023/08/04/static-webpage-deployment-for-a-beginner/","link":"","permalink":"https://zhul.in/2023/08/04/static-webpage-deployment-for-a-beginner/","excerpt":"","text":"这篇博客是受 Tiancy 之托，在2023年精弘网络暑期授课的前端系列第七节课时针对项目部署这一块内容时所产生的产物。在授课视频中，受时长所限，我不得不采用宝塔面板+纯 ip 访问的方式来完成一个简单的部署，但这终究不是什么优雅的方案: 宝塔的安全性堪忧、其隐私性也是备受争议，而纯 ip 访问的方式也过于简陋，且没有支持 https 访问。 因此这篇博客将以面对初学者的口吻去讲述如何从零开始部署一个 Vue.js 的项目到云服务器，以解我心头的愧疚。但是，我没有备案过的域名，且国内云服务器厂商众多，这篇博客终究不可能做到像保姆级教学那样去一一演示每一家云服务器厂商网页面板上的操作过程，而一些比较基础的概念我会给出简单的解释和例子以及引用一些外部链接，但终究不会全面覆盖到，诸位还请见谅。 本文采用了一些 ChatGPT 和 Google Bard 提供的内容，准确性经过我本人核阅。 基础 Web 知识针对以下三个知识点，我是在初中的信息课上学到的，互联网上应该不乏对于这三个问题的权威解释，因此我也不在此赘述，不知道的小伙伴请自行搜索。 ip 地址是什么 域名是什么 DNS 服务器是干什么的 关于备案不备案的影响当你通过域名去访问境内服务器的 80 (http 默认端口) 和 443 (https 默认端口)时，如果该域名没有备案或者境内这台云服务器的云服务器商不知道你在别的服务商那里有备案的情况下，则会对请求进行拦截。对于访问 80 的请求，将会直接劫持 http 请求以重定向到他们的备案提示页面；对于访问 443 的请求，由于 https 没法被劫持，则会通过连接重置的方式阻止你访问。如果你确定你需要使用中国大陆境内的云服务器，应当采取「备案」和「接入备案」两种方式分别解决上述两种情况。 备案方法每个省都有自己对应的管局，而各省的管局对于备案的规则都有些差异，而个人备案一般是找自己户籍所在地的管局去备案，详细的可以看阿里云写的文档。 使用中国大陆境外的云服务器可以选择和我一样去中国大陆以外的地区部署云服务，但由于众所周知的原因，访问别的国家或地区的服务器可能会有速度慢、延迟高等问题，这涉及到线路优化，也比较复杂。更糟糕的情况是，你甚至有可能刚开出来一台机子就发现这个 ip 在中国大陆境内是无法访问到的，这也是比较尴尬的地方。一般来说，可以选择在境内的云服务器商那里实名认证（不是备案）去购买他们的境外服务器（比如 ucloud 新用户优惠的香港云服务器，ucloud 的客户经理看到了能不能再送我一台机子啊），这种机子是线路相对比较好的。 选购中国大陆境外的云服务器时，厂商可能会提供测试 ip 来帮助你判断线路质量，可以使用 ipip.net 提供的 besttrace 程序来查看数据包经过的地方，很可能你买一台香港的服务器，数据却要从日本或者美国绕一圈，这就非常尴尬。 域名部分域名注册要获得一个域名，最简单的方式是花钱。境内的阿里云、腾讯云、华为云等几家比较有名的云服务器厂商均有域名注册的业务且价格基本差距不大，可以随便找一个注册。而境外的域名注册商，我这边个人推荐 namesilo，这家支持支付宝付款且价格尚可，首次购买前可以去搜索引擎搜一搜近期的优惠码，可能会有一些优惠折扣。（可恶我没有拿到 aff 回扣） 域名解析域名解析的作用如果你了解了 dns 的作用，那我们可以来简单讲讲域名解析是干什么的。dns 服务器将会告诉用户的设备某一个域名它对应的 ip 是多少，而域名解析这一步就是告诉世界上所有的 dns 服务器这个域名从此刻开始对应的 ip 是多少，以便世界上所有的 dns 服务器向网民在需要时告知他们正确的 ip 地址。 要实现这一步骤并不复杂，作为初学者我们也不必去担心会不会有人把你花钱买来的域名指向错误的 ip 地址，这些都交给域名解析服务去解决。几乎每一家提供的域名解析服务页面上都会指导你去将域名的 NameServer 设置为他们家的服务器，这里也不做教学。 域名解析服务推荐凡是提供域名注册服务的云服务商基本也都会提供域名解析服务，在这里我主要推荐两家云服务商（我没拿广告费啊）—— cloudflare 和 dnspod。这两家免费版套餐的操作页面都简洁明了，没有非常扎眼的广告。前者提供了除中国大陆以外地区的 cdn 加速服务，而后者可以提供境内境外分线路解析的功能（把来自境内的用户指向 ip 地址 A，来自境外的用户指向 ip 地址 B）。 解析记录类型作为初学者只需要了解 A 记录和 CNAME 记录就行了。 A 记录的意思就是将一个域名指向一个 ipv4 地址，也就是去实现 dns 服务器最主要的作用。而 CNAME 记录是将一个域名指向另一个域名，通俗来讲就是「和它一样」。比如 a.com 如果 CNAME 指向 b.com，意思就是说我现在不确定 a.com 的 ip 是多少，但我知道 a.com 的 ip 和 b.com 一样，所以你去查 b.com 就行了。 服务器部分云服务器的购买这部分我直接忽略过去了，本文在「关于备案」这一部分已经详细阐述了备案相关的内容，购买中国大陆境内还是境外的服务器需要由屏幕前的各位自己决定（应该没人会把我的博客打印成纸质稿看吧）。 如何选择云服务器上要运行的 Linux 发行版服务器上常用的 Linux 发行版主要是 Debian、Ubuntu、CentOS(这个死得差不多了) 这三个，那我个人更熟悉的是 Ubuntu，版本号越新越好，截止本文发出最新的 lts 版本是 22.04 lts，所以直接选择这个就行。 使用 ssh 连接上服务器在云服务器的网页面板上选择好服务器的配置与运行的操作系统后，云服务商应该至少给你提供两样东西: 云服务器的 ip 和 root 用户的登陆密码。这可能是在网页面板上展示的，一些境外的云服务商可能是直接发送到你注册时预留的邮箱中的，这都无所谓。拿到这两样东西我们就可以使用 ssh 连接到服务器的终端，进行配置操作。 打开自己系统的终端，使用如下命令去连接云服务器（Win10 以上的系统应该也已经自带 openssh 了） 1ssh root@&lt;your_server_ip&gt; 12345678[zhullyb@Archlinux ~]$ ssh root@120.55.63.96The authenticity of host &#x27;120.55.63.96 (120.55.63.96)&#x27; can&#x27;t be established.ED25519 key fingerprint is SHA256:Op8u4Fv+NvtOxJDKeBQ/jIsFpuR4EYTUt53qjG8k6ok.This key is not known by any other names.Are you sure you want to continue connecting (yes/no/[fingerprint])? yesWarning: Permanently added &#x27;120.55.63.96&#x27; (ED25519) to the list of known hosts.root@120.55.63.96&#x27;s password: Welcome to Ubuntu 22.04.2 LTS (GNU/Linux 5.15.0-78-generic x86_64) 输入密码时，已经输入的密码部分在屏幕上不会显示，但无需理会，只要将云服务器的密码粘贴后直接敲回车就好。 如何编辑一个服务器上的文件一般来说，网上的教程会推荐你使用 vim 这个 tui 界面的编辑器去编辑这个文件，但 vim 的学习成本有点高，如果只是临时编辑服务器上的文件的话，我个人更加推荐使用 nano 1nano /etc/caddy/conf.d/example.conf 这行命令表示我要编辑 /etc/caddy/conf.d/example.conf 这个文件，如果这个文件不存在则去创建这个文件。 随后你可以根据自己的需求去编辑文件了，上下左右按键可以调整光标位置，直接敲键盘上的字母按键就可以把字母敲进去，想推出时使用 ctrl+s 保存，再使用 ctrl+x 退出就可以了。 云服务器的安全组规则一般是国内的云服务厂商会有安全组规则这种东西，你可以理解成一个额外的防火墙。一般来说，80 和 443 两个端口被我们约定作为网页的默认端口，80 是 http 的端口，而 443 则是 https 的端口。因此，我们需要在安全组规则这里去允许 80 和 443 两个端口能被外部访问到。截图中是阿里云的控制面板。 云服务商给的默认规则应该是下面这个样子的: 这里开放的 22 端口用于 ssh 连接服务器，而3389 则是 Windows 的远程桌面。我们可以使用「快速添加」按钮来开放 80 和 443 端口 Linux 下常见的文件路径及对应作用在这一章节中，我只罗列了几个比较常见的路径，更多的资料推荐查阅菜鸟教程，写得还不错。$USER 指当前用户的用户名 路径 作用 /home/$USER 用户的家目录，下有 Desktop，Download，Picture 等多个文件夹（root 用户的家目录是 /root） /etc 存放软件的配置文件的地方 /usr/bin 存放二进制可执行文件的地方，一般也会被链接到 /bin /usr/lib 一般用于存放依赖库(动态链接库)，一般会被链接到 /lib /usr/share 一些共享数据，比如帮助文档、软件需要的资源文件等等 /opt optional(可选) 的缩写，一些由官网提供的（区别于发行版自带的）软件可能被安装到这里 /boot 开机引导使用的路径，一般在正常使用时不会去操作这里 /var variable(变量) 的缩写，存放那些经常被变更的东西，比如运行日志、网站数据等等 caddy 的配置与使用caddy 是一个 web 服务器，他是使用 golang 写的一个平替品，拥有配置更简单、自动申请 Let’s Encrypt 证书的优势，我个人非常推荐非专业运维去使用这个。caddy 的官方文档在 https://caddyserver.com/docs/ ，但我相信你们不会去看（我也没有认真看过），有问题可以尝试去问问 chatgpt 看看能不能得到想要的配置文件。caddy 现在已经迭代到 V2 版本了，与 V1 版本相比有一些语法差异以支持更多的功能，且许可证允许商用更加自由。 caddy V2 支持使用 json 配置文件或者 Caddyfile，对于不复杂的需求我个人更推荐后者，简洁易懂。下面是我博客所使用的 Caddyfile 示例: 1234567891011121314151617181920212223# 这里表示，使用 zhul.in 这个域名访问 443 端口时，提供以下内容zhul.in:443 &#123; # 这里设置了所需提供内容的目录 root * /var/www/blog # 这里设置的是开启 https 支持时所需要使用的 ssl 证书文件，但如果不设置也不碍事，caddy 会自动帮你申请 Let&#x27;s Encrypt 的 ssl 证书 tls /var/www/key/zhul.in.cert /var/www/key/zhul.in.key # 这里表示我们开启了 zstd 和 gzip 两种压缩算法，来减少数据传输量，不设置也没问题 encode zstd gzip # 这里表示我们开启了一个文件服务器，当你访问 https://zhul.in/example_file 时，caddy 会提供 /var/www/blog/example_file 这个文件的内容 file_server # 这里是错误处理部分 handle_errors &#123; # 这里表示当发生错误时，将请求重定向到 /404.html 这个文件 rewrite * /404.html # 这里使用了模板来处理错误页面。当发生错误时，Caddy会使用模板引擎来填充错误页面的内容，以便向用户显示有关错误的相关信息。 templates #这里表示继续使用文件服务器来提供错误页面 file_server &#125;&#125; 你可以发现，如果要把这个 Caddyfile 写到最简单，仅仅是能跑的状态，只需要这几行: 12345zhul.in:443 &#123; root * /var/www/blog file_server&#125; 这就是我为什么推荐非专业运维去使用 caddy 的原因，只需要三行代码就可以跑起来一个简单的服务。 而部署一个 Vue.js 项目，我们可能会需要多加一行 try_files &#123;path&#125; &#123;path&#125;/ /index.html ，这一行代码的意思是当用户尝试访问 /example 时，实际需要用户的浏览器去访问 /index.html 这个地方，因为使用了 vue-router 的项目的编译产物只有 /index.html 而没有 /example.html，而后者的内容是包括在前者中的。以下的 Caddyfile 是精弘的首页正在使用的配置文件，应该可以适用于绝大多数的 Vue 项目: 1234567www.myzjut.org &#123; root * /var/www/jh encode zstd gzip file_server try_files &#123;path&#125; &#123;path&#125; /index.html&#125; 第一行省略了端口号，说明 80 和 443 端口都支持。 通过sftp/rsync将本地的静态网页上传到云服务器的对应目录使用 sftp 部署 sftp 是一个交互性比较强的上下传工具，如果不喜欢背命令的话可以考虑使用 sftp，操作起来都比较顺其自然 首先，我们在本地 cd 到静态网页文件所在的路径，比如一个 Vue 项目编译产生的文件可能就会在 dist 下面 1cd dist/ 然后，我们使用 sftp 连接到服务器，这和 ssh 命令没什么两样的，就换了个命令名。 1sftp root@&lt;your_server_ip&gt; 输入 root 用户的密码后，命令行的提示符就会变成 sftp &gt; 的样子 123[zhullyb@Archlinux ~]$ sftp root@&lt;your_server_ip&gt;Connected to &lt;your_server_ip&gt;.sftp&gt; 这是一个交互式的命令行窗口，可以使用 cd、mkdir 等几个简单的命令。我们先创建 /var/www 这个文件夹: 1sftp&gt; mkdir /var/www 再创建 /var/www/jh 这个文件夹: 1sftp&gt; mkdir /var/www/jh 随后，我们就可以进入远程服务器的 /var/www/jh 目录下 1sftp&gt; cd /var/www/jh 这样我们就可以把本地的静态网页文件上传到服务器，使用 put 命令即可，下面的命令表示将本地当前目录下的所有文件以及其子文件夹全部内容都上传到服务器的当前文件夹，也就是 /var/www/jh 1sftp&gt; put -r * 再输入 exit 即可推出 sftp 状态。 这边再教一些 sftp 使用中的常用命令: ls: 查看远程服务器中当前目录中所有非隐藏文件 lls: 查看本地当前路径中的所有非隐藏文件 pwd: 查看远程服务器中当前的路径 lpwd: 查看本地当前的路径 使用 rsync 部署 rsync 的交互性就不太强，是在本机操作的，需要提前写好一行比较长的命令去执行操作，比较适合写在脚本里。 下面这行代码是我们精弘网络首页使用 github action 部署时的命令 1rsync -avzP --delete dist/ root@&lt;your_server_ip&gt;:/var/www/jh/ dist/ 表示我想要上传当前路径下的 dist 文件夹下的所有文件 root@ 这一段和前面的 ssh 与 sftp 一样，都表示用户名和对应的服务器 ip， :var/www/jh 表示文件将被上传到服务器的这个路径下。 以下是 rsync 的一些常用参数： -a：以归档模式进行同步，即保持文件的所有属性（如权限、属主、属组、时间戳等）。 -v：显示详细的同步过程。 -z：使用压缩算法进行数据传输，以减少网络带宽的占用。 --delete：在目标目录中删除源目录中不存在的文件。 -P选项是rsync命令的一个常用选项，它的作用是将--partial和--progress选项组合在一起使用。 --partial选项表示如果文件传输被中断，rsync会保留已经传输的部分文件，下次继续传输时可以从上次中断的地方继续。 --progress选项表示显示文件传输的进度信息，包括已经传输的字节数、传输速度和估计剩余时间等。 使用-P选项可以方便地同时启用这两个选项，以便在文件传输期间显示进度信息，并在中断后继续传输。 附 : 其他相关的一些操作技巧（还没写完，等我填坑）使用 ssh-copy-id 将本地的 ssh 公钥复制到服务器上配置 sshd 以加强服务器的安全性sshd 是 Secure Shell Daemon 的缩写，它是一个 ssh 的守护进程，允许用户通过 SSH 协议安全地连接到远程服务器。 sshd 的配置文件应该在 /etc/ssh/sshd_config 文件中，通过更改其中一些配置项，我们可以让我们的服务器更安全。 建议 修改方式 禁用 root 用户通过 SSH 登录 在 sshd配置文件中将 PermitRootLogin 选项设置为 no。（在此之前，你应该创建一个非 root 用户并设置好对应的账号密码，修改好 /etc/sudoers 文件确保该用户能够通过 sudo 执行一些需要 root 权限去执行的语句） 强制使用 SSH 密钥登录 在 sshd 配置文件中将 PasswordAuthentication 选项设置为 no。（在此之前，你应该完成上一步 ssh-copy-id 将本地的 ssh 公钥复制到服务器上） 更改 SSH 端口 在 sshd 配置文件中将 Port 选项设置为一个未使用的端口。（在此之前，使用 ssh 命令连接到服务器时，需要使用 -p &lt;port&gt; 参数去指定端口） 启用 SSH 日志记录 在 sshd 配置文件中将 SyslogFacility 选项设置为 auth。 systemd 的作用与使用方法systemd 是一个用于管理 Linux 系统的服务管理器和初始化系统。 使用 systemctl 命令管理服务状态在我们静态网页部署这一块，我们主要用 systemctl 命令去管理一些服务的状态，比如我们想要将 caddy 设置为开机自启，这样我们即使重启了服务器，caddy 也能自动开始提供服务。 以下是一些常见的 systemctl 命令： systemctl start：启动服务。 systemctl stop：停止服务。 systemctl restart：重新启动服务。 systemctl status：查看服务的状态。 systemctl enable：使服务在启动时自动启动。 systemctl disable：使服务在启动时不自动启动。 使用 journalctl 命令来查看日志消息在服务出现问题的时候，我们可以通过 systemctl 命令去查看服务在运行过程中留下的日志消息，方便我们去排错。 以下是一些常见的 journalctl 命令： journalctl -b: 显示当前系统日志。 journalctl -b -1: 显示最近一条系统日志。 journalctl -b -10: 显示最近 10 条系统日志。 journalctl -u &lt;unit&gt;: 显示指定单元的日志。 journalctl -u &lt;unit&gt; -b: 显示指定单元的最近系统日志。 journalctl -u &lt;unit&gt; -b -1: 显示指定单元的最近一条系统日志。 journalctl -u &lt;unit&gt; -b -10: 显示指定单元的最近 10 条系统日志。 还可以使用 journalctl 命令来导出日志消息到文件。例如，以下命令将当前系统日志导出到 /home/user/journal.log 文件： 1journalctl &gt; /home/user/journal.log 防火墙的配置关于防火墙，iptables 是 Linux 系统中最早使用的防火墙工具，它基于内核模块来过滤网络数据包。nftables 是 iptables 的继任者，与 iptables 相比，nftables 更简单易用，同时性能也更好。 但我这边想要推荐的是 ufw，他是 iptables 的一个前端，它提供一个更简单、更易于使用的命令行界面。UFW 基于 iptables 来实现其功能，但它不被用来直接使用 iptables 命令。UFW 使用自己的命令来配置防火墙，这些命令被转换为 iptables 命令并执行。 查看 ufw 状态 1sudo ufw status 禁用所有端口 1sudo ufw deny all 开放 22 端口(ssh 的默认端口，禁用可能导致服务器失联) 1sudo ufw allow 22 开放 80 端口 1sudo ufw allow 80 开放 443 端口 1sudo ufw allow 443 启用 ufw 1sudo ufw enable 包管理器是什么Linux 常用命令常用的一些debug手段","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Vue.js","slug":"Vue-js","permalink":"https://zhul.in/tags/Vue-js/"},{"name":"Caddy","slug":"Caddy","permalink":"https://zhul.in/tags/Caddy/"}]},{"title":"在运行OpenWRT的N1盒子上部署 QQBot","slug":"run-qq-bot-on-phicomm-n1-openwrt","date":"2023-07-30T20:11:31.000Z","updated":"2023-10-28T17:48:04.000Z","comments":true,"path":"2023/07/31/run-qq-bot-on-phicomm-n1-openwrt/","link":"","permalink":"https://zhul.in/2023/07/31/run-qq-bot-on-phicomm-n1-openwrt/","excerpt":"","text":"由于学校社团的招新需要，我写了一个依赖于 go-cqhttp 运行的 QQ Bot，并没有实现什么花里胡哨的功能，只是实现了关键词回复和新人入群时的欢迎语。因为没考虑后续维护的问题，代码也写得比较草，但毕竟是能跑。这么一个小型的程序并不会占用的多少的服务器资源，单独为这么一个 Bot 去开一台国内的 vps 似乎是有些大材小用了，刚好我手上有一台运行在 OpenWRT 上的 Phicomm N1 盒子，反正也是 Linux 系统，便打算拿来挂 QQ Bot。 安装 JDK由于腾讯近几个月对于 Bot 风控非常严格，所以不得不采用 SignServer 项目 fuqiuluo/unidbg-fetch-qsign 来确保 Bot 账号不会被风控一次保证 Bot 运行的稳定性。而这个项目又是使用 Java 开发的，因此需要先安装 JDK/JRE。但 OpenWRT 的开发者可能并没有考虑到在路由器设备上运行 Java 程序的需求，因此 OpenWRT 的源里面是没有预先打包 JDK 的，因此我们需要额外安装。我直接 google 搜索了 install java on openwrt 的关键词，在 Github 找到了这个脚本: https://gist.github.com/simonswine/64773a80e748f36615e3251234f29d1d。但很遗憾，代码跑不起来，下载时提示 404。于是我打开脚本细细一看，脚本中 jdk 的版本号和设备的架构均需要改动。具体改动如下: 123456789101112131415- REVISION=8.212.04-r0+ REVISION=8.302.08-r1# 版本号请自行去仓库内翻最新的......- URL=http://dl-cdn.alpinelinux.org/alpine/v3.10/community/armv7/+ URL=http://dl-cdn.alpinelinux.org/alpine/v3.14/community/aarch64/......- # verify packages- sha256sum -c &lt;&lt;EOF- e2fce9ee7348e9322c542206c3c3949e40690716d65e9f0e44dbbfca95d59d8c openjdk8-8.212.04-r0.apk- 26ad786ff1ebeeb7cd24abee10bc56211a026a2d871cf161bb309563e1fcbabc openjdk8-jre-8.212.04-r0.apk- 947d5f72ed2dc367c97d1429158913c9366f9c6ae01b7311dd8546b10ded8743 openjdk8-jre-base-- 8.212.04-r0.apk- c6a65402bf0a7051c60b45e1c6a8f4277a68a8b7e807078f20db17e0233dea8e openjdk8-jre-lib-8.212.04-r0.apk- EOF# 我这里直接将 sha256 校验给删除了，有兴趣可以自己去更新这几个文件的文件名和其对应的哈希值 随后 chmod +x 授予脚本可执行权限后直接执行，我们就将 alpine linux 上的 openjdk 成功解包并安装到了我们的 OpenWRT 中，我们只需要配置好环境变量即可完成安装。但我又比较懒，我看见 SignServer 的启动脚本里是可以通过读取 $JAVA_HOME 来获取 Java 二进制可执行文件的代码逻辑，于是我便在每次启动 SignServer 脚本前提前执行 export JAVA_HOME=/opt/java-1.8-openjdk 即可。 安装 screen相比起前面 JDK 的安装，这一步 screen 的安装反而没有那么麻烦，在最新版本的 OpenWRT 源中，screen 已经被包括进去了，我们直接把 OpenWRT 换好源，从源里就可以安装。 12opkg updateopkg install screen 下载 fixed 版本的 go-cqhttp由于 SignServer 更新，在其请求中多添加了 key 的参数要求，导致原版 go-cqhttp 的最新 release 中释出的二进制文件无法适配最新版的 SignServer，我暂时选用了一个修复了这个问题的 fork 去运行 Bot。下载到 OpenWRT 后记得也要授予可执行文件。 安装 Python 脚本中所需要使用到的库OpenWRT 自带了 python 和 pip，这让我很欣慰。直接使用 pip 安装 flask 和 xlrd 等库即可，完全没有难度。 运行 SignServer这一步很简单，将原项目的 Release 下载下来解压后上传到 OpenWRT 的某个路径后，开个 screen 窗口，设置好 JAVA_HOME 变量后再去调用 SignServer 中自带的 shell 脚本即可 运行 go-cqhttp这一步也很简单，得益于 go 静态链接的特性，我们不需要为 go-cqhttp 安装任何额外的依赖就可以执行 Release 中的二进制文件，直接将我们在 PC 上登录好的 session、配置好的 device.json、config.yml 等文件上传到 N1 ，开个 screen 窗口运行即可。 运行主程序这个没什么好讲的，同样是开个 screen 窗口运行 python main.py 的事情 python 代码如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162from flask import Flask,requestimport requestsimport xlrd# 读取 xls 中的关键词以及回应语句，将其加载到 dict 数据结构中_data2 = xlrd.open_workbook(&#x27;/root/8yue222.xls&#x27;)main_table2 = _data2.sheets()[0]key_lst2 = main_table2.col_values(0)[1:]value_lst2 = main_table2.col_values(1)[1:]final_dict = dict(zip(key_lst2,value_lst2))# 读取第二份 xls，并对相同的关键词做覆盖_data = xlrd.open_workbook(&#x27;/root/daihao.xls&#x27;)main_table = _data.sheets()[0]key_lst = main_table.col_values(4)[1:]key_lst = [str(int(item)) if type(item) == float else item for item in key_lst if item != &#x27;&#x27;]key_lst.remove(&#x27;Gary&#x27;)value_lst = main_table.col_values(5)[1:]value_lst = [str(int(item)) if type(item) == float else item for item in value_lst if item != &#x27;&#x27;]final_dict.update(dict(zip(key_lst,value_lst)))app = Flask(__name__)class API: @staticmethod def send(message): url = &quot;http://127.0.0.1:5700/send_msg&quot; data = request.get_json() params = &#123; &quot;group_id&quot;:data[&#x27;group_id&#x27;], &quot;message&quot;:message &#125; requests.get(url,params=params)@app.route(&#x27;/&#x27;, methods=[&quot;POST&quot;])def post_data(): data = request.get_json() print(data) if data[&#x27;post_type&#x27;] == &#x27;message&#x27;: message = data[&#x27;message&#x27;] messagex() elif data[&#x27;post_type&#x27;] == &#x27;notice&#x27; and data[&#x27;notice_type&#x27;] == &#x27;group_increase&#x27;: welcome() else: print(&quot;忽略消息&quot;) return &quot;OK&quot;def messagex(): data = request.get_json() message = data[&#x27;message&#x27;].replace(&#x27;％&#x27;,&#x27;%&#x27;) for key in final_dict.keys(): if key == message: API.send(final_dict[key]) breakdef welcome(): data = request.get_json() group_id = data[&#x27;group_id&#x27;] user_id = data[&#x27;user_id&#x27;] API.send(&quot;[CQ:at,qq=&#123;&#125;] 欢迎来到浙江工业大学，精弘网络欢迎各位的到来！如果想进一步了解我们，请戳精弘首页：www.jh.zjut.edu.cn\\n输入 菜单 获取精小弘机器人的菜单 哦！\\n请及时修改群名片\\n格式如下：姓名+专业/大类&quot;.format(user_id))if __name__ == &#x27;__main__&#x27;: app.run(host=&#x27;0.0.0.0&#x27;, port=5701) 参考资料: https://gist.github.com/simonswine/64773a80e748f36615e3251234f29d1d https://blog.csdn.net/qq_64126275/article/details/128586651","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Bot","slug":"Bot","permalink":"https://zhul.in/tags/Bot/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"}]},{"title":"在浙工大宿舍使用路由器连接移动网络(校园网)","slug":"connect-china-mobile-with-router-in-zjut-dormitory","date":"2023-06-24T06:30:24.000Z","updated":"2024-09-26T07:36:01.000Z","comments":true,"path":"2023/06/24/connect-china-mobile-with-router-in-zjut-dormitory/","link":"","permalink":"https://zhul.in/2023/06/24/connect-china-mobile-with-router-in-zjut-dormitory/","excerpt":"","text":"上一篇博客中，我为 Redmi AC2100 刷入了 Padavan，接下来就打算使用这台路由器进行联网。其实小米大多数路由器都是支持 l2tp 的协议的，只需要在路由器后台稍微设置一下就能上网，服务器 ip 填 192.168.113.1，账号密码就是 hxzha+手机尾号后8位，密码就是手机尾号后6位。我使用 Padavan 是我个人有一些别的官方固件所不能提供的功能。 2024.04.09 Updates: 几天前移动对网页认证的页面进行了更新，原有的脚本失效，本博客已更新适配新版网页认证的脚本。 2023.7.10 Updates: 首先，搬到屏峰校区以后，l2tp 服务器确实依然为 192.168.115.1，这点挺奇怪的。 然后我发现 6.26 我的那个解决方案过于复杂，原先写的认证脚本完全可以胜任这项工作，之前失败的原因是因为我在朝晖抓的脚本参数不适用于屏峰校区，目前已经修复。脚本的变动情况可以看这里。 2023.6.26 Updates: 在我于 2023 年 6 月 26 日搬去屏峰校区以后，发生了连不上网的情况。目前一个可行的方案: 在 192.168.210.100 将自己的 MAC 地址全部解绑，然后使用自己的一台设备连接网线接口，正常通过网页验证。随后在 192.168.210.100 查看刚才通过网页验证的设备的 MAC 地址，将这一串 MAC 地址复制到 Padavan 的「外部网络（WAN）- MAC 地址」中，且将 l2tp 服务器改为 192.168.115.1 （没错，填朝晖的可以用）并重新连接 l2tp。 l2tp 相关设置我们将 WAN 口插上墙壁一侧的网口，左侧菜单栏点击外部网络，将外网连接类型改为 l2tp DNS 建议前两个填写学校的内网 DNS 地址( 172.16.7.10 ， 172.16.7.30)，最后一个填一个稳定的公共 DNS 即可，由于这一步是可选项，所以就不提供截图了。 往下拉，设置 l2tp 相关的设置项，只需要设置红色框框内的设置项即可。朝晖的 l2tp 服务器 ip 是 192.168.115.1 ， 屏峰校区是 192.168.113.1 ，这里不要填错了。 网页认证脚本 做完这些步骤，其实就可以正常上网了，只不过每次断网以后可能都需要重新过一遍验证，所以我专门写了一个脚本去过这个验证。 这份脚本我已经开源到 github gist 了，在顶部填好自己网页认证时的账号密码以后就可以用了。 顶部 TODO 处要写的账号密码就是那个有图书馆背景的网页认证密码。 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bash# Login webpage identify for China Mobile in Zhejiang University of Technology automatically# Author: zhullyb# Email: zhullyb@outlook.com# TODO: Fill Your Account and Password for 192.168.210.112/192.168.210.111 hereuser_account=user_password=if `ip route | grep -q 10.129.0.1`; then gateway=10.129.0.1elif `ip route | grep -q 10.136.0.1`; then gateway=10.136.0.1fiif whoami | grep -q &quot;admin\\|root&quot; &amp;&amp; [ -n &quot;$gateway&quot; ]; then route add -net 192.168.210.111 netmask 255.255.255.255 gw $&#123;gateway&#125; route add -net 192.168.210.112 netmask 255.255.255.255 gw $&#123;gateway&#125; route add -net 192.168.210.100 netmask 255.255.255.255 gw $&#123;gateway&#125; route add -net 172.16.0.0 netmask 255.255.0.0 gw $&#123;gateway&#125;fi# 尝试访问内网服务器，如果未通过网页认证则会获得 url 跳转信息，用于判断用户为朝晖校区或屏峰校区，并获取用户 iptest_curl=$(curl -s http://172.16.19.160)wlan_user_ip=$(echo $&#123;test_curl&#125; | grep -oE &#x27;wlanuserip=[0-9\\.]+&#x27; | grep -oE &#x27;[0-9\\.]+&#x27;)wlan_ac_ip=$(echo $&#123;test_curl&#125; | grep -oE &#x27;wlanacip=[0-9\\.]+&#x27; | grep -oE &#x27;[0-9\\.]+&#x27;)wlan_user_mac=$(echo $&#123;test_curl&#125; | grep -oE &#x27;usermac=[[:xdigit:]-]+&#x27; | cut -d&#x27;=&#x27; -f2 | tr -d &#x27;-&#x27;)wlan_ac_name=$(echo $&#123;test_curl&#125; | grep -o &quot;wlanacname=[^&amp;]*&quot; | cut -d&#x27;=&#x27; -f2)# 朝晖校区宿舍楼内的移动宽带的认证请求if echo &quot;$&#123;test_curl&#125;&quot; | grep -q &quot;192.168.210.112&quot;; then \\curl &quot;http://192.168.210.112:801/eportal/portal/login?callback=dr1003&amp;login_method=1&amp;user_account=%2C0%2C$&#123;user_account&#125;%40cmcczhyx&amp;user_password=$&#123;user_password&#125;&amp;wlan_user_ip=$&#123;wlan_user_ip&#125;&amp;wlan_user_ipv6=&amp;wlan_user_mac=$&#123;wlan_user_mac&#125;&amp;wlan_ac_ip=$&#123;wlan_ac_ip&#125;&amp;wlan_ac_name=$&#123;wlan_ac_name&#125;&amp;jsVersion=4.2.1&amp;terminal_type=1&amp;lang=zh-cn&amp;v=5099&amp;lang=zh&quot;# 屏峰校区宿舍楼内的移动宽带的认证请求elif echo &quot;$&#123;test_curl&#125;&quot; | grep -q &quot;192.168.210.111&quot;; then \\curl &quot;http://192.168.210.111:801/eportal/portal/login?callback=dr1003&amp;login_method=1&amp;user_account=%2C0%2C$&#123;user_account&#125;%40cmccpfyx&amp;user_password=$&#123;user_password&#125;&amp;wlan_user_ip=$&#123;wlan_user_ip&#125;&amp;wlan_user_ipv6=&amp;wlan_user_mac=$&#123;wlan_user_mac&#125;&amp;wlan_ac_ip=$&#123;wlan_ac_ip&#125;&amp;wlan_ac_name=$&#123;wlan_ac_name&#125;&amp;jsVersion=4.2.1&amp;terminal_type=1&amp;lang=zh-cn&amp;v=5099&amp;lang=zh&quot;fi 在 Padavan 的设置界面中，我们去打开 ssh 服务 在自己的电脑上通过 ssh 连接到路由器的终端 ssh admin@192.168.123.1，默认密码也是 admin，就和进入 Padavan 后台的默认管理密码一样。 看了一下 Padavan 并没有自带 nano 这个方便的 tui 编辑器，只好用自带的 vi 将就一下将认证代码复制到路由器中。 1vi /etc/storage/login_edu.sh 关于 vi 的使用方法我在这里也不展开讲，我个人也不熟悉这款编辑器。 将脚本复制进去后，记得输入自己网页认证的账号密码，然后保存离开，给这个脚本赋予 x 权限。 1chmod a+x /etc/storage/login_edu.sh 随后运行 crontab -e ，设置运行脚本为每天早上 6 点 01 分执行一次（因为工作日凌晨 00:30 断网，早上网络恢复以后有可能会要求你通过网页认证后才能再次联网） 1 6 * * * /etc/storage/login_edu.sh 随后来到路由器的设置界面，设置「在 WAN 上行/下行启动后执行」和「在防火墙规则启动后执行」这两个地方分别调用我们的网页认证脚本，防止因停电、网线接口松动等故障恢复后依然没法联网的问题。图中的 logger 命令是给我自己排错看的，不需要设置。","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Router","slug":"Router","permalink":"https://zhul.in/tags/Router/"}]},{"title":"为红米 Redmi AC2100 路由器刷入 Padavan","slug":"redmi-ac2100-router-with-padavan","date":"2023-06-23T16:22:53.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2023/06/24/redmi-ac2100-router-with-padavan/","link":"","permalink":"https://zhul.in/2023/06/24/redmi-ac2100-router-with-padavan/","excerpt":"","text":"大一一年转眼就要过去了，最近要搬校区了，顺手就把之前刷过的「小米路由器4A千兆版」出手给了同学，自己反手入了一个 「Redmi AC 2100」，尽管是跟着教程走，但过程中依然是遇见了不少坑，因此就开一篇博客记录了一下。 重置路由器这一步其实可有可无，只是我从闲鱼上入手这个路由器，买家并没有告知我密码，于是我只能手动 RESET 这个路由器来进入后台。 通过网络设置引导原本就是连上路由器后简单地通过引导界面，但由于我没有一个正常的网络环境，所以这一步走的其实也是有点困难的，我还是稍微记一下。 首先浏览器地址栏输入 192.168.31.1 (小米家的路由器默认好像都是这个 ip 地址)，看到下图界面，加不加入用户改善计划其实都是无所谓的，反正马上就要刷掉这个系统了。 此处选择「不插网线，继续配置」，因为我们没有标准的网络环境，还指望着这台路由器跑 l2tp 帮我们连校园网呢。 这里需要选择「自动获取IP」（静态 IP）好像也行，但别的选项在我的网络环境下恐怕都是没法继续配置下去的。 随后随手输个 WIFI 名称和密码，主要是记住密码进路由器后台管理。 设置完上述设置项以后，再次进入 192.168.31.1 ，就能看见路由器后台管理的登陆页面了。 获取 ssh 权限输入登陆密码，进入路由器后台管理页面，我们需要通过 bug 去获取打开官方系统的 ssh 功能 这里提一嘴，当初我刷小米路由器4A千兆版的时候用的是这个仓库来打开 ssh。 首先是确认路由器的版本，我从闲鱼上购得的路由器自带的版本是官方稳定版 2.0.23，一开始跟着别人的思路就降级到了 2.0.7，但后来遇见问题在网上查解决方案的时候看到有人说这个漏洞在 2.0.23 依然可用，但我也没有去试。 在电脑上下载 2.0.7 的升级包，在路由器设置界面的常用设置-&gt;系统状态-&gt;手动升级 选择自己下载的升级包，确认等待重启即可。有些教程说可以选择保留数据，但我也懒得试，就直接清除了所有数据，又不得不再次过一遍上面的配置引导。 在地址栏，删除 /web/home#router 部分，加入下面这串代码 1/api/misystem/set_config_iotdev?bssid=Xiaomi&amp;user_id=longdike&amp;ssid=-h%3B%20nvram%20set%20ssh_en%3D1%3B%20nvram%20commit%3B%20sed%20-i%20&#x27;s%2Fchannel%3D.*%2Fchannel%3D%5C%22debug%5C%22%2Fg&#x27;%20%2Fetc%2Finit.d%2Fdropbear%3B%20%2Fetc%2Finit.d%2Fdropbear%20start%3B 再次删除后面的代码，加入下面这串代码 1/api/misystem/set_config_iotdev?bssid=Xiaomi&amp;user_id=longdike&amp;ssid=-h%3B%20echo%20-e%20&#x27;admin%5Cnadmin&#x27;%20%7C%20passwd%20root%3B 两次请求的正常反馈应该长成下面这个样子。 此时应该就可以使用 ssh 访问路由器的 root 账户了，密码已经被改为了 admin 1ssh -o HostKeyAlgorithms=+ssh-rsa -o PubkeyAcceptedKeyTypes=+ssh-rsa root@192.168.31.1 刷入 breed如果用我在安卓刷机的经验来讲 breed 是什么的话，我会把他类比成第三方 Recovery (TWRP)。这是一个能够帮助你去输入系统、备份系统的恢复模式。虽然我们可以直接刷入 padavan，但如果系统没有自带镜像刷写工具或者输入的系统打不开了，那可能就是一台路由器的报废，或许得靠编程器才能救回来。 首先，我们到 breed 下载站上下载 breed 的镜像: https://breed.hackpascal.net/ 随后，在电脑上这个存放了 breed 镜像的路径上开一个 http server，我这里选择的是 darkhttpd，Windows 或者 MacOS 用户可以选择使用 miniserve，他们呢起的是一样的效果，甚至可以使用 python 直接开一个 local server。 接下来，通过自己电脑在路由器局域网内的那个 ip 地址并添加端口号在浏览器上访问你开的 http server，直接右键复制 breed 镜像的下载链接。 将 ssh 连接到的路由器终端 cd 到 /tmp 路径下，使用 wget 命令去下载你刚刚复制到的 url，这样我们就简单地将 breed 镜像传输到了路由器的内存上。再使用 mtd -r write breed-mt7621-xiaomi-r3g.bin Bootloader 刷入 breed，刷入成功后 ssh 将会自动断开连接，但并不会直接进入 breed。 我们需要先断开路由器的电源，使用一根针（比如取卡针）怼在 RESET 按钮上面，再次接通路由器的电源并持续按压 RESET 按钮几秒钟，浏览器这时就会进入 breed 状态，浏览器访问 192.168.1.1 就可以看到他的控制面板。 刷入 Padavan在 Breed 中拥有很多的功能，不过我们用到的只是「固件更新」这一个功能，备份功能什么的可以自己尝试，这只是一个可选项。 首先去下载站下载适配 Redmi AC2100 的 Padavan 镜像: https://opt.cn2qq.com/padavan/ 然后在 Breed 的 web 端控制台直接选择 Padavan 的系统镜像进行固件更新 确认后直接刷入 自动重启后，Padavan 就刷入完成了。 Padavan 的默认 WIFI 名是 PDCN 和 PDCN_5G，WIFI 密码是 1234567890 浏览器输入 192.168.123.1 就可以进入默认的后台管理页面，管理页面的用户名和密码都是 admin 参考文章: 《小米/红米AC2100刷OpenWrt/Padavan/第三方固件的详细教程（2022年8月23日更新）》 《小米、红米 AC2100 一键开启 SSH，可自定义安装各种插件》 《解决SSH no matching host key type found 问题》","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Router","slug":"Router","permalink":"https://zhul.in/tags/Router/"}]},{"title":"Azure 教育订阅申请时遇到的麻烦","slug":"troubles-when-applying-azure-education","date":"2023-05-12T15:38:29.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2023/05/12/troubles-when-applying-azure-education/","link":"","permalink":"https://zhul.in/2023/05/12/troubles-when-applying-azure-education/","excerpt":"","text":"进入大学已经快一年了，但我的 Azure 教育订阅申请一直没有成功，每年有 100 刀的额度，再这样下去就要亏掉近 700 元了，于是便打算趁期中考试刚结束的闲暇时间把 Azure 的教育订阅给过了。 我拥有 *.edu.cn 的邮箱，并且通过了 Github Student Pack 的认证，但每次在 https://signup.azure.com/studentverification?offerType=1 页面尝试申请 Azure 订阅时，总是会得到一句冷冷的「你没有资格使用 Azure 免费帐户」。于是，我找到了 Azure 订阅支持客服帮忙，链接是这个: https://azureforeducation.microsoft.com/en-us/institutions/Contact，简要填写了我的基本信息后就开始等待邮件回复了。 我是周四上午申请的，不到一个小时就等来了微软的工单生成通知 但光有这工单也没有用，我只能继续等人工客服的介入。 在周五的早上十点，我收到了来自人工客服的邮件，并且在几分钟后收到了来自人工客服的电话（电话是 021 开头的，是归属地为上海的座机打来的，但客服操着严重的港台口音，可能是港台那边的客服通过上海的座机中转打给我的？）: 但很显然，这封邮件并没有提供任何行之有效的方案，我只能按照邮件中的指示将我的截图发了过去。不过客服不知道出于什么原因一定要求全屏截图（如果电话说的是全面屏，那也是指 PC 端的全屏截图），可能是他们有什么工作制度吧。回复邮件的时候一定要选择回复全部，好像是他们只使用 &#115;&#117;&#112;&#112;&#x6f;&#114;&#x74;&#64;&#x6d;&#97;&#x69;&#x6c;&#x2e;&#115;&#x75;&#x70;&#x70;&#111;&#114;&#x74;&#x2e;&#109;&#x69;&#x63;&#114;&#111;&#115;&#111;&#102;&#x74;&#46;&#99;&#111;&#x6d; 这一个邮箱与我们通信，微软的服务器收到内容后会将我们发送的内容再抄送给给我们分配的客服手上，如果不选择「回复全部」的话，客服可能就看不到之前的通信记录了。 于是就在当天下午的2点收到了人工客服的第二封邮件，说是已经帮我提交到了后台处理。 20 分钟后，我收到了这封应该是系统自动发送的邮件，说明我的账号因异常而触发了审查所以过不了 Azure 的教育订阅，需要我提交能够佐证我的学生身份的东西上去，当晚7点我便按照要求回信。 当晚8点半，我便收到了来自系统的消息，得知异常已经解除，再次申请 Azure 学生认证就成功了。","categories":[],"tags":[{"name":"Azure","slug":"Azure","permalink":"https://zhul.in/tags/Azure/"}]},{"title":"执行 repo sync 后将 git-lfs 中的资源文件 checkout","slug":"checkout-lfs-file-after-repo-sync","date":"2023-05-02T17:15:35.000Z","updated":"2023-05-02T17:33:23.000Z","comments":true,"path":"2023/05/03/checkout-lfs-file-after-repo-sync/","link":"","permalink":"https://zhul.in/2023/05/03/checkout-lfs-file-after-repo-sync/","excerpt":"","text":"最近期中考试挺忙的，五一好不容易有一些自己的时间，于是打算重操旧业，搞点有意思的内容，没想到准备阶段就出了新问题，有点跟不上时代了 本次遇到的问题是在执行 repo sync 命令后储存在 git-lfs 中的文件没有被自动 pull 并 checkout 出来，尽管我在 repo init 阶段已经加了 --git-lfs 参数了。 上 google 简单查了查，查到一篇 stackoverflow 的回答，给出的思路是使用 repo forall -c &#39;git lfs pull&#39; 的方案解决的，意思是在 repo 同步的每一个 git 仓库中都自动执行 git lfs pull 命令，但这个解决方案在我这有两个问题。 仓库的 git-lfs 没有被安装，所以 git-lfs 会直接报错 将整个安装源码一千多个仓库一一执行这些命令的速度太慢了 解决方案也很简单，直接检测每个 git 仓库下是否存在 .lfsconfg 文件，存在的话就执行 git lfs install &amp;&amp; git lfs pull 1repo forall -c &#x27;test -e .lfsconfig &amp;&amp; git lfs install &amp;&amp; git lfs pull&#x27;","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"隐式转发——骚套路建站方案","slug":"implicit-forwarding-is-a-new-site-deploying-method","date":"2023-03-25T16:10:02.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2023/03/26/implicit-forwarding-is-a-new-site-deploying-method/","link":"","permalink":"https://zhul.in/2023/03/26/implicit-forwarding-is-a-new-site-deploying-method/","excerpt":"","text":"其实很久以前就接触到了国内 DNS 解析服务商提供的这个「隐式 URL」 这种 “DNS 记录类型”了，但我域名没有备案，一直没有机会去体验。 今天社团内某个同学在折腾自己博客的时候又用到了「隐式 URL」，于是就借此机会了解了一下相关内容。 DNSPOD 文档的描述如下 隐性转发：用的是 iframe 框架技术、非重定向技术，效果为浏览器地址栏输入 http://www.dnspod.cn 回车，打开网站内容是目标地址 http://cloud.tencent.com/ 的网站内容，但地址栏显示当前地址 http://www.dnspod.cn 。 也就是说，所谓「隐式 URL」，只不过是域名解析的服务商用他们的服务器去响应了访客的请求，并回应了一段使用了 iframe 的 html 。这段代码打开了一个大小为 100% 的窗口去请求了被“隐式代理”的站点。我这位同学域名是备案在阿里云下的，阿里云所使用的 html 代码如下: 1&lt;!doctype html&gt;&lt;html&gt;&lt;frameset rows=&quot;100%&quot;&gt;&lt;frame src=&quot;http://example.com&quot;&gt;&lt;noframes&gt;&lt;a href=&quot;http://example.com&quot;&gt;Click here&lt;/a&gt;&lt;/noframes&gt;&lt;/frameset&gt;&lt;/html&gt; 在下图中，我通过更改 hosts 文件实现将百度的域名在本地被解析到 localhost，并使用 iframe 标签将 b 站嵌入到页面中。当然，这并不能说明什么事情，不过是我个人的恶趣味罢了。 将 http://example.com改为目标站点，我们完全可以摆脱国内云服务商，在自己的服务器上直接实现「隐式代理」的效果。 而这种方案，恰巧可以用于在境内机子上建站，尤其是针对未备案的域名。 碍于 Github Pages 在境内的访问体验并不好，所以直接把博客部署在 Github Pages 下一直都不是首选，因此很多人都会选择去购买一台境内的小鸡，带宽虽然不大，但跑个博客什么的其实没什么大问题，但备案就很麻烦了。 我们可以通过在 Github Pages（或者其他境外的服务器） 上挂一个 index.html ，html 中使用 iframe 嵌套一个部署在境内小鸡上的网页来规避掉备案的问题。而境内小鸡可以选用非标准端口去监听请求。 这样带来的好处是访客只需要从境外的服务器上获取一个不到 1 KB 大小的 html ，随后的所有请求都是指向境内云服务器的，所以网页打开时的体验会得到改善。 隐式转发拥有以下优势： 直接向境内的云服务器发送请求，速度会得到改善 （相比于直接部署在境外服务器上的方案） 不怎么消耗境外服务器的流量 （相比于使用境外服务器反向代理的方案） 浏览器的地址栏不会直接显示 ip 或端口号（相比于未备案使用境内服务器的非标准端口的方案） 不需要备案（相比于备案后使用境内服务器的 80/443 端口的方案） 但也存在以下劣势： 移动端设备访问时好像还是会展示 PC 端的界面（存疑 现代浏览器访问时可能会有 strict-origin-when-cross-origin 的问题（一般好像是出现在 iframe 的 html 是 https 访问，而目标站点是 http 访问的情况？） 一些古老的浏览器可能不支持 iframe （？ 访问目标站点的其他路径时，浏览器地址栏的显示的地址不会变 那么应某些群友的要求，本文的第二作者为 Finley，通信作者为 LanStarD。","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"}]},{"title":"在 vps 上配合 caddy 部署 siteproxy","slug":"deploy-siteproxy-with-caddy-on-vps","date":"2023-02-01T14:33:53.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2023/02/01/deploy-siteproxy-with-caddy-on-vps/","link":"","permalink":"https://zhul.in/2023/02/01/deploy-siteproxy-with-caddy-on-vps/","excerpt":"","text":"之前趁着春节活动的时候在某 vps 服务商买了 1 年的 vps，线路不算太好，但勉强够用，于是打算在上面部署一些反代程序。在群友的推荐下，发现了这款名为 siteproxy 的开源项目。 siteproxy 相较于我在 r.zhullyb.top 部署的那个反代，其特点是可以运行在 vps 上，且将会替换被反代页面上的所有 url，因此遇到使用相对路径的网页也可以从容应对。 在项目的 README 中介绍了一种部署方案，但我仍有以下几点不太满意 README 中的方案仅支持 nginx 部署，但我希望使用 caddy README 中的方案使用 npm 安装了 forever 来达到保活的目的，甚至为此安装了 nvm，但我一不希望使用 npm 在系统上安装软件、二不希望安装 nvm 与 forever 原项目把根目录页做成了一个导航，指向了一些比较敏感的站点，而我希望换掉这个网页。 因此这篇博客也就应运而生。 反代 8011 端口根据项目 README 的描述，我们应当使用 nginx 去反代 127.0.0.1:8011 端口，但我是 caddy 用户，此前也有过使用 caddy 反代的经验，所以很容易写出一段使得程序可以正确运行的 Caddyfile。 12345678910example.com &#123; reverse_proxy 127.0.0.1:8011 &#123; header_up Host &#123;upstream_hostport&#125; header_up X-Real-IP &#123;http.request.remote.host&#125; header_up X-Forwarded-For &#123;http.request.remote.host&#125; header_up X-Forwarded-Port &#123;http.request.port&#125; header_up X-Forwarded-Proto &#123;http.request.scheme&#125; header_up Accept-Encoding identity &#125;&#125; 将 example.com 的 A 记录解析到 vps 主机的 ip，并使用 systemctl 重新启动 caddy，这一步就算完成了。 安装 nodejs我在 vps 上安装的发行版是 Archlinux，所以直接 pacman -S nodejs 安装完就是了，别的发行版应该也可以直接调用系统默认的包管理器安装 node 或者 nodejs 完成这一步。 下载程序首先，我们需要一个地方来存放我们下载的程序，我使用的是 /opt 路径。 我们可以直接根据 README 所说的，直接 clone 整个项目，但我本人并不想这么做，项目里似乎有太多对于 vps 用户没有用的东西了。此外，整个项目首页我也不想要，首页的导航指向了一些比较敏感的网站，而我的反代就想安安心心的一个人用。 综合以上需求，我所需要的文件一共就五个: 12345├── config.js├── index.js├── logger.js├── package.json└── Proxy.js 123mkdir -p /opt/siteproxycd /opt/siteproxywget https://raw.githubusercontent.com/netptop/siteproxy/master/&#123;config.js,index.js,logger.js,package.json,Proxy.js&#125; 然后补上一个 index.html 我这边选择直接使用 JavaScript 将对于 / 的访问直接重定向到我的博客。 1&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;refresh&quot; content=&quot;0; url=https://zhul.in/&quot; /&gt;&lt;/head&gt;&lt;body&gt;Redirect to &lt;a href=&quot;&quot;&gt;https://zhul.in/&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 安装依赖在 /opt/siteproxy 目录下执行 1npm install npm 将会根据 package.json 的内容自动安装所需的依赖。 修改配置文件1$EDITOR /opt/siteproxy/config.js 按照 README 所说，修改 serverName 字段 设置开机自启动这里我选择使用 systemd 帮助我实现 siteproxy 程序的开机自启动，service 文件是我直接根据 frp 程序提供的 service 改的。 1234567891011121314151617cat /usr/lib/systemd/system/siteproxy.service -----[Unit]Description=SiteProxyAfter=network-online.targetWants=network-online.target[Service]Type=simpleUser=nobodyRestart=on-failureRestartSec=5sEnvironment=&quot;NODE_PATH=/opt/siteproxy/&quot;ExecStart=node --tls-min-v1.0 /opt/siteproxy/index.js [Install]WantedBy=multi-user.target 随后使用 systemctl enable siteproxy --now 启动即可访问。 为反代站点添加访问密码（可选）参考我的另一篇博客。 使用防火墙程序禁止 8011 的公网访问（可选）","categories":[],"tags":[{"name":"nodejs","slug":"nodejs","permalink":"https://zhul.in/tags/nodejs/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"OpenSource Project","slug":"OpenSource-Project","permalink":"https://zhul.in/tags/OpenSource-Project/"},{"name":"siteproxy","slug":"siteproxy","permalink":"https://zhul.in/tags/siteproxy/"},{"name":"Caddy","slug":"Caddy","permalink":"https://zhul.in/tags/Caddy/"}]},{"title":"onedrive(by abraunegg) —— 一个 Linux 下的开源 OneDrive 客户端(cli)","slug":"onedrive-abraunegg-recommendation","date":"2022-12-24T14:40:13.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2022/12/24/onedrive-abraunegg-recommendation/","link":"","permalink":"https://zhul.in/2022/12/24/onedrive-abraunegg-recommendation/","excerpt":"","text":"这款 Linux 下的 OneDrive 客户端我其实一年前就已经在用了，最近打算给自己的 vps 重装系统并重新部署下 aria 的下载服务，顺便把上传到 OneDrive 的功能增加进去，便又想到了这款运行在命令行中的第三方开源 Linux 客户端，去谷歌上搜索了一番，依然没有什么成规模的中文博客去写它的用法，于是就打算自己来写。那肯定不是因为我博客这个月没有什么题材 安装abraunegg 用 D 语言写的 OneDrive 客户端安装起来并不是什么难事，Ubuntu/Debian/Fedora 等常见发行版的仓库中均有它的身影，具体情况在 Github 项目页面中都有描述。 在 Archlinux 下，我可以直接从 AUR/ArchlinuxCN 中安装 onedrive-abraunegg 这个包来安装这个项目。 1sudo pacman -S onedrive-abraunegg 运行前配置 本章内容中的所用到的和没有用到的命令都可以在该项目的 Github 仓库中找到。 在终端直接运行 onedrive 命令，程序将打印出一行地址。 使用浏览器打开地址，就会跳出微软的登陆页面，正常登陆即可。 登陆成功后，浏览器将会显示一片白屏，不必慌张，直接将浏览器地址栏中的网址复制后粘贴进终端中即可完成配置，获取到的 refresh_token 将会被保存到 $HOME/.config/onedrive 下。 账号授权成功以后我有两个迫切的需求需要在开始同步前解决: 我不希望把我 OneDrive 里所有的文件下载下来，我在 OneDrive 中存放了至少 1T 的数据，而我的系统盘就只有 512G，这绝对是放不下的，所以我想仅同步部分文件夹。 我需要修改被同步到的文件夹的路径，我不想把 OneDrive 上的文件下载到我的 /home 下。 要解决第一个需求，我们可以通过创建 sync_list 的方式指定我们要同步的文件，在 $HOME/.config/onedrive 路径下创建 sync_list ，并填入需要的文件或文件夹名，或在 !或- 后面写上不想同步的文件或文件夹名即可，支持通配符，在原仓库的文档中给出了非常详细的描述。 我们可以先使用 onedrive --display-config 命令查看我们当前的配置情况。（我这边直接应用 Github 文档中展示的内容） 12345678910onedrive version = vX.Y.Z-A-bcdefghiConfig path = /home/alex/.config/onedriveConfig file found in config path = trueConfig option &#x27;sync_dir&#x27; = /home/alex/OneDriveConfig option &#x27;enable_logging&#x27; = false...Selective sync &#x27;sync_list&#x27; configured = falseConfig option &#x27;sync_business_shared_folders&#x27; = falseBusiness Shared Folders configured = falseConfig option &#x27;webhook_enabled&#x27; = false 这很显然，OneDrive 中的文件默认将会被保存到 $HOME/OneDrive 中。为了修改这个位置项，我们直接在 $HOME/.config/onedrive/ 路径下创建一个名为 config 的文件，把此处给的 configuration examples 全部复制进去，找到 sync_dir 把前面的注释删掉，改成自己喜欢的路径 （别问我为什么写 /tmp，问就是我内存够大 修改好此处的配置文件后，可以再次运行 onedrive --display-config 检查自己的配置文件格式有没有问题、自己更改的配置项有没有生效，这样就解决了我的第二个需求。 Standalone Mode / Monitor Mode?这款 OneDrive 客户端支持以两种方式运行，monitor 模式将会监控本地磁盘上的文件状态，因而在同步路径内的文件从一个路径移动到另一个路径时，客户端将不会傻傻地执行「在原路径删除远端文件-重新上传新路径的本地文件」的这一个过程，具体使用 monitor 或 standalone 模式还请自行斟酌，可参考 Moving files into different folders should not cause data to delete and be re-uploaded . 开始同步使用该客户端执行同步的命令很简单，即 1onedrive --synchronize 但可选的运行参数很多，我只举出最常用的几个例子 –dry-run使用 --dry-run 选项后，OneDrive 将不会执行同步操作，它将在终端输出原本将会被执行的操作以供你排查自己的配置是否正确。 –local-first字面意思，--local-first 即为本地优先，同步时如果遇到文件冲突将会优先参考本地的情况。 –single-directory--single-directory 后面需要跟一个子文件夹在 OneDrive 根目录中的相对路径，这将使本次的同步操作仅对单个文件夹生效。 –download-only字面意思，--download-only 即为仅下载模式。 –upload-only字面意思，--upload-only即为仅上传模式，后跟 --no-remote-delete将不会在 OneDrive 网盘中删除本地相较于网盘中缺少的文件，真正做到 upload only. –resync当下列配置项被更改时，需要执行 --resync 来确保客户端正在按照更新后的配置文件来同步你的数据 sync_dir skip_dir skip_file drive_id Modifying sync_list Modifying business_shared_folders","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"OpenSource Project","slug":"OpenSource-Project","permalink":"https://zhul.in/tags/OpenSource-Project/"},{"name":"Experience","slug":"Experience","permalink":"https://zhul.in/tags/Experience/"},{"name":"OneDrive","slug":"OneDrive","permalink":"https://zhul.in/tags/OneDrive/"}]},{"title":"【翻译】关于2022年11月的事件的一些话[Z-Library]","slug":"a-few-words-about-the-events-of-november-2022","date":"2022-11-21T05:24:33.000Z","updated":"2022-11-21T07:28:38.000Z","comments":true,"path":"2022/11/21/a-few-words-about-the-events-of-november-2022/","link":"","permalink":"https://zhul.in/2022/11/21/a-few-words-about-the-events-of-november-2022/","excerpt":"","text":"正如我们所知道的那样，Z-Library 的主域名在前不久已经被美国警方给 take down 了，目前仅剩下 Telegram Bot 和 Tor 网络两种访问方式是我们仍然可以信任的。在11月18日，Z-Library 于其博客上发布了一篇新的文章（onion链接），此处是我的翻译版本。 As many of you know, on November 3rd most of our domains were seized and some our servers were suspended by the United States Department of Justice and Federal Bureau of Investigation. In addition, on November 16 the United States Department of Justice published the indictment against two citizens of Russia, Anton and Valeria. They are accused of criminal copyright infringement, wire fraud and money laundering to operate the Z-Library. 正如你们大多数人所知道的那样，在11月3日，我们大多数的域名和一部分服务器被美国司法部和联邦调查局封禁了。此外，在11月16日，美国司法部出发布了针对两个俄罗斯公民—— Anton 和 Valeria 的指控。他们因经营 Z-Library 而被指控犯有侵犯版权、电汇欺诈和洗钱等罪名。 We refrain commenting on the alleged Anton and Valeria involvement in the Z-Library project and the charges against them. We are very sorry they are arrested. We also regret that some authors have suffered because of Z-Library and ask for their forgiveness. We do our best to respond to all complaints about files hosted in our library if it violates author’s rights. 我们不评论 Anton 和 Valeria 涉嫌参与 Z-Library 项目的行为以及对他们的指控。我们对他们的被捕感到非常抱歉，也对一些因为 Z-Library 而遭受的损失的作者表示歉意，并请求他们的原谅。如果我们的网站中托管的文件侵犯了作者的权利，我们会尽最大努力回应所有的投诉。 We see the resonance recent events caused, we see how many people support and believe in Z-Library. Thank you for your support, it is extremely valuable to us. Thank you for each donation you make. You are the ones who making the existence of the Z-Library possible. We believe the knowledge and cultural heritage of mankind should be accessible to all people around the world, regardless of their wealth, social status, nationality, citizenship, etc. This is the only purpose Z-Library is made for. 我们看到最近发生的事件所引起的共鸣，我们看到了有多少人支持并信任 Z-Library。 感谢您的支持，这对我们来说极其珍贵。我们感激您的每一笔捐款，你们是使 Z-Library 的存在成为可能的人。 我们认为，人类的知识和文化遗产应该为全世界所有人所用，无论其财富、社会地位、国籍、公民身份等，而这，正是 Z-Library 存在的唯一目的。 My makeup may be flakingBut my smile still stays on 我的妆容可能会脱落但我的笑容将会永存","categories":[],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://zhul.in/tags/%E7%BF%BB%E8%AF%91/"},{"name":"Z-Library","slug":"Z-Library","permalink":"https://zhul.in/tags/Z-Library/"}]},{"title":"【已过期】使用 vercel+supabase 免费部署 umami","slug":"free-umami-deploy-plan","date":"2022-11-08T05:37:53.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2022/11/08/free-umami-deploy-plan/","link":"","permalink":"https://zhul.in/2022/11/08/free-umami-deploy-plan/","excerpt":"","text":"讲起静态网站的访客统计，我最先使用的是百度统计，但后来转到了 umeng，发现后续的几天百度爬虫的光顾次数反而多了起来。好家伙，使用百度统计相当于把自己网站访问量向百度全盘托出，我说我的博客怎么还不被百度收录呢。 后来，umeng 推出了新的服务条款，好像是说不再向未备案的站点提供服务，随后不得不转向自部署的开源网站统计程序。 umami 提供了多种部署方式，在 vps 上可以非常轻松地使用 docker 一键部署，但上次 vps 到期时用 1Mbps 的小水管拖了好久都没有把博客前几个月的访客数据拖下来，一气之下我选择直接丢掉了这些可有可无的数据。 所以这一次，我决定放弃在自己的 vps 上部署，转去探索免费的部署方案。 umami 的官方文档上提供了非常多的部署方案，我个人比较喜欢 vercel，本站的随机图片 api 就是挂在 vercel 上的，界面比较简洁，且境内访问还算OK。 但问题在于 vercel 本身并不提供免费的数据库，所以我们不得不去寻找一些长期免费提供数据库的供应商，我选择了 supabase。 在下图中选择顶栏的 Pricing 后看到这个 $0/month 就疯狂戳烂这个 Get Started 随便填写个项目名然后输入一个足够强大的密码，地区选择美国就行，东部西部无所谓（毕竟我也不知道 vercel 的机房是在东部还是西部） 看到这个小小的绿标就说明数据库正在初始化(你先别急，让我先急 随后打开官方文档，点击其描述 vercel 那一页中大大的 Deploy 初始化过程中，vercel 会要求你创建一个 git 仓库，一般私有库就够了。 随后需要我们设置两个环境变量，第一个 DATABASE_URL 就是我们刚刚从 supabase 中复制下来并替换好 password 的 url，第二个 HASH_SALT需要你随意生成一长串字符串（比如你可以找一个新手让他帮你退出 vim 点击 Deploy 并等上两分钟，我们就部署完啦（首页没东西，白屏是正常的 来到项目首页，点击任意域名即可访问到我们部署的 umami，不过 vercel 的域名近年来也有被污染的情况，建议在设置里绑定自己的域名。 哦对了，别忘了 umami 的默认用户名密码是admin和umami，别到时候点击进去看到登陆框一脸懵，这是在文档里写过的。","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"umami","slug":"umami","permalink":"https://zhul.in/tags/umami/"},{"name":"vercel","slug":"vercel","permalink":"https://zhul.in/tags/vercel/"},{"name":"OpenSource Project","slug":"OpenSource-Project","permalink":"https://zhul.in/tags/OpenSource-Project/"}]},{"title":"我的博客部署方案","slug":"my-blog-plan","date":"2022-11-04T08:41:28.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2022/11/04/my-blog-plan/","link":"","permalink":"https://zhul.in/2022/11/04/my-blog-plan/","excerpt":"","text":"一直以来，我的博客使用的几乎都是 Hexo 框架。 静态博客的一大优点就是可以支持 Serverless 部署，这使得我们可以直接在 Github Pages、Vercel 等平台直接部署上我的博客，如果用上 .eu.org 或者非洲国家免费域名就可以实现零成本的博客部署。 当然，我现在的博客并非是零成本搭建的，如你所见，我购入了印度国别域名 zhul.in 来凑出 竹林 的谐音。并在 Github Pages、Vercel 等平台的访问质量每况愈下的情况下又购入了位于香港的 VPS，这就引申出了今天的内容——介绍我博客的部署方案。 我的博客是使用 HK vps + Github Pages 两处部署实现的，通过 dnspod 免费版的域名分境内/外解析实现了分流。当境内的访客访问我的博客时，他们将会被解析到香港的 vps 上以获得更好的体验，而境外的访客将会被解析到 Github pages，毕竟 Github Pages 在境外的速度并不慢，并且稳定性肯定比我这小鸡要好得多。 不过关于通过 dns 解析分流这件事，之前看城南旧事的博客中有提到可以使用境外的 GeoScaling 完成，其免费支持全球分as、城市、经纬等智能解析，也支持自编辑脚本，看起来以后可以去试一试。 而 Hexo 框架最被人诟病的一点是更新麻烦。这一点不可否认，使用 hexo generate 生成静态网页文件再部署到服务器上的过程在一台新设备上是不小的工作量，它涉及 git、nodejs 的安装，涉及到 ssh key 和 rsync，整个环境的搭建就要废上不小的工夫。 在博客内容的更新方面，我选择了将整个 Hexo 的 workdir 全部上传到 github，使用 Github Action 帮助我同时完成静态页面的生成和 Github Pages 及 vps 的部署工作。具体的代码可以直接见我的 GIthub 仓库，我在这里简单讲下思路。 安装 nodejs 这个没什么可说的，有现成的 Github Action 去完成这件事，我这边直接使用了actions/setup-node@v2。 使用 npm/yarn 安装相关依赖 这个直接跑 yarn install 即可。 为每个文件重新设定最后修改时间 这一步其实是挺重要的，Hexo框架生成每篇文章的最后修改时间的依据是该文件的最后修改时间，而对于 Github Action 的容器来说，每一个文件都刚刚被下载下来，都是最新的，这就会导致你的每一篇文章每次部署时都会被认为刚才修改过。 我们这边可以直接使用 git 记录的时间来作为文件的最后修改时间。（参考 Sea’s Blog） 1git ls-files | while read filepath; do touch -d &quot;$(git log -1 --format=&#x27;@%ct&#x27; $filepath)&quot; &quot;$filepath&quot; &amp;&amp; echo &quot;Fixed: $filepath&quot;; done 设置时区 读我的博客的人应该大多都是东八区的人，那我们应当把 Github Action 容器的时区设置为东八区，和自己 git commit 时所使用的设备的时间保持一致，否则某些文章的日期可能会发生一天的偏移。 1export TZ=&#x27;Asia/Shanghai&#x27; 生成静态网页文件 1yarn build 部署到 Github Pages 使用 peaceiris/actions-gh-pages@v3 初始化 Github Action 容器上的 ssh 私钥 应当在 Github 仓库的设置里先新建一个 secret，填入自己的 ssh 私钥（更加标准的做法应当是为 github action 专门生成一对 ssh 密钥，将公钥上传到自己的 vps，将私钥上传到 Github 仓库的 secret 中）。 我这边直接从点墨阁那边抄了点代码直接用。 使用 hexo 的 deploy 插件调用 rsync 将静态文件上传到自己服务器的对应目录（static server 你应当已经设置好了） 1yarn deploy 注: 本篇博客中引用的所有博客页面均在 web.archive.org 进行了存档，如后续遇到页面打不开的问题请自行前往查询存档。","categories":[],"tags":[{"name":"Github Action","slug":"Github-Action","permalink":"https://zhul.in/tags/Github-Action/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Blog","slug":"Blog","permalink":"https://zhul.in/tags/Blog/"},{"name":"Hexo","slug":"Hexo","permalink":"https://zhul.in/tags/Hexo/"}]},{"title":"使用 VirtScreen 将 Pad 作为副屏","slug":"use-virtscreen-to-turn-pad-into-another-screen","date":"2022-10-03T16:19:20.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2022/10/04/use-virtscreen-to-turn-pad-into-another-screen/","link":"","permalink":"https://zhul.in/2022/10/04/use-virtscreen-to-turn-pad-into-another-screen/","excerpt":"","text":"由于浙江工地大专的朝晖尚9宿舍实在是太小了，我没有办法放下一块便携显示屏，所以只能把家中闲置的 Huawei Pad M6 作为自己的副屏。 经过一轮搜索下来，我找到了 VirtScreen 作为工具。 安装在 Archlinux 上，大概有三种以上的方式进行安装: 一、使用 AUR 上的 virtscreen 遇到的唯一一个麻烦是作为依赖之一的 python-quamash 在 python3.10 上无法直接安装。通过 AUR 的评论区得知，需要将 collections.Mapping 改为 collections.abc.Mapping 方可通过安装。 二、使用 dderjoel 的 fork 进行安装 见 https://github.com/dderjoel/VirtScreen/blob/master/package/archlinux/PKGBUILD 三、直接通过 appimage 安装，不过需要自己手动安装 x11vnc 配置系统层打开软件以后，我们需要先在 Display-&gt;Virtual Display-&gt;Advaced 选择 VIRTUAL1 作为显示屏。 如果没有这个选项，可能需要根据自己的显卡做出相应的调整。 可以参考 ArchWiki。 软件层在这里，我们需要根据我们作为副屏的设备的屏幕分辨率来计算我们需要在 VirtScreen 中设置的分辨率参数。 我的 Huawei Pad M6 是 2560*1600 的分辨率，但 VirtScreen 最高支持只有 1920*1080，所以我们需要选择 1280*800，并开启高分辨率选项。 VNC 那边只需要根据自己的需求设置一下密码即可。 使用在 VirtScreen 的 Display 界面点击 “Enable Virtual Screen”，切换到 VNC 界面点击 “Start VNC Server”，可以勾选右侧的 “Auto”。 Pad 端只需要安装任意一个 VNC 客户端即可，我这里使用的是”VNC Viewer”。 图片","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Hardware","slug":"Hardware","permalink":"https://zhul.in/tags/Hardware/"}]},{"title":"在 Archlinux 下使用 l2tp 协议连接校园网","slug":"use-l2tp-protocol-to-connect-internet","date":"2022-09-29T06:30:46.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2022/09/29/use-l2tp-protocol-to-connect-internet/","link":"","permalink":"https://zhul.in/2022/09/29/use-l2tp-protocol-to-connect-internet/","excerpt":"","text":"由于高考爆炸，所以不得不进入浙江工地大专来度过自己接下来四年的人生（希望到时候可以借助学校的力量润出去）。 学校这边由于某些不可描述的原因，将校园卡与宽带捆绑销售，且每次登陆校园网时都需要使用定制的 l2tp 协议客户端进行上网，且该客户端将会禁用用户的无线网卡（这不明摆着想让我们宿舍每个人都花一次钱）。 更惨的是，学校仅提供了 Windows 与 MacOS 的客户端。 在 BearChild 的提醒下，我意识到 Linux 下也可以有 l2tp 协议。 谷歌搜索了一番，我在简书上捞到了这篇文章《ubuntu 连校园网 via l2tp》。不过这显然有些麻烦，我们的客户端不需要 pppoe 拨号，只需要插上网线后连接 l2tp 协议即可联网。 所幸，NetworkManager 非常贴心地为我们提供了 l2tp 的插件，在 Archlinux 下使用如下命令即可完成安装。 1sudo pacman -S networkmanager-l2tp 安装完成后，就可以在图形化界面下进行我们的设置操作。 由于定制的客户端已经把 l2tp 服务器 ip 写死且显示在界面上了，我们就不需要再去抓包截取服务器 ip，直接使用这边的 192.168.115.1 即可。","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"}]},{"title":"为 Element 添加自己喜欢的贴纸","slug":"add-sticker-support-for-element","date":"2022-08-10T11:51:19.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2022/08/10/add-sticker-support-for-element/","link":"","permalink":"https://zhul.in/2022/08/10/add-sticker-support-for-element/","excerpt":"","text":"在读这篇文章之前，你应该已经知道 element、matrix 是什么，这部分内容咱就不过多展开讲了。 需要准备的 PC 端 element python3.6+ 环境 能够挂静态资源的站点（比如 Github Pages、Gitlab Pages、Vercel 等免费平台的账号） 可能需要能够突破大局域网限制的网络环境 需要用到的项目 maunium/stickerpicker 克隆主项目1git clone https://github.com/maunium/stickerpicker.git &amp;&amp; cd stickerpicker 使用 pip 安装依赖其实本来想直接用包管理去安装这个项目的依赖的，可惜我看了一眼依赖列表，有整整一半的依赖没有被 Fedora 打包，所以干脆就直接用 pip 安装算了。 1pip install . 选择一：将本地图片制成贴纸包在项目根目录下创新一个新的目录。 1mkdir &lt;pack directory&gt; 将需要的图片放入其中。如果需要排序，可以在图片的文件名最前面加上数字标号。 执行命令进行打包 1sticker-pack &lt;pack directory&gt; --add-to-index web/packs/ 如果想要给目录贴纸包命名，则可以追加--title &lt;custom title&gt;，否则将直接设置为目录名 选择二：从 tg 获取现成的贴纸包项目内已经为我们准备了 sticker-import 命令来帮助我们直接从 tg 获取表情包，那我们直接收下 1sticker-import &lt;pack_url&gt; 第一次使用时，会要求我们登陆 matrix 和 tg 账号 matrix 的 homeserver 和 access token 可以在 PC 端 element 的设置里找到 tg 登陆时需要你输入手机号码，或者某一个 tg bot 的 token，这个大家都懂。 运行完成后，贴纸包就被上传到了你所使用的 matrix homeserver 上。 接着我们需要做的事情就是将 web 文件夹部署到 github pages 等做成静态站点，这个比较简单，不再赘述，我这里直接部署在了 https://matrix-sticker.zhullyb.top 我们下文就直接拿它做演示，看得上的也可以直接拿来用。另外，@朝色 的 url 也可以直接拿来使用 https://sticker.zhaose.cyou/web/ 添加到 element这是本篇文章最吊诡的地方，element 其实并没有为我们准备这么一个添加自定义 sticker 的地方，从某种意义上讲，我们是把我们的 sticker 给 hack 进去。 在 element 的 pc 端找到任意一个对话框，输入 /devtools 并发送 将会出现如下页面，选择 Explore account data 找到 m.widgets，如果没有，就点击下图标出的按钮 在新的页面中，填写如下内容，url 那一行应当改为自己部署的页面，并发送请求 1234567891011121314&#123; &quot;stickerpicker&quot;: &#123; &quot;content&quot;: &#123; &quot;type&quot;: &quot;m.stickerpicker&quot;, &quot;url&quot;: &quot;https://matrix-sticker.zhullyb.top/?theme=$theme&quot;, &quot;name&quot;: &quot;Stickerpicker&quot;, &quot;data&quot;: &#123;&#125; &#125;, &quot;sender&quot;: &quot;@you:matrix.server.name&quot;, &quot;state_key&quot;: &quot;stickerpicker&quot;, &quot;type&quot;: &quot;m.widget&quot;, &quot;id&quot;: &quot;stickerpicker&quot; &#125;&#125; 重启 element，此时就可以享受到自己导入的 sticker 了，手机端的 element 设置也将会被同步。 补一张效果图","categories":[],"tags":[]},{"title":"nodejs16：是我配不上 openssl 3 咯？","slug":"a-fucking-store-about-openssl3-and-nodejs16","date":"2022-08-04T09:31:49.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2022/08/04/a-fucking-store-about-openssl3-and-nodejs16/","link":"","permalink":"https://zhul.in/2022/08/04/a-fucking-store-about-openssl3-and-nodejs16/","excerpt":"","text":"今年上半年升级 Fedora 36 的时候遇到了这个问题。 那会儿很无奈，一直在等 nodejs16 合并提供 --openssl-legacy-provider 的那个 PR。nodejs16 是一个 lts 版本，照道理来说，既然要提供 Long-term Support，而 openssl 1 作为它的依赖之一，生命周期结束又在 nodejs16 之前，那是不是应该给 nodejs16 backport 在 nodejs17 上实现的 --openssl-legacy-provider 参数选项呢？否则绝大多数发行版都会在 openssl 1 的生命周期结束之前切换到 openssl 3，那 nodejs16 不就没法用了嘛。 然而，nodejs 在他们的官网上发布的一篇博客刷新了我的世界观，而此前的那个 PR 甚至一度被关停。（此处有寒晶雪提供的中文翻译） 博客称他们将会把 nodejs16 的生命周期结束时间提前以防止 openssl 1 生命周期在 nodejs16 生命周期结束之前结束（这种做法甚至还有先例） 很无奈，那会儿有两个 npm 管理的软件没法在 Fedora 36 上编译出来，就一直搁置了下去。 不过好在，事情还是有转机的。（要不然就这档子鸡毛蒜皮的小事我也不会专门去写篇博客出来） 前几天我给 atpoossfl 仓库打了 rpm 版本的 nvm 以后，意外地发现 nvm 所提供的 nodejs 会自带 openssl。 所以我们只需要使用 nvm 安装的 nodejs16 即可解决 Fedora36 以后没有 openssl 1 的问题。 使用 Fedora 的用户需要注意，Fedora 官方源中的yarnpkg在打包时遇到了错误，他们将 /usr/lib/node_modules/yarn/bin/yarn.js 的 shebang 给改成了 #!/usr/bin/node，应当改回 #!/usr/bin/env node才能让 yarn 正常使用上 nvm 提供的 nodejs；或者干脆添加 dl.yarnpkg.com 提供的 yarn 软件包。在写 specfile 的 BuildRequires 时，可以直接写成 /usr/bin/yarn 来避免频繁在 yarn 和 yarnpkg 这两个包名间改动。 更好的消息是，nodejs 已经在 v16.17.0-proposal 和 v16.x-staging 分支收下了这个为 nodejs16 提供 --openssl-legacy-provider 的 commit。相信在不久的将来，这个 commit 将会进入主线，并在 v16.17 版本的 nodejs16 上发挥它的作用。","categories":[],"tags":[{"name":"Fedora","slug":"Fedora","permalink":"https://zhul.in/tags/Fedora/"},{"name":"nodejs","slug":"nodejs","permalink":"https://zhul.in/tags/nodejs/"},{"name":"openssl","slug":"openssl","permalink":"https://zhul.in/tags/openssl/"}]},{"title":"如何拯救失声的 hollywood","slug":"restore-the-sound-of-hollywood","date":"2022-07-25T03:25:44.000Z","updated":"2022-08-22T15:48:33.000Z","comments":true,"path":"2022/07/25/restore-the-sound-of-hollywood/","link":"","permalink":"https://zhul.in/2022/07/25/restore-the-sound-of-hollywood/","excerpt":"","text":"我刚开始接触 Linux 下的 hollywood 时，我记得它运行时是有声音的，应该是 007 的主题音乐，如今再次装上 hollywood，却发现音乐没了。 在 Github 找到 hollywood，发现有一个 issue 也提到了这个问题。 原作者在该 issue 中回复道 没错，它只是一段视频，音频受到版权保护。 所以不难看出，作者因为版权问题而去掉了音频，进而导致 hollywood 失声。但我们作为用户，是不是可以想办法获取到老版本中那段带有音频的 mp4 文件呢？ 答案是肯定的。 得益于 git 的版本控制特色，在 hollywood 的 github 仓库中，我们可以找到原来的 mp4 文件。 下载这个 mp4 文件后，我们将其放入 /usr/share/hollywood/ 路径下，重命名为 soundwave.mp4，并确保其被正确设定为 0644 权限。 1sudo install -Dm644 ./mi.mp4 /usr/share/hollywood/soundwave.mp4 接下来试着跑一跑 hollywood，发现依然没有声音。再次查阅源码，发现缺少了 mplayer 这个依赖。 使用包管理器安装 mplayer 后，运行 hollywood 就可以听到声音了。 然而，你觉不觉得这个音乐。。。听上去怪怪的。。。 没错，作者在去掉音频后，给 soundwave.mp4 设定了加速播放。而我们现在需要这段视频被原速播放。编辑 /usr/lib/hollywood/mplayer 123456789101112131415161718192021#!/bin/bash## Copyright 2014 Dustin Kirkland &lt;dustin.kirkland@gmail.com&gt;## Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.command -v mplayer &gt;/dev/null 2&gt;&amp;1 || exit 1trap &quot;pkill -f -9 lib/hollywood/ &gt;/dev/null 2&gt;&amp;1; exit&quot; INTPKG=hollywooddir=&quot;$(dirname $0)/../../share/$PKG&quot;-DISPLAY= mplayer -vo caca -loop 0 -ss $((RANDOM % 100)) -speed 100 $MPLAYER_OPTS $dir/soundwave.mp4+DISPLAY= mplayer -vo caca -loop 0 $MPLAYER_OPTS $dir/soundwave.mp4 再次运行，确认修改已经成功。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Fun","slug":"Fun","permalink":"https://zhul.in/tags/Fun/"}]},{"title":"处理 fcitx5 的文字候选框在 tg 客户端上闪烁的问题","slug":"fcitx5-blinking-on-tg-under-wayland-kde","date":"2022-07-03T05:52:44.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2022/07/03/fcitx5-blinking-on-tg-under-wayland-kde/","link":"","permalink":"https://zhul.in/2022/07/03/fcitx5-blinking-on-tg-under-wayland-kde/","excerpt":"","text":"文章开头，先要感谢 fcitx5 的开发者 老K 帮我 debug 这个问题 鬼畜的文字候选框在新装的 Fedora 36 KDE Wayland 下使用 fcitx5 时遇到了文字候选框前后移动晃眼的问题（如下图） 解决方案当我向老K提出这个问题上的时候，老K告诉我这是预期行为，一共有两个解决方案。 使用 qt 的 text input 关掉 kwin 的淡入淡出特效 但由于我并不熟悉 KWin 的特效，所以我选择了前者的方案。 首先，需要确保自己的 Plasma 版本在 5.24 或以上，fcitx5 的版本号在 5.0.14 以上。 然后我们需要让 KWin 去启动 fcitx5。KCM 为此提供了一个非常简单的方式，如下图 随后需要确保环境变量没有设置 QT_IM_MODULE 。一定要确保这个变量不存在，连空也不行，必须是 unset。 理论上来说，是不需要重启的，但我的环境变量是 fcitx5-autostart 这个 rpm 包在 /etc/profile.d/fcitx5.sh里面设置的，我需要重启系统来使新的环境变量生效。 重启后，如果没有什么意外的话，就算成功了。 绝对不会缺席的意外很遗憾，我遇到了意外。 完成上述操作后，文字候选框依然有问题。 在老K的正确推测下，是因为我在 Fedora 下曾经使用过 im-settings，该程序在 $HOME/.config/environment.d/ 路径下重新帮我设置回了 QT_IM_MODULE 这个变量，从而使得 tg 启动时还在使用 IM MODULE，而不是预期的 qt text input。 删除这两个影响环境变量的文件后，在 tg 输入时，fcitx5 的文字候选框恢复了正常。 debug 过程中用到的两个方式dbus-send1dbus-send --print-reply=literal --dest=org.fcitx.Fcitx5 /controller org.fcitx.Fcitx.Controller1.DebugInfo 运行如上命令后，我得到了如下的输出 12345678 Group [x11::1] has 0 InputContext(s)Group [wayland:] has 5 InputContext(s) IC [a50fe208d42e4611b240c0b66a2fa0b9] program:konsole frontend:dbus cap:e001800060 focus:1 IC [d7d4d5c05e9c445aab1af9c7dfb5fbd4] program:telegram-desktop frontend:dbus cap:e001800060 focus:0 IC [ac72ec3edf58481bbdf838352520efd5] program:krunner frontend:dbus cap:e001820060 focus:0 IC [d8b450176e204953837248f786204c29] program:plasmashell frontend:dbus cap:e001800060 focus:0 IC [df252979343d42ebbe9bd82ead6ff194] program: frontend:wayland cap:40 focus:0Input Context without group 老K指出，出现了 telegram 的那一行表明 tg 还是在用 IM Module，所以是环境变量有问题 /proc 查看程序运行时的环境变量 参考资料Use Plasma 5.24 to type in Alacritty (Or any other text-input-v3 client) with Fcitx 5 on Wayland Candidate window is blinking under wayland with Fcitx 5 查看进程的环境变量 注: 上述参考资料均已在 web.archive.org 和 archive.ph 做过存档，如遇到原站点无法访问的情况，可自行前往这两个站点查看存档。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"},{"name":"KDE","slug":"KDE","permalink":"https://zhul.in/tags/KDE/"}]},{"title":"使用caddy反向代理维基百科中文站点","slug":"use-caddy-to-proxy-wikipedia","date":"2022-05-30T00:59:21.000Z","updated":"2022-08-10T13:42:13.000Z","comments":true,"path":"2022/05/30/use-caddy-to-proxy-wikipedia/","link":"","permalink":"https://zhul.in/2022/05/30/use-caddy-to-proxy-wikipedia/","excerpt":"","text":"反代的目的无非是两点 满足自己在无代理情况下访问无法访问的站点的需求 方便将站点分享给亲朋好友。 一直以来，我都想用 caddy 去反代一份维基百科来用，今天刚好就顺手解决了。 注意事项 用于反代的机子需要有对目标站点的访问能力 最好准备一个新的域名作为白手套，防止被污染 建议增加密码保护，一来使得小鸡流量不被滥用，二来防止防火墙检测到站点内容 本文使用的 caddy 开启了 replace_response 插件，可以使用 xcaddy 编译或直接前往 https://caddyserver.com/download 勾选相应插件后下载。安装时，建议先根据官方文档安装原版 caddy，再用启用了 replace_response 插件的 caddy 二进制文件覆盖掉原版 caddy，这样就不需要去手写 systemd 相关的文件了。 Caddyfile12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&#123; order replace after encode&#125;https://zhwiki.example.com &#123; reverse_proxy * https://zh.wikipedia.org &#123; header_up Host &#123;upstream_hostport&#125; header_up X-Real-IP &#123;http.request.remote.host&#125; header_up X-Forwarded-For &#123;http.request.remote.host&#125; header_up X-Forwarded-Port &#123;http.request.port&#125; header_up X-Forwarded-Proto &#123;http.request.scheme&#125; header_up Accept-Encoding identity header_down location (https://zh.wikipedia.org/)(.*) https://zhwiki.example.com/$2 header_down location (https://zh.m.wikipedia.org/)(.*) http://m.zhwiki.example.com/$2 &#125; replace &#123; &quot;upload.wikimedia.org&quot; &quot;up.zhwiki.example.com&quot; &quot;zh.wikipedia.org&quot; &quot;zhwiki.example.com&quot; &quot;zh.m.wikipedia.org&quot; &quot;m.zhwiki.example.com&quot; &#125;&#125;https://m.zhwiki.example.com &#123; reverse_proxy * https://zh.m.wikipedia.org &#123; header_up Host &#123;upstream_hostport&#125; header_up X-Real-IP &#123;http.request.remote.host&#125; header_up X-Forwarded-For &#123;http.request.remote.host&#125; header_up X-Forwarded-Port &#123;http.request.port&#125; header_up X-Forwarded-Proto &#123;http.request.scheme&#125; header_up Accept-Encoding identity header_down location (https://zh.wikipedia.org/)(.*) https://zhwiki.example.com/$2 header_down location (https://zh.m.wikipedia.org/)(.*) http://m.zhwiki.example.com/$2 &#125; replace &#123; &quot;upload.wikimedia.org&quot; &quot;up.zhwiki.example.com&quot; &quot;zh.wikipedia.org&quot; &quot;zhwiki.example.com&quot; &quot;zh.m.wikipedia.org&quot; &quot;m.zhwiki.example.com&quot; &#125;&#125;https://up.zhwiki.example.com &#123; reverse_proxy * https://upload.wikimedia.org &#123; header_up Host &#123;upstream_hostport&#125; header_up X-Real-IP &#123;http.request.remote.host&#125; header_up X-Forwarded-For &#123;http.request.remote.host&#125; header_up X-Forwarded-Port &#123;http.request.port&#125; header_up X-Forwarded-Proto &#123;http.request.scheme&#125; header_up Accept-Encoding identity &#125;&#125; 简单解释第一大段是启用 replace_response 插件的部分，直接照抄即可。 第二和第三大段的思路是一致的，分别反向代理了 PC 端和移动段的网页。两行 header_down 的写法是受到了知乎上那篇 Github 反代的启发，避免了源站发出 302 重定向时访客被带到源站去。replace 部分不用多说，就是将针对三个源站域名的请求改到反代站域名。 第四大段就是中规中举地反代了 upload.wikimedia.org 这个域名，上面存放的大多数是媒体文件，如果条件允许的话其实可以考虑使用多个服务器反代。 密码保护在我这份 Caddyfile 中没有启用，如果有需要的话可以参考我的另一篇博客。 参考资料Caddy 官方文档The Road to Serfdom——如何为GitHub搭建反向代理使用 Caddy 配置 Wikipedia 反向代理使用 Caddy 反代 ghcr.io 所有参考资料除官方文档外均使用 web.archive.org 和 archive.ph 进行存档，如有无法访问的情况，请自行前往存档站获取历史存档。","categories":[],"tags":[{"name":"Caddy","slug":"Caddy","permalink":"https://zhul.in/tags/Caddy/"}]},{"title":"创建一个本地的 Fedora 镜像源","slug":"setup-a-local-fedora-source","date":"2022-05-10T20:18:26.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2022/05/11/setup-a-local-fedora-source/","link":"","permalink":"https://zhul.in/2022/05/11/setup-a-local-fedora-source/","excerpt":"","text":"Fedora 36 在多次跳票后，总算是在 5月10日正式发布了。截止北京时间 5月11日凌晨两点，上海交通大学开源镜像站的上游 rsync://download-ib01.fedoraproject.org/ 仍然没有同步 Fedora 36 的 Release 源。鉴于 Release 自 freeze 以后基本是不会有什么大变动的，也不需要及时同步更新，干脆就直接建立一个本地的镜像源。 准备 一块足够大的硬盘 根据我个人实测，单 Fedora 36 的 x86_64 架构 的 Release 源中的 binary rpm 就占用了 89.6 GB，具体准备多的的硬盘空间还得看你具体需要同步些什么。 符合要求的上游 这里所说的符合要求一共是两个方面，一是允许 rsync 同步，二是有你想要的文件。我通过 getfedora.org 的下载按钮的转发目标得知 mirror.karneval.cz 已经完成了 Fedora 36 Release 源的同步。 良好的网络条件 这里说的良好的网络条件，并不一定是说需要访问境外站点的能力，而是你和你的上游之间的网络访问畅通，不要动不动就i断开连接那种。如果你选择的是国内镜像站作为你的上游，那一般不会有什么问题。 开始同步现在的主流方案一般都是选择 rsync 直接开整。 试探环节很多镜像站的 rsync 文件路径和 http 文件路径路径是不同的。 比如说，我这里用的 mirror.karneval.cz 的 http 页面显示的 fedora 仓库路径在 /pub/fedora，但 rsync 同步时需要使用 /fedora 路径。 为了确定这一点，我们可以先通过 rsync rsync://example.com 进行预览 1rsync rsync://mirror.karneval.cz 通过一层一层预览目录的方式，找到需要同步的路径是 /fedora/linux/releases/36/Everything/x86_64/os/ 同步环节通过 mkdir 和 cd 创建并进入我们准备用于同步源码的文件夹，然后开始执行同步命令。 1rsync -avP rsync://mirror.karneval.cz/fedora/linux/releases/36/Everything/x86_64/os/ . Ps: 中途如果由于各种原因而中断了同步过程，可以再次使用上述命令继续同步，rsync 会保证文件完整性。 安装、配置并启用 static server (可选)如果只需要本机使用，那么直接跳过这一步即可；如果需要给局域网内的其他机器提供镜像源，那么需要启用 static server。 我这里选择的是 caddy，性能虽然比 nginx 略逊一筹，但胜在配置简单。 caddy 的安装可以直接参考官方文档，这里不再赘述。 配置也不过那么几行的事情，我给个 example。端口号只要和别的程序没有冲突，就可以随意指定。443 端口需要 ssl 证书比较麻烦，局域网内直接用非标准端口即可。 1234567:14567 &#123; root * /the/directory/you/use file_server &#123; browse &#125;&#125; 配置完后直接以普通用户的权限启用即可，使用 systemd 启用需要解决 caddy 用户对目标无权限的问题。 1caddy run --config /etc/caddy/Caddyfile 浏览器输入对应的 ip 和端口，应该就可以访问了。 修改源配置文件由于我们仅同步了 Release 源，就只需要修改 /etc/yum.repo.d/fedora.repo 即可。 如果镜像源在本机上，可以直接使用 file:// 协议头: 123456789101112[fedora]name=Fedora $releasever - $basearch+ baseurl=file:///the/directory/you/use- metalink=https://mirrors.fedoraproject.org/metalink?repo=fedora-$releasever&amp;arch=$basearchenabled=1countme=1metadata_expire=7drepo_gpgcheck=0type=rpmgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-fedora-$releasever-$basearchskip_if_unavailable=False 如果镜像源在同局域网设备上，通过 http:// 协议也能达到相同的效果: 123456789101112[fedora]name=Fedora $releasever - $basearch+ baseurl=http://192.168.1.233:14567- metalink=https://mirrors.fedoraproject.org/metalink?repo=fedora-$releasever&amp;arch=$basearchenabled=1countme=1metadata_expire=7drepo_gpgcheck=0type=rpmgpgcheck=1gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-fedora-$releasever-$basearchskip_if_unavailable=False Ps: 提供镜像源的机子的局域网 ip 可以通过 ip -br a 命令获取","categories":[],"tags":[{"name":"Fedora","slug":"Fedora","permalink":"https://zhul.in/tags/Fedora/"},{"name":"Caddy","slug":"Caddy","permalink":"https://zhul.in/tags/Caddy/"}]},{"title":"好软推荐——FastOCR","slug":"fastocr-experience","date":"2022-04-13T21:55:18.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2022/04/14/fastocr-experience/","link":"","permalink":"https://zhul.in/2022/04/14/fastocr-experience/","excerpt":"","text":"前两天在 PC 端有 OCR 的需求，需求如下 自带框选功能或者图片上传前的编辑功能 硬盘占用小，不要 electron (((已经受够了 支持系统托盘或者快捷键快速调出 免费 在李皓奇的推荐下试用了 Arch 群兔兔拿 python 和 qt 写的 fastocr，体验可以说是相当不错了。四个要求基本都能完美满足！ 支持 百度、有道、旷视Face++ 三家的接口，免费额度绝对够我试用的（大不了一家用完了换一家嘛 此外，空间占用小，算上依赖也不过 31MB 的硬盘空间占用，连半个 electron 都不到，运行起来反而更加流畅 &lt;^_^&gt;","categories":[],"tags":[{"name":"OpenSource Project","slug":"OpenSource-Project","permalink":"https://zhul.in/tags/OpenSource-Project/"},{"name":"Experience","slug":"Experience","permalink":"https://zhul.in/tags/Experience/"}]},{"title":"抛弃PicGo，直接使用curl将图片上传到LskyPro","slug":"upload-pic-to-lskypro-with-curl","date":"2022-03-31T11:19:14.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2022/03/31/upload-pic-to-lskypro-with-curl/","link":"","permalink":"https://zhul.in/2022/03/31/upload-pic-to-lskypro-with-curl/","excerpt":"","text":"前一阵子为了图床折腾了好长一段时间。刚开始用的是 cloudinary，虽然每月有限制，但强在境内访问速度还不错，可惜后来 res.cloudinary.com 这个域名在某些地方被 DNS 污染了，而自定义域名是付费版的功能，就不得不放弃了。 后来也尝试过 npm图床 的方案，可惜面对这种滥用公共资源的行为我无法接受（肯定不是因为受不了那繁琐的上传步骤，随便传张图都得 bump 下版本号的原因），而且现在境内的能作为图床使用的 npm 镜像似乎也就只剩下 npm.elemecdn.com 这一个能够正常回源了，没准哪天就用不了了，所以就去投奔了杜老师的去不图床。 去不图床采用开源图床程序 Lsky Pro 搭建，没有免费服务，且配置了鉴黄服务，看起来就是打算长久做下去的图床站点。境内使用腾讯云cdn，境外采用 cloudflare cdn，速度都挺让我满意的。（杜老师看见请给我打钱，或者多送我点空间也行（x Typora 一直是我写博客的主用 Markdown 编辑器，之前我采用 Typora 调用 PicUploader(php) 自动上传图片的方案写博客，体验相当不错，如图: 可惜 PicUploader 目前仍然没有支持 LskyPro 的上传，我采用的是现在烂大街的 Typora+PicGo+LskyPro插件 的方案去实现 Typora 的自动上传图片功能。 这个方案有明显的弊端： PicGo 运行依赖于 electron，极大地消耗了系统资源。 PicGo 面对多张图片( &gt;=4张 )同时上传时容易报错。 PicGo 对于 Linux 的支持比较有限，作者可能不熟悉 Linux，直到半个月前我去交了一个 pr 才支持 wayland 下使用 wl-clipboard 将图片链接复制到粘贴版。 正好 LskyPro 有详细的文档，应该可以用 curl 手糊一段 Shell 脚本实现直接上传，资源占用小，唯一的弊端是上传完成后的图片不容易管理。脚本如下 1234567891011121314151617181920212223242526#!/bin/bashAPI_URL=&quot;https://7bu.top/api/v1&quot;AUTH_TOKEN=&quot;&quot;markdown=falsewhile [[ &quot;$#&quot; -gt 0 ]]; do case $1 in -m|--markdown) markdown=true; shift ;; *) break ;; esacdonefor images in &quot;$@&quot;; do UPLOAD_RESPONSE=$(curl -s -X POST &quot;$API_URL/upload&quot; \\ -H &#x27;Content-Type: multipart/form-data&#x27; \\ -H &quot;Authorization: Bearer $AUTH_TOKEN&quot; \\ -F &quot;file=@$images&quot;) if [ &quot;$markdown&quot; = true ]; then echo &quot;$UPLOAD_RESPONSE&quot; | jq -r .data.links.markdown else echo &quot;$UPLOAD_RESPONSE&quot; | jq -r .data.links.url fidone 2022/04/02更新: 第六行 $@ - “$@”，解决文件名中出现空格时导致的上传失败问题。 需要借助 jq 来读取返回的 json，各 Linux 发行版源内应该都有打包，自行安装即可。 授予x可执行权限后，Typora 内直接填写自定义命令输入脚本所在位置即可实现 Typora 自动上传图片了。 2023/12/12更新: 支持 -m 或 –markdown 参数，使脚本输出 markdown 格式的链接。","categories":[],"tags":[{"name":"图床","slug":"图床","permalink":"https://zhul.in/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"Shell Script","slug":"Shell-Script","permalink":"https://zhul.in/tags/Shell-Script/"},{"name":"Lsky Pro","slug":"Lsky-Pro","permalink":"https://zhul.in/tags/Lsky-Pro/"}]},{"title":"使用 Github Action 跑 rpmbuild","slug":"run-rpmbuild-with-github-action","date":"2022-03-06T08:02:54.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2022/03/06/run-rpmbuild-with-github-action/","link":"","permalink":"https://zhul.in/2022/03/06/run-rpmbuild-with-github-action/","excerpt":"","text":"一直打算用 Github Action 跑 rpmbuild 构建 rpm 包，然后传到 Action 的 Artifacts 里面，用户就可以在登陆 Github 帐号的情况下进行下载。只要不发 Release，应该就不算「再分发」的行为，也就自然规避了再分发闭源软件的法律风险。 然而，现有的那些 Action 几乎全都是针对 CentOS 老古董定制的，，有些甚至连 buildrequires 都不帮你安装，而且大部分情况下都不支持 Source 直接填写一个链接，需要你直接提供 Source 文件。我自己又不可能在 Github 的仓库里用 lfs 强行存一个 200MB+ 的二进制文件，显然是不符合我要求的。还有几个项目使用 mock 去构建的，但使用 mock 构建需要提前用 rpmbuild 生成 srpm，在我们的个人电脑上可以理解为用一个干净的 chroot 打包防止自己的环境受污染，但在一个全新的、用完一次就要扔掉的 docker 里面还要防止环境被污染似乎有些画蛇添足的嫌疑。 最终，我选择了 naveenrajm7/rpmbuild 这个项目。（虽然我并不理解为什么他要用 nodejs 去调用系统命令去执行 rpmbuild 等一系列步骤，我也没学过这类语言。不过项目的 main.ts 我还是能仿写的。） 在经过三四个小时的摸爬滚打下，我还是成功地将这个项目按照我的想法改完了。 采用 Fedora 35 作为 host 进行 rpmbuild 自动安装 buildrequires 自动下载 source 允许仓库内自带本地 source 移除针对 srpm 的构建 改完后的 action 在 zhullyb/rpmbuild-github-action，欢迎使用。 最终是在 zhullyb/dingtalk-for-fedora 项目成功实装了，有兴趣的访客们可以去尝试着一起来白嫖 Github Action 呀！ &gt;_&lt;","categories":[],"tags":[{"name":"Fedora","slug":"Fedora","permalink":"https://zhul.in/tags/Fedora/"},{"name":"Github Action","slug":"Github-Action","permalink":"https://zhul.in/tags/Github-Action/"},{"name":"RPM Package","slug":"RPM-Package","permalink":"https://zhul.in/tags/RPM-Package/"}]},{"title":"如何打出一个「-git」的rpm包","slug":"how-to-package-a-git-rpm-package","date":"2022-02-07T02:23:29.000Z","updated":"2022-08-22T15:42:13.000Z","comments":true,"path":"2022/02/07/how-to-package-a-git-rpm-package/","link":"","permalink":"https://zhul.in/2022/02/07/how-to-package-a-git-rpm-package/","excerpt":"","text":"本文中，笔者通过 github api 获取最新的 commit_id ，以一种曲线救国的方式成功为 rpm 打下了一个 -git 包。 On Archlinux用过 AUR 的 Arch 用户应该知道，makepkg 支持 “-git” 包。当我们执行 makepkg 时，PKGBUILD 中的 pkgver 函数会自动被运行，并将输出的结果作为本次打包的版本号。这是一个非常棒的设计，我们不需要去手动更新 PKGBUILD，就可以直接从 git 服务区拉取最新的 master 分支编译打包，对于跟进开发进度而言非常方便。 一般来说，一个 -git 包的版本号会分成 2~4 个部分，最为核心的是 count 和 commit_id：count用于记录这是第几次提交，通过提交的次数作为版本号的靠前部分可以帮助包管理器比较版本号的新旧，比如第21次提交的代码一定比第18次的更加新，而21也正好比18大，包管理器也就凭借着这个数字来保证其可以在用户在更新的时候为用户选择一个更新版本的包；而 commit_id则可以帮助人类更快定位这个包是在哪一次代码提交以后编译的，以帮助 开发者/用户 定位问题。 On Fedora然而，这个思路在 rpm 上似乎无法实现。rpmbuild 执行的时候会事先根据版本号在 BUILDROOT 路径下创造一个 %&#123;name&#125;-%&#123;version&#125;-%&#123;release&#125;-%&#123;arch&#125;的目录，如此一来，就必须先确定版本号，无法像 PKGBUILD 那样使用一个 pkgver 的函数去自动更新版本号。此外，rpm 似乎专注于软件包的 Reproducibility，也就是希望拿到了指导 rpmbuild 打包的 specfile 以后打出一个相同包的能力，因此，使用同一份 specfile 在不同时间打出一个不同包的这种行为似乎并不符合 Fedora/Redhat 的哲学，所以我们怕是等不到 rpm 支持这个功能的那一天了。 Turn of events当然，这也并非不可能完成的任务，在 西木野羰基 的指引下，我在 Fedora Docs 找到了对于某个 Branch 的打包样版。其实也就是直接从 github 下载 master 分支的 master.tar.gz 压缩包来获取最新的源码，这样就确保了每一次 rpmbuild 的时候都能获取最新的源码。接下来需要处理的就是版本号的问题。 Sad Story很可惜，master.tar.gz 压缩包中并不包括 .git 文件，我们无法通过 git rev-list --count HEAD 来获取 count 计数，此外，最新的 commit_id 我们也不得而知。即使我们知道这些参数，也无法在 rpmbuild 执行之前自动把这些参数填进 specfile 中。 Improvement好在天无绝人之路，在 Liu Sen 的 RPM 中宏的简单介绍 一文中发现宏其实也可以类似 bash 中的 $() 一样定义成系统运行某些命令后的结果，通过仿写 copr 上 atim/fractal 的 specfile 定义了下面两个宏。 12%global timenow %(echo $(date +%Y%m%d.%H%M))%global commit_short_id %(api_result=$(curl -s https://api.github.com/repos/&lt;username&gt;/&lt;reponame&gt;/branches/master | head -n 4 | tail -n 1); echo $&#123;api_result:12:7&#125;) 版本号就可以直接写成 %&#123;timenow&#125;.%&#123;commit_id_short&#125; %&#123;timenow&#125; 是直接通过运行系统的 date 命令获得一个精确到分钟的时间来当作 count 给 dnf 判断版本号大小使用 %&#123;commit_id_short&#125; 从 api.github.com 获取到该仓库最新的 commit 号，配合粗制滥造的 shell 命令做切片，提取前7 位，帮助用户和开发者快速定位源码版本使用。当然，也可以选择直接使用 jq 作为 json 的解释器，不过 copr 大概率没有预装，生成 srpm 的时候估计就会报错。 Review至此，我们成功解决了在 rpm 上打 -git 包的问题，不过仍然有以下缺点 仅支持 github 上的项目，对于其他的 git 托管服务商还需要去查阅他们的 api 文档 粗制滥造的 shell 命令可能不足以应对以后的 github api 变更 使用了精确到分钟的时间作为计数器，导致版本号过长 使用 copr 打包的时候，有概率出现 srpm 与 rpm 之间版本号出现分钟级的差异","categories":[],"tags":[{"name":"Fedora","slug":"Fedora","permalink":"https://zhul.in/tags/Fedora/"},{"name":"RPM Package","slug":"RPM-Package","permalink":"https://zhul.in/tags/RPM-Package/"}]},{"title":"雪藏在开源镜像站点中的那些常用却不为人知的软件","slug":"the-common-software-hidden-in-mirrors","date":"2022-01-19T05:01:30.000Z","updated":"2023-05-01T06:49:51.000Z","comments":true,"path":"2022/01/19/the-common-software-hidden-in-mirrors/","link":"","permalink":"https://zhul.in/2022/01/19/the-common-software-hidden-in-mirrors/","excerpt":"","text":"前两天在下载 微PE 的时候眼睛突然一瞥，发现了山东大学的开源镜像站。突然间才发现在各个开源镜像站点中提供了许多那些我们误以为只能顶着断断续续的 Github 网络才能下载的软件。 下面这张列表主要来自山东大学的镜像站中的「常用软件」和南京大学的「github-release」。我严重怀疑南京大学就是把整个 tuna 给搬了一遍过来。 山东大学 南京大学 清华大学 balena-io/etcher https://mirrors.nju.edu.cn/github-release/balena-io/etcher/LatestRelease/ https://mirrors.tuna.tsinghua.edu.cn/github-release/balena-io/etcher/LatestRelease/ drawio-desktop https://mirrors.sdu.edu.cn/github-release/jgraph_drawio-desktop/ git-for-windows https://mirrors.sdu.edu.cn/github-release/git-for-windows_git/ https://mirrors.nju.edu.cn/github-release/git-for-windows/git/LatestRelease/ https://mirrors.tuna.tsinghua.edu.cn/github-release/git-for-windows/git/LatestRelease/ Krita https://mirrors.nju.edu.cn/kde/stable/krita/ libreoffice https://mirrors.tuna.tsinghua.edu.cn/libreoffice/libreoffice/ Magisk https://mirrors.nju.edu.cn/github-release/topjohnwu/Magisk/LatestRelease/ https://mirrors.tuna.tsinghua.edu.cn/github-release/topjohnwu/Magisk/LatestRelease/ Motrix https://mirrors.sdu.edu.cn/github-release/agalwood_Motrix/ obs-studio https://mirrors.sdu.edu.cn/github-release/obsproject_obs-studio/https://mirrors.sdu.edu.cn/software/Windows/OBS%20Studio/ https://mirrors.nju.edu.cn/github-release/obsproject/obs-studio/LatestRelease/ https://mirrors.tuna.tsinghua.edu.cn/github-release/obsproject/obs-studio/LatestRelease/ office tool plus https://mirrors.sdu.edu.cn/github-release/YerongAI_Office-Tool/ picgo https://mirrors.sdu.edu.cn/github-release/pbatard_rufus/ rufus https://mirrors.sdu.edu.cn/software/Windows/Rufus/ https://mirrors.nju.edu.cn/github-release/pbatard/rufus/LatestRelease/ https://mirrors.sdu.edu.cn/software/Windows/WePE/ventoy https://mirrors.sdu.edu.cn/github-release/ventoy_Ventoy/ https://mirrors.nju.edu.cn/github-release/ventoy/Ventoy/LatestRelease/ virtualbox https://mirrors.nju.edu.cn/virtualbox/ https://mirrors.tuna.tsinghua.edu.cn/virtualbox/ vlc https://mirrors.nju.edu.cn/videolan-ftp/ https://mirrors.tuna.tsinghua.edu.cn/videolan-ftp/ winehq https://mirrors.nju.edu.cn/winehq/ https://mirrors.bfsu.edu.cn/winehq/ wepe https://mirrors.sdu.edu.cn/software/Windows/WePE/","categories":[],"tags":[]},{"title":"在Fedora搭建jekyll环境——dnf module","slug":"dnf-module-in-setting-up-the-jekyll","date":"2022-01-12T14:11:42.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2022/01/12/dnf-module-in-setting-up-the-jekyll/","link":"","permalink":"https://zhul.in/2022/01/12/dnf-module-in-setting-up-the-jekyll/","excerpt":"","text":"起因我之前的博客一直用的是这个主题，直接使用 Fedora 官方源里的 rubygem-jekyll 似乎无法正常安装 Gemfile 中的依赖。之前使用 Archlinux 的时候，我是直接从 AUR 安装了一个 ruby-2.6 来使用的，但最近转到 Fedora 以后似乎就没法用这样的方案来解决了。 好在天无绝人之路，Fedora 也提供了安装老版本的 ruby 的方案——使用 dnf 的 module 功能。 关于 dnf module关于 dnf 的 module 功能到底是用来做什么的，其实我并不清楚。虽说 Fedora 提供了文档，但就凭我的读中文文档都吃力的水准，似乎没有办法通过英文文档来理解这个全新的概念，所以我选择直接莽过去。 就我目前的理解而言，dnf 的 module 似乎并不致力于帮助用户完成系统内某一程序的新老版本共存的难题，而仅仅是给用户提供了停留在老版本软件的权利。module 所负责的，是保证老版本的程序能在你的系统上正常运行起来，而不会因为其他组件的更新而导致老版本的程序无法正常使用。 基本的使用方法通过下列命令可以查看目前所支持的 module 1sudo dnf module list 通过下列命令可以选择 module 所要停留的版本( 以 ruby 2.7 为例 ) 1sudo dnf module enable ruby:2.7 通过下列命令可以取消锁定 module 程序所要停留的版本( 以 ruby 为例 ) 1sudo dnf module reset ruby 开始配置该 jekyll 主题的运行环境12345sudo dnf module install ruby:2.7sudo dnf install ruby-develcd /path/to/the/jekyll-blog/bundle install --path vendor/bundle 完成后，我们即可在 jekyll-blog 目录下 使用 bundle exec jekyll 来正常运行 jekyll 了。试着跑一下 bundle exec jekyll server 参考材料Fedora Docs openSUSE 中文社区主页贡献指南 Switching to use Ruby 2.7 (or older) in Fedora 34 using DNF Modules 「WebArchive」","categories":[],"tags":[{"name":"Fedora","slug":"Fedora","permalink":"https://zhul.in/tags/Fedora/"}]},{"title":"pacman更新时遇到「GPGME 错误：无数据」","slug":"pacman-gpgme-error-no-data","date":"2022-01-01T15:42:09.000Z","updated":"2024-06-24T10:08:07.000Z","comments":true,"path":"2022/01/01/pacman-gpgme-error-no-data/","link":"","permalink":"https://zhul.in/2022/01/01/pacman-gpgme-error-no-data/","excerpt":"","text":"情景再现当初是使用 pacman 更新时遇上了「GPGME 错误：无数据」的问题，我尝试复现了下，大概是下面这样的情况。 123456789101112[zhullyb@Archlinux ~]$ sudo pacman -Syu错误：GPGME 错误：无数据错误：GPGME 错误：无数据错误：GPGME 错误：无数据:: 正在同步软件包数据库... core 137.6 KiB 598 KiB/s 00:00 [------------------------------------] 100% extra 1566.0 KiB 6.12 MiB/s 00:00 [------------------------------------] 100% community 6.0 MiB 20.6 MiB/s 00:00 [------------------------------------] 100%错误：GPGME 错误：无数据错误：GPGME 错误：无数据错误：GPGME 错误：无数据错误：未能同步所有数据库（无效或已损坏的数据库 (PGP 签名)） 英文版的提示应该是长成下面这个样子 123456789101112[zhullyb@Archlinux ~]$ sudo pacman -Syuerror: GPGME error: No dataerror: GPGME error: No dataerror: GPGME error: No data:: Synchronizing package databases... core 137.6 KiB 574 KiB/s 00:00 [------------------------------------] 100% extra 1566.0 KiB 5.66 MiB/s 00:00 [------------------------------------] 100% community 6.0 MiB 18.1 MiB/s 00:00 [------------------------------------] 100%error: GPGME error: No dataerror: GPGME error: No dataerror: GPGME error: No dataerror: failed to synchronize all databases (invalid or corrupted database (PGP signature)) 解决方案1sudo rm /var/lib/pacman/sync/*.sig 很简单，就这一条命令就够了。 问题原因pacman在更新数据库文件时也会尝试下载$repo.db.sig，这里的$repo可以是 core、extra、community、archlinuxcn 等仓库名。 但是无论是官方源还是 archlinuxcn 源，大多数源的数据库文件都不会被签名，也就不会存在 .db.sig 文件。 pacman 尝试下载时这些数据库文件的签名文件时，镜像站就会返回 404 的 http 状态码告诉pacman: “你个傻叉，神他妈没有这个文件！” pacman 挨了一顿骂，也就善罢甘休，没有再动这个念头，所以我们每次更新也都相安无事。 而出现这种错误的情况大多是发生在 校园网、酒店免费 WIFI 这种需要登陆以后才能上网的网络环境。 因为 pacman 尝试下载 .db.sig 文件时被登陆网页劫持了（这点你们应该深有感受，如果你在这种网络环境下没有登陆，你无论访问什么网页都会被重定向到登录界面，http 的状态码此时是200，不是404）。从没见过 .db.sig的 pacman 此时两眼放光，由于没有挨骂，他就迅速地把登录界面当成是.db.sig下载下来了。 下载下来以后，pacman 激动地摆弄起 .db.sig，甚至发现里面没有自己期待已久的 GPG签名数据并开始报错时仍然不愿意撒手，因此此时无论再怎么同步源码、再怎么 Syyu 也不会有效果，必须人工干预。","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"}]},{"title":"Cutefish的前世今生","slug":"the-history-of-cutefish","date":"2021-12-11T16:10:34.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/12/12/the-history-of-cutefish/","link":"","permalink":"https://zhul.in/2021/12/12/the-history-of-cutefish/","excerpt":"","text":"CutefishOS是由我们国内的开发者主导（目前也主要是他们在开发）的桌面环境。不过似乎对于他的前世今生，似乎很多人都有误解。尤其是很多人认为他是一个Archlinux-based发行版；部分用户分不清他到底是基于Debian还是基于Ubuntu；还有人把它和 JingOS 弄混了。 先把这些问题的回答写在最前面: CutefishOS 是一个基于Debian的发行版，他的前身 CyberOS 是一个基于 Archlinux 的发行版。但要注意: Cutefish （不加OS）可以单独指代 CutefishOS 所使用的桌面环境，为了避免混淆，本文中我将使用CutefishDE来指代他的桌面环境。 CutefishOS 和 JingOS 目前只是官网互加友链的关系，并不是相同的东西。Cutefish的开发方向是基于qt重写一套UI，而JingOS则更像是在开发一套KDE的主题。 Cutefish的历史CyberOS的故事第一次体验到这个UI其实是在21年的3月，在Archlinux的QQ群里，群主向我们推荐了 CyberOS ，这是一个基于 Archlinux 的发行版。 由于基于 Archlinux，我直接就添加了CyberOS的源作为第三方源安装上了CyberDE，那会儿还顺手水了篇博客，由于后来事情发展太快，这篇博客早就不适用了，就干脆删了，现在在我的Github还能找到那会儿的存档。 更名CutefishOS后来根据 CutefishOS 的QQ群的群主所说，是因为当时没注重海外平台的宣发，导致 CyberOS 的用户名在 Twitter 被抢注，因此决定改名 CutefishOS 。由于时间较为久远，QQ群的聊天记录已经几乎找不到了，我无法放出。 关于CutefishOS的创始时间我已经记不清了，但是可以推测是在21年的4~5月份左右。[1][2][3] 官网上线21年5月12日，cutefishos.com 上线，暂时不提供安装镜像。 进军Arch系5月26日，CutefishDE进入 Archlinux官方源。 同日，Github 组织 manjaro-cutefish 放出了使用 CutefishDE 的 manjaro安装镜像。这个组织和官方的 github.com/cutefishos 没有共同维护者，因此可以基本断定是第三方打包的。 Ubuntu第三方打包版的跟进大约在7月中旬左右[4]，Github出现了一位名为 cutefish-ubuntu 的用户，开始在 Ubutnu 上编译 CutefishDE ，并通过 GithubPages 发布安装镜像，依然是第三方打包的安装镜像。 官方版本释出21年国庆长假期间，cutefishos.com 释出由 Cutefish官方发布的基于Debian的CutefishOS镜像，搭载的DE是 0.5 版本的，英文版网页提供 Google Drive 和 Mega 的下载链接，中文版本网页非常贴心地添加了使用飞书下载的方式方便国内用户下载。 RPM系的跟进COPRcopr上分别有三名用户打包了CutefishDE/CyberDE，我以表格形式简单罗列一下 用户名 打包的DE 第一次打包日期 rmnscnce cutefish 2021.8.19 cappyishihara cyber 2021.11.17 jesonlay cutefish 2021.12.06 论坛用户21年12月2日，一为名为gesangtome的网友在CutefishOS的论坛上发布了自己编译的CutefishDE。 通过whois查询得知cutefishos.com 这个域名注册时间为21年3月31日 ↩Cutefish进入Archlinux官方源是在5月26日 ↩CyberOS的Github仓库最后一次内容变更是在21年的5月23日 ↩这里参考的是 cutefish-ubuntu/cutefish-ubuntu.github.io 仓库的第一个commit的时间 ↩","categories":[],"tags":[{"name":"OpenSource Project","slug":"OpenSource-Project","permalink":"https://zhul.in/tags/OpenSource-Project/"}]},{"title":"wolai再打包遇到的问题--electron应用的dev判断机制","slug":"dev-app-update-in-wolai","date":"2021-12-03T14:53:25.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/12/03/dev-app-update-in-wolai/","link":"","permalink":"https://zhul.in/2021/12/03/dev-app-update-in-wolai/","excerpt":"","text":"之前对于electron懵懵懂懂的时候就把 wolai 给打包上了 AUR ，那会儿年少无知，也不懂得把内置的 electron 拆开来换成系统内置的以节省空间。前一阵子给CN源打完 Motrix 以后突然想起来自己在 AUR 上还有维护一个叫 wolai 的electron 应用，于是打算把软件内置的 electron 拆出来。尝试使用 electron /path/to/app.asar 命令启动的时候发现了以下的问题。 虽然这个报错无关紧要，直接右上角叉掉也不影响软件正常使用，但是就这样推上 AUR 似乎有些不太妥当。于是使用搜索引擎查找答案。 发现是使用系统自带的 electron 启动时，app.asar 内置的一个叫 electron-updater 的模块在自动检测更新时会误认为我们此时处于开发模式，于是会尝试读取 app.asar 内部的 dev-app-update.yml 以查询更新。[1] 但问题在于这个 app.asar 并不是 wolai 开发者在开发时使用 development 模式打出来的包，应该是 production ，所以内置的那个文件名叫 app-update.yml ，少了个dev 前缀，就很尴尬。 以下内容来自一篇简书的文章[2] 所以调试的时候可以建一个default-app.yml文件放在D:\\hzhh123\\workspace\\vue-work\\electron-demo1\\node_modules\\electron\\dist\\resources\\default_app.asar 下，这里就涉及到asar解压缩，但是这样会很麻烦，打包后也需要这样替换，麻烦，所幸electron-updater中提供了这个文件的属性配置updateConfigPath，可以通过设置这个属性来解决这个问题 很遗憾，我们并不是该应用的开发者，并不能指定electron-uploader构建时的参数，所以只能考虑解压缩 app.asar 手动放入 dev-app-update.yml 的方案。 根据又一篇简书的文章[3]，我们了解到 npm 中有一个叫 asar 的程序可以帮助我们解压缩 app.asar。我这里直接将内容搬过来 解压 1asar extract 压缩文件 解压文件夹 压缩：如果压缩文件存在，则会被替换 1asar pack 文件夹 压缩文件名 原文是让我们直接使用 npm 下载安装 asar 程序，然而这就会让打包过程变得很复杂，所幸 Archlinux 官方源中已经将这个程序打完了，我们可以直接将 asar 写入 makedepends。 大概就写成了这个样子。 123asar extract $&#123;srcdir&#125;/squashfs-root/resources/app.asar $&#123;srcdir&#125;/new_appmv $&#123;srcdir&#125;/squashfs-root/resources/app-update.yml $&#123;srcdir&#125;/new_app/dev-app-update.ymlasar pack $&#123;srcdir&#125;/new_app $&#123;srcdir&#125;/squashfs-root/resources/app.asar 程序正常启动，没有弹出之前的对话框了。 参考: https://github.com/electron-userland/electron-builder/issues/1505 ↩https://www.jianshu.com/p/15bde714e198 ↩https://www.jianshu.com/p/17d97e6bf174 ↩","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"electron","slug":"electron","permalink":"https://zhul.in/tags/electron/"}]},{"title":"Typora与我","slug":"typora-and-me","date":"2021-11-26T15:05:05.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/11/26/typora-and-me/","link":"","permalink":"https://zhul.in/2021/11/26/typora-and-me/","excerpt":"","text":"Typora 要收费了，$14.9 买断制，支持三设备激活。而且尚且不知道这里买断的是单个大版本更新还是多个大版本更新。 很多人说，不要紧，我们有VsCode、我们有Vnote、我们有MarkText。。。 但我还是不习惯。 Typora真的就是个非常纯粹的Markdown编辑器，他有所见即所得的视觉效果，同时为我提供了沉浸式的写作体验。 当我在使用Typora写文章的时候，我就是个非常单纯的内容创作者，我不需要去考虑各种Markdown的语法格式，我只需要用文字写下我所想的，然后通过右键菜单把文字的样式调整到一个能够合理突出主次的程度，便完成了。若是用的时间长了，记住了打开菜单时旁边现实的快捷键，那速度便更快了。即使有插入图片/视频的需求，我也只需要将图片复制进 Typora 的编辑框，我在Typora预先设置好的自定义上传命令会自动调用我部署在本地的PicUploader完成上传，并将媒体文件以 Markdown/html 语法呈现在编辑框中。 这样一来，我的行文思路就是连贯、不受打断的。即使需要从系统中截取一些图片作说明用途，我也可以通过 Flameshot 截取图片并简单画几个箭头、标几个序号或者框几个按钮后复制到剪切板，并最终粘贴到Typora的编辑框中，整个过程就像是我在和别人QQ聊天时截个图发过去一般简单。 倘若我使用别的Markdown编辑器，我便需要将图片保存到本地、手动上传到图床、手动写markdown的![]()语法，如此一来，我的精力就被分散了，那我也就不会有为文章插入图片的兴趣，抑或是插入完某张图片以后深感心力憔悴，便把写了一半的文章束之高阁，欺骗自己将来有一天我会继续完成这篇文章。 总而言之，Typora对于我而言确实是非常有用的工具，而我将在接下来的半年到一年时间中过渡到其他的开源Markdown编辑器中。即使改变我的使用习惯将是一件非常痛苦的事情，但我不得不这么做。Typora内置的electron在Archlinux的滚动更新下不知道过多久会出现与系统不兼容的情况[1]，所以这意味着继续使用老版本的Typora并不是长久之策，我需要在此之前尽快切换到其他的Markdown编辑器。而我不是个商业公司的Markdown工程师，单纯为了个人兴趣而花大价钱去买这一款生产力工具却无法得到经济回馈似乎并不是一个明智的选择。 反转了，仔细阅读Typora官网的Q&amp;A后发现了这么一条: Can I use Typora for free ? You will have a 15 days free trial before the purchase. If you use dev version or Linux version, you will have unlimited trial time if you keep Typora updated. But we may show “trial button” or disable certain features to encourage you to purchase our app, but basic and most functions will be kept. 看起来 Dev 版和 Linux版本在最新版本可以无限试用下去，那我不考虑改变我的写作习惯了。 注: Dev 版藏得有点深，在这里 baidunetdisk-bin内置的electron已经无法在如今的Archlinux上跑起来了，目前唯一的解决方案是拆包、并使用系统级的electron去启动百度网盘，也就是AUR的baidunetdisk-electron。但是typora运用了一些混淆/加密的手段，使得只有他内置的electron才可以正确启动程序。 ↩","categories":[],"tags":[{"name":"Casual Talk","slug":"Casual-Talk","permalink":"https://zhul.in/tags/Casual-Talk/"}]},{"title":"我是来吹CloudflareMirrors的","slug":"use-cloudflare-mirrors","date":"2021-11-20T17:48:49.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/11/21/use-cloudflare-mirrors/","link":"","permalink":"https://zhul.in/2021/11/21/use-cloudflare-mirrors/","excerpt":"","text":"Cloudflare也开始提供Linux开源镜像站了。 虽然在中国大陆地区，Cloudflare速度日常抽风，不适合作为我们本机镜像源，但完全可以用于境外VPS。平常我们对国内的镜像站比较熟悉，也知道自己的网络环境使用哪个镜像站会稍微快一些，但一旦出了国，这些经验就没有用了。 作为一家老牌的CDN网站加速服务提供商，Cloudflare提供的网络服务在全球范围内都非常快（嗯，对，全球范围不包含中国大陆） 无论你的vps是在美国日本，还是香港新加坡，cloudflare都能提供非常稳定高速的服务，只需要记住cloudflare镜像站的域名，便可以抛弃挑选镜像站的烦恼。 根据网页上所说，cloudflare会以「反代就近的镜像站」+「缓存」的形式来提供服务，既然都要通过cloudflare网络，那中国大陆地区就可以彻底别想了，能够给几乎所有地区提供不错的服务。目前说是只提供了「Archlinux」和「Debian」的服务，但是根据我考证下来，其实「Ubuntu」和「CentOS」也有，只不过没写在页面上罢了。那么废话不多说，我们上境外的vps测一下下载速度如何。 cloudflaremirrors 在我这台位于美国达拉斯机房的1Gbps机器上可以跑到80MB/s+的速度，虽然没有跑满理论速率，但也算是相当喜人的成绩了。 小结: CloudflareMirrors非常适合境外的vps使用，免去了用户自行给一个个镜像站测速的麻烦。","categories":[],"tags":[{"name":"Cloudflare","slug":"Cloudflare","permalink":"https://zhul.in/tags/Cloudflare/"}]},{"title":"deepin-elf-verify究竟是何物？","slug":"what-is-deepin-elf-verify","date":"2021-11-19T16:00:00.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/11/20/what-is-deepin-elf-verify/","link":"","permalink":"https://zhul.in/2021/11/20/what-is-deepin-elf-verify/","excerpt":"","text":"起因越来越多上架在 Deepin 应用商店中的 deb 包中开始依赖了一个叫做 deepin-elf-verify 的依赖，今天来讲讲这个神奇的 deepin-elf-verify 到底为何物，为什么这么多程序都要依赖于他来工作。 下载拆包打开 Bfsu镜像站 ，可以很轻松地找到 Packages —— 在 apt 源中记录了各个文件信息（包括他在仓库中的相对位置）的这么一个神奇的文件，就是体积有点大，达到了68MB的样子。我们可以通过以下命令检索今天的主角——deepin-elf-verify。 1curl -s https://mirrors.bfsu.edu.cn/deepin/dists/apricot/main/binary-amd64/Packages | grep deepin-elf-sign | grep pool 得到了输出: Filename: pool/main/d/deepin-elf-verify/deepin-elf-verify_0.2.0.6-1_amd64.deb 我们就可以把完整的下载链接拼出来: https://mirrors.bfsu.edu.cn/deepin/pool/main/d/deepin-elf-verify/deepin-elf-verify_0.2.0.6-1_amd64.deb 下载解压，大概是这么一个目录结构: 1234deepin-elf-verify_0.2.0.6-1_amd64├── control.tar.xz├── data.tar.xz└── debian-binary 是个常规的deb包该有的结构了。 control.tar.xz 中存放了deb包的相关信息 data.tar.xz 是整个包最终会被安装到系统中的文件 终于到了激动人心的时刻了，打开 data.tar.xz ！ 搞错了，再来 打开UOS的源链接，使用curl+grep检索deepin-elf-verify在源中的相对位置 1curl -sL https://uos.deepin.cn/uos/dists/eagle/main/binary-amd64/Packages | grep deepin-elf-verify | grep pool 获得输出: Filename: pool/main/d/deepin-elf-verify/deepin-elf-verify_0.0.14.5-1_amd64.debFilename: pool/main/d/deepin-elf-verify/deepin-elf-verify-dbgsym_0.0.14.5-1_amd64.deb 拼接为链接: https://uos.deepin.cn/uos/pool/main/d/deepin-elf-verify/deepin-elf-verify_0.0.14.5-1_amd64.deb 下载后打开 data.tar.xz 说说结论吧对于UOS在UOS下，deepin-elf-verify用于检测用户运行的进程是否被deepin信任的证书签名过，虽然有些过于限制用户，对于一个将要广泛用于政府机关的发行版而言是可以理解的。 对于deepin deepin-elf-verify 在 deepin 上就是个空包。 当我们使用 deepin 安装一个含有 deepin-elf-verify 的软件包时，apt 会自动从源内搜索并安装 deepin-elf-verify，由于是个空包，他对于系统不会有任何负担。 大多数依赖deepin-elf-verify的程序都把依赖写成了deepin-elf-verify (&gt;= 0.0.16.7-1)，而在deepin源中，deepin-elf-verify版本号是 0.2.0.6，因此在未来的很长一段时间里应该都是满足要求的，说明统信那边并没有「想要让deepin装不上UOS的包」的这种想法，可见在这一点上，统信还没有明显的偏心。 在别的Deb发行版下deepin-elf-verify存在于、并且仅仅存在于 deepin 和 UOS 的源内。 而当我们使用别的 deb 发行版（如Debian、Ubuntu）时，apt 无法在他们自己的源内找到 deepin-elf-verify ，apt就会报错并且停止安装。 小结: 至于其最终目的，是为了__________________________","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"deepin","slug":"deepin","permalink":"https://zhul.in/tags/deepin/"}]},{"title":"【翻译】请别再使用主题装饰我们的软件","slug":"please-dont-theme-our-apps","date":"2021-11-05T12:35:58.000Z","updated":"2023-02-04T01:51:09.000Z","comments":true,"path":"2021/11/05/please-dont-theme-our-apps/","link":"","permalink":"https://zhul.in/2021/11/05/please-dont-theme-our-apps/","excerpt":"","text":"标题中的「我们」当然不是我自己，这是一封来自GNOME开发者针对广大GNOME社区开发者的一封公开信。看着挺有意思的，其中也透露出了GNOME的设计理念，我在这里尽力将其不掺杂个人情感地翻译完。原文可以查看这里: https://stopthemingmy.app/ 请从头到尾阅读这封信。 这份信针对的是那些在默认设置下使用第三方主题破坏软件体验的发行版，而不是那些试图使用第三方主题美化自己桌面的用户。（原文中出现的是tinkerers，意为修补匠） 我们是 GNOME 平台的应用开发者与设计者，我们为自己的成果感到自豪，并努力确保我们的应用能够为人们提供良好的体验。 然而不幸的是，在许多情况下，我们所有在软件的设计、开发、测试上所做出努力都因为第三方主题而变得徒劳无功。 注: 这些例子纯粹只是用于说明问题，并不针对个别主题。所以，主题开发者们别多想。❤️ 当然，还有些不那么直接的后果，包括: 在GNOME软件中心或Flathub 中使用的截图( Appstream Screenshots )中的UI会和你实际安装以后的UI看上去完全不同，这使得这些截图失去了原有的意义。 如果系统的UI元素和用户帮助文档中出现的元素不同，用户帮助文档将会极大地丢失原有意义。 这些博客文章更详细地解释了主题化的一些问题： GTK Stylesheets — Restyling apps at scale App Icons — Linux Themes &amp; Third-Party Icons 这就是为什么我们心平气和地要求我们的软件不要被主题化。 它们是被上游所使用的（即默认的） GNOME 样式表、图标和字体 所构建和测试的，因此它们在用户的系统上应该是原汁原味的。 虽然我们可以直接在我们的应用程序中禁用主题，但我们不想这么做。 我们认为技术性的解决方案可能不会有效，因为这不是技术问题。 在技术上，我们希望软件可以在没有人工干预的情况下被自动地重新设计，但这到目前为止仍然是个幻想。在这种技术现状被改善之前，这种（应用被主题搞炸）的情况几乎不可能被解决。因此，我们正试图通过这封信向大家告知这种情况，并尽自己的一份力量。 如果你想要美化你自己的系统，我们没有意见。然而，如果你改变了诸如图标、样式表等东西，你应当意识到你的行为不会得到支持（应该是指不会得到社区的帮助）。您遇到的任何问题都应直接报告给主题开发者，而不是软件开发者。 作为一个平台，我们坚信GTK应当停止强制默认在所有软件使用同一个样式表（也就是说应该可以为不同的软件指定不同的GTK样式）。应用程序不必通过把样式表写死来避免这种情况，而是应该使用平台样式表（系统提供的样式表），除非他们魔改了样式表以加入其他内容。 我们意识到这是一个复杂的问题，但假设每个应用程序都适用于每个样式表同样也是一个糟糕的默认设置。 如果你是更改了系统样式表和图标的发行版的开发人员，希望你重新考虑此决定。 在没有任何 QA 的情况下更改第三方应用程序是鲁莽的，并且在任何其他平台上都是不可接受的。 您的行为对我们这些应用程序开发人员造成了很大的伤害，并且正在损害除了您的发行版以外的整个软件生态。 我们理解发行版需要脱颖而出来吸引用户。但是，我们敦促您想办法在不剥夺我们代理权的情况下做到这一点。 我们厌倦了当人们告诉我们「这个主题魔改得还不错」时，我们必须为我们从未打算支持的设置做额外的工作。你绝对不会对 Blender、Atom、Telegram 或其他第三方应用程序做出这样的魔改。我们的应用程序使用 GTK 并不意味着我们可以接受别人对它们的魔改。 由于你要使用 GNOME 平台开发，我们预设「你希望这个软件生态是健康的」。如果现实确实如此，我们要求您停止使用主题装饰我们的软件的这一行为。 署名, Alexander Mikhaylenko Maintainer of Games Avi Wadhwa Maintainer of Organizer Bilal Elmoussaoui Maintainer of Authenticator, Icon Library, Contrast and Obfuscate Cédric Bellegarde Maintainer of Lollypop, Eolie, and Passbook Christopher Davis Core contributor to Fractal Daniel García Moreno Maintainer of Fractal and Timetrack Falk Alexander Seidl Maintainer of Password Safe Felix Häcker, Maintainer of Gradio/Shortwave, Fragments, and Remotely Forever XML Maintainer of Random Jan Lukas Gernert Author of FeedReader and NewsFlash Jordan Petridis Maintainer of Podcasts Julian Sparber Core contributor to Fractal, maintainer of Teleport Lains Maintainer of Notejot, Khronos, Dot Matrix, Quilter, and Emulsion Manuel Genovés Maintainer of UberWriter Maximiliano Sandoval Maintainer of Decoder and Lorem, core contributor to Password Safe Michael Gratton Maintainer of Geary Rafael Mardojai C.M. Maintainer of Blanket, Dialect, Share Preview and Webfont Kit Generator Sophie Herold Maintainer of Pika Backup Tobias Bernard Designer of Fragments and Podcasts (among others) Zander Brown Maintainer of Icon Preview The Bottles Developers The Pitivi Developers Note: Even though some of us are Foundation members or work on GNOME, these are our personal views as individuals, and not those of the GNOME Project, the GNOME Foundation, or our employers. 推荐阅读: 《libadwaita：修复 Linux 桌面的可用性问题》","categories":[],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://zhul.in/tags/%E7%BF%BB%E8%AF%91/"}]},{"title":"Waydroid on KDE 初体验","slug":"waydroid-experience-on-kde","date":"2021-10-31T07:57:57.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2021/10/31/waydroid-experience-on-kde/","link":"","permalink":"https://zhul.in/2021/10/31/waydroid-experience-on-kde/","excerpt":"","text":"在西木野羰基的博客中看到了其在Fedora中使用waydroid跑明日方舟的截图，心里有有些痒痒了，决定在Archlinux上尝试使用waydroid。 Waydroid是什么Waydroid是一个基于lxc容器技术，用以启动完整安卓系统的方案。 默认使用了LineageOS-17.1，对应 Aosp10，相比起 anbox 显然是更加新了。 内核支持waydroid需要内核提供Ashmem和binder支持，西木野羰基是使用的自己编译的内核。而我在使用Archlinux，因此直接使用linux-zen即可。 注: AUR上的linux-xanmod虽然也有这些模块支持，但是在编译时设置了psi=0以提升性能，而waydroid恰巧需要psi=1的支持，故不可使用。 安装Archlinux已经有人将其打包上传到了AUR，我们直接安装即可。我使用的 AUR Helper 是 yay，所以直接 1yay -S waydroid --noconfirm 再装个python-pyclip解决剪切板同步的问题 1yay -S python-pyclip 下载Waydroid镜像1sudo waydroid init 这一步将会自动（从SourceForge）下载纯净的LineageOS镜像压缩包并解压，处于中国大陆网络环境的用户记得（ ） 如果你需要Gapps，可以指定下载Gapps版本，但是这将需要你获取Android ID并向谷歌提交 Custom Rom 的 Gapps 申请。见这里 1sudo waydroid init -s GAPPS 启用服务这个没什么好说的，使用systemctl启动服务。 1sudo systemctl start waydroid-container.service 开启waydroid1waydroid session start 一些简单的使用技巧如果你想直接展示整个系统界面，可以使用 1waydroid show-full-ui 我们也可以用waydroid app launch $&#123;package_name&#125;的方式来启动单个应用（包名可以使用waydroid app list来获取 当然，可以直接在Linux环境里 安装 某个apk 1waydroid app install path/to/apkfile.apk F11有助于解决应用分辨率问题，左Alt有助于解决键盘无法输入的问题。 Github上有个脚本，可以帮助 安装OpenGapps/Magisk/arm转译库/获取Android ID。 牢骚时间 对AMD和英伟达的显卡支持都不太行 不能直接输入中文，还是得借助安卓系统内的输入法。 不自带arm转译库，通过脚本安装的转译库似乎兼容性挺差（至少我是成功打开什么arm软件 系统运行的流畅度还可以 相关的资料似乎有点少，官方的文档也没有写得太详细 Waydroid会自动在$HOME/.local/share/applications/为wayland内的安装应用添加Desktop文件（这让我有些反感 一些截图","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Experience","slug":"Experience","permalink":"https://zhul.in/tags/Experience/"},{"name":"KDE","slug":"KDE","permalink":"https://zhul.in/tags/KDE/"},{"name":"Waydroid","slug":"Waydroid","permalink":"https://zhul.in/tags/Waydroid/"}]},{"title":"PicUploader使用系列（二）——为KDE的dolphin添加右键快捷菜单","slug":"picuploader-with-kde-action","date":"2021-10-24T14:26:50.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/10/24/picuploader-with-kde-action/","link":"","permalink":"https://zhul.in/2021/10/24/picuploader-with-kde-action/","excerpt":"","text":"上一篇文章我们在Archlinux中成功部署了PicUploader的web端，本文我们来讲讲如何为KDE的dolphin添加右键快捷键上传，效果类似这样。（gif图来自PicUploader作者的博客) 创建.desktop文件12mkdir -p $HOME/.local/share/kservices5/touch $HOME/.local/share/kservices5/picuploader.desktop 填上这段内容12345678910111213[Desktop Entry]Actions=PicUploader;MimeType=image/jpeg;image/png;Type=ServiceX-KDE-Priority=TopLevelX-KDE-ServiceTypes=KonqPopupMenu/PluginIcon=/var/www/image/favicon.ico[Desktop Action PicUploader]Name=Upload with PicUploaderName[zh_CN]=使用PicUploader上传Icon=/var/www/image/favicon.icoExec=php /var/www/image/index.php %F | scopy 注: 这里的 scopy 是我在下面自己创建的一段脚本，用以同时满足x11和wayland下的使用，如果你仅使用x11的话直接改成xclip -selection clipboard即可。 MimeType指的是文件类型。在这份desktop中，我仅指定了png和jpg文件在右键时会弹出picuploader的上传菜单，如果你需要更多文件类型的MimeType，你可以参考下gwenview的desktop都写了哪些文件类型。 MimeType=inode/directory;image/avif;image/gif;image/jpeg;image/png;image/bmp;image/x-eps;image/x-icns;image/x-ico;image/x-portable-bitmap;image/x-portable-graymap;image/x-portable-pixmap;image/x-xbitmap;image/x-xpixmap;image/tiff;image/x-psd;image/x-webp;image/webp;image/x-tga;application/x-krita;image/x-kde-raw;image/x-canon-cr2;image/x-canon-crw;image/x-kodak-dcr;image/x-adobe-dng;image/x-kodak-k25;image/x-kodak-kdc;image/x-minolta-mrw;image/x-nikon-nef;image/x-olympus-orf;image/x-pentax-pef;image/x-fuji-raf;image/x-panasonic-rw;image/x-sony-sr2;image/x-sony-srf;image/x-sigma-x3f;image/x-sony-arw;image/x-panasonic-rw2; 安装所需组件通知提示右下角弹出文字提示的功能依赖于libnotify 1sudo pacman -S libnotify --needed 复制到粘贴板复制到粘贴板的功能依赖于xclip sudo pacman -S xclip --needed 考虑到我可能在 x11 和 wayland 之间反复横跳，仅仅一个xclip看起来满足不了我的需求 1sudo pacman -S xclip wl-clipboard --needed 手糊了一段脚本，用以判断对应的运行环境并调用相应的粘贴板工具 1234567891011/usr/bin/scopy---#!/bin/bashif [ &quot;$XDG_SESSION_TYPE&quot; = &quot;wayland&quot; ]; then wl-copyelif [ &quot;$XDG_SESSION_TYPE&quot; = &quot;x11&quot; ]; then xclip -selection clipboardelse echo &quot;ERROR! You are using $XDG_SESSION_TYPE&quot;fi 为/usr/bin/scopy授予运行权限 1sudo chmod 755 /usr/bin/scopy 启用该动作菜单1kbuildsycoca5 处理普通用户无权写入logs的问题1sudo chmod 777 -R /var/www/image/logs/ 最终结果 参考链接在 KDE Plasma 5 的 Dolphin 中添加一个右键动作菜单 PicUploader: 一个还不错的图床工具","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"PHP","slug":"PHP","permalink":"https://zhul.in/tags/PHP/"},{"name":"KDE","slug":"KDE","permalink":"https://zhul.in/tags/KDE/"},{"name":"PicUploader","slug":"PicUploader","permalink":"https://zhul.in/tags/PicUploader/"}]},{"title":"PicUploader使用系列（一）——在Archlinux上使用Caddy部署PicUploader","slug":"picuploader-on-archlinux-with-caddy","date":"2021-10-21T14:15:33.000Z","updated":"2023-12-12T06:37:16.000Z","comments":true,"path":"2021/10/21/picuploader-on-archlinux-with-caddy/","link":"","permalink":"https://zhul.in/2021/10/21/picuploader-on-archlinux-with-caddy/","excerpt":"","text":"之前找对大陆网络友好的图床时，找到了cloudinary，但是全英文界面对操作增加了不少难度，其页面也不是很简洁，让我一下打消了使用网页版的念头。通过搜索，找到了 PicUploader 这一方案，使用php编写，支持cloudinary的api。 作者在其博客中仅提供了nginx的部署方案，我参考其配置文件成功实现了在caddy下的部署，并且花费了数个小时排坑，故写下本文帮助后来者节省时间。 安装caddy和php-fpm以及所需的拓展1sudo pacman -S caddy php-fpm php-gd php-sqlite --needed 配置php-fpm在/etc/php/php.ini启用PicUploader所需拓展PicUploaer依赖于fileinfo、gd、curl、exif、pdo_sqlite拓展，可以使用php -m命令来查看目前加载成功了的插件。 12345678910111213141516171819202122232425262728293031323334353637383940414243;extension=bcmath;extension=bz2;extension=calendar- extension=curl+ extension=curl;extension=dba;extension=enchant- extension=exif+ extension=exif;extension=ffi;extension=ftp- extension=gd+ extension=gd;extension=gettext;extension=gmp;extension=iconv;extension=imap;extension=intl;extension=ldap;extension=mysqli;extension=odbc;zend_extension=opcache;extension=pdo_dblib;extension=pdo_mysql;extension=pdo_odbc;extension=pdo_pgsql- extension=pdo_sqlite+ extension=pdo_sqlite;extension=pgsql;extension=pspell;extension=shmop;extension=snmp;extension=soap;extension=sockets;extension=sodium;extension=sqlite3;extension=sysvmsg;extension=sysvsem;extension=sysvshm;extension=tidy;extension=xmlrpc;extension=xslextension=zip 编辑/etc/php/php.ini以增加单文件上传大小限制查出这个问题浪费了我整整4小时时间。 12- upload_max_filesize = 2M+ upload_max_filesize = 100M 编辑/etc/php/php-fpm.d/www.conf使其在运行时使用caddy用户。12345678910111213141516171819202122232425262728293031---; Unix user/group of processes; Note: The user is mandatory. If the group is not set, the default user&#x27;s group; will be used.- user = http+ user = caddy- group = http+ group = caddy; The address on which to accept FastCGI requests.; Valid syntaxes are:; &#x27;ip.add.re.ss:port&#x27; - to listen on a TCP socket to a specific IPv4 address on; a specific port;; &#x27;[ip:6:addr:ess]:port&#x27; - to listen on a TCP socket to a specific IPv6 address on------; Note: This value is mandatory.listen = /run/php-fpm/php-fpm.sock; and group can be specified either by name or by their numeric IDs.; Default Values: user and group are set as the running user; mode is set to 0660- listen.owner = http+ listen.owner = caddy- listen.group = http+ listen.group = caddy;listen.mode = 0660; When POSIX Access Control Lists are supported you can set them using; these options, value is a comma separated list of user/group names.; When set, listen.owner and listen.group are ignored;listen.acl_users =;listen.acl_groups =--- 2022年1月14日更新：在 Fedora 尝试部署的时候遇到了新的坑，Fedora 的相应配置文件为 /etc/php-fpm.d/www.conf，相应修改如下 12345678910111213141516171819202122232425262728293031323334353637383940; Unix user/group of processes; Note: The user is mandatory. If the group is not set, the default user&#x27;s group; will be used.; RPM: apache user chosen to provide access to the same directories as httpd-user = apache+user = caddy; RPM: Keep a group allowed to write in log dir.-user = apache+group = caddy; The address on which to accept FastCGI requests.; Valid syntaxes are:; &#x27;ip.add.re.ss:port&#x27; - to listen on a TCP socket to a specific IPv4 address on; a specific port;------; Set permissions for unix socket, if one is used. In Linux, read/write; permissions must be set in order to allow connections from a web server.; Default Values: user and group are set as the running user; mode is set to 0660-;listen.owner = nobody+listen.owner = caddy-;listen.owner = nobody+listen.group = caddy;listen.mode = 0660; When POSIX Access Control Lists are supported you can set them using; these options, value is a comma separated list of user/group names.; When set, listen.owner and listen.group are ignored-listen.acl_users = apache,nginx+;listen.acl_users = apache,nginx;listen.acl_groups =; List of addresses (IPv4/IPv6) of FastCGI clients which are allowed to connect.; Equivalent to the FCGI_WEB_SERVER_ADDRS environment variable in the original; PHP FCGI (5.2.2+). Makes sense only with a tcp listening socket. Each address; must be separated by a comma. If this value is left blank, connections will be; accepted from any ip address.; Default Value: anylisten.allowed_clients = 127.0.0.1 拉取 PicUploader 最新代码首先创建一个用于存放代码的目录 1sudo mkdir -p /var/www/ clone 最新源码 1sudo git clone https://github.com/xiebruce/PicUploader.git /var/www/picuploader 将代码所有权转交给caddy用户 1sudo chown -R caddy:caddy /var/www/picuploader 编辑Caddyfilecaddy默认使用/etc/caddy/Caddyfile，因此如果你就部署这一个站点，直接修改这个就好了。 caddy的语法非常简洁易懂，因此我随手写了几行就能跑起来了。 下面是我用的Caddyfile，如果你在服务器上部署，请把http://api.picuploader.com更换为你服务器所需要绑定的域名(不带http协议头)，caddy将自动为你申请ssl证书。 123456789101112131415161718192021http://api.picuploader.com &#123; root * /var/www/picuploader php_fastcgi * unix//run/php-fpm/php-fpm.sock &#123; index dashboard.php &#125; file_server &#123; index index.php &#125; handle_errors &#123; root * /etc/caddy/error rewrite * /error.html templates file_server &#125;&#125;# Import additional caddy config files in /etc/caddy/conf.d/import /etc/caddy/conf.d/* php我选择了监听本地unix//run/php-fpm/php-fpm.sock的方案，这个路径在上文的/etc/php/php-fpm.d/www.conf可以设置，如需查询，直接使用 grep listen\\ = /etc/php/php-fpm.d/www.conf应该就能看见。 设置访问密码（可选）caddy2开始不允许在caddyfile中直接指定明文密码，因此我们需要用hash-password获取加密后的密码密文 1caddy hash-password --plaintext &lt;YourPassword&gt; 再在Caddyfile中，加上 123basicauth /* &#123; &lt;username&gt; &lt;hashed_password&gt;&#125; 修改hosts/设置DNS解析由于 api.picuploader.com 这个域名不在我手里，而我只是想在本地使用，并不打算部署到服务器，因此修改hosts将这个域名解析到本地是个不错的选择。 1sudo sh -c &quot;echo &#x27;127.0.0.1 api.picuploader.com&#x27; /etc/hosts&quot; 而你若是在服务器上部署，应当去设置DNS解析，这个应该不需要我多说。 开启服务在Archlinux下，我习惯直接用systemd运行caddy和php-fpm以开机自启动。 1sudo systemctl enable --now caddy php-fpm 最终测试在浏览器内访问 api.picuploader.com ，如果能看到页面，就算是成功啦。 设置上传参数见作者博客：PicUploader: 各图床获取上传图片参数的方法","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"PHP","slug":"PHP","permalink":"https://zhul.in/tags/PHP/"},{"name":"Caddy","slug":"Caddy","permalink":"https://zhul.in/tags/Caddy/"},{"name":"PicUploader","slug":"PicUploader","permalink":"https://zhul.in/tags/PicUploader/"}]},{"title":"Archlinux坚果云踩坑实录","slug":"nutstore-guide-on-archlinux-kde","date":"2021-10-01T16:21:34.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/10/02/nutstore-guide-on-archlinux-kde/","link":"","permalink":"https://zhul.in/2021/10/02/nutstore-guide-on-archlinux-kde/","excerpt":"","text":"在Archlinux上，坚果云似乎出现了一些问题。 安装1yay -S nutstore 这个没什么可说的，AUR还是Archlinuxcn都无所谓，都是一模一样的。 白屏双击图标，咦？怎么白屏了？ 看看AUR评论区，有人说nutstore-experimental修了？ 对比了一下，就是改了改/opt/nutstore/conf/nutstore.properties 1sudo sed -i &#x27;s|webui.enable=true|webui.enable=false|&#x27; /opt/nutstore/conf/nutstore.properties 轻松解决 窗口太小不能登陆 桌面使用了暗色主题导致部分字体不清晰？ 参考使用fakehome方案暂时解决跑在KDE暗色主题下的程序使用亮色字体的问题编写启动命令 1bwrap --dev-bind / / --tmpfs $HOME/.config /usr/bin/nutstore 本地markdown文件的文件类型被识别成了「坚果云 Markdown」这个是由于坚果云自作主张推广他自己并不好用的lightapp，写了几条 mime 的规则，如图 看来在我们的启动命令中也需要防止坚果云接触到$HOME/.local/share/这个路径，所以现在的启动命令得写成这样。 1bwrap --dev-bind / / --tmpfs $HOME/.config --tmpfs $HOME/.local/share/ /usr/bin/nutstore 修改desktop文件，使其使用我们自己攥写的启动命令首先，复制一份desktop文件到我们的 $HOME 目录下，好处是下次更新的时候我们所做的更改不会被包管理器覆盖。 1cp /usr/share/applications/nutstore.desktop $HOME/.local/share/applications/ 再修改$HOME/.local/share/applications/nutstore.desktop 12345678910111213[Desktop Entry]Encoding=UTF-8Type=ApplicationTerminal=falseIcon=nutstore-Exec=/usr/bin/nutstore+Exec=bwrap --dev-bind / / --tmpfs $HOME/.config --tmpfs $HOME/.local/share/applications --tmpfs $HOME/.local/share/mime /usr/bin/nutstoreStartupWMClass=NutstoreName=NutstoreName[zh_CN]=坚果云 Comment=Data Sync, Sharing, BackupComment[zh_CN]=数据同步,共享和备份Categories=Network;Application;","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"}]},{"title":"把老版的火狐顶栏UI带回来","slug":"bring-firefox-old-topbar-back","date":"2021-10-01T11:20:23.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/10/01/bring-firefox-old-topbar-back/","link":"","permalink":"https://zhul.in/2021/10/01/bring-firefox-old-topbar-back/","excerpt":"","text":"在Firefox更新UI以后，我就一直感觉不太适应。顶栏的一个个标签页占用的体积达到了原来的1.5~2倍。Thanks to black7375/Firefox-UI-Fix ，我们得以把以前的顶栏找回来。 加载新的cssclone该github项目并进入对应路径后，执行install.sh 123git clone https://github.com/black7375/Firefox-UI-Fix.gitcd Firefox-UI-Fix.git./install.sh 在接下来的对话中，我们选择Photon-Style，这是最接近老版UI的。 紧接着脚本会要求我们选择我们的Firefox数据文件夹，我们可以打开Firefox，在浏览器地址栏输入about:support查看到我们所使用的数据文件夹路径。 使用空格键选择我们的数据文件夹后，在终端上该路径开头处的[ ]中会被打上X，确认无误后，敲回车。 重启浏览器，顶栏就长成了这样。 添加主题为了进一步模仿Firefox经典的配色，我们可以安装上这个主题，变成这样 禁用暗色模式如果你的系统主题使用的是深色，导致了诸如TUNA镜像站自动为你启用了暗色模式，而你想禁用的话，之前通过修改about:config方案依然适用。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Firefox","slug":"Firefox","permalink":"https://zhul.in/tags/Firefox/"},{"name":"Bwrap","slug":"Bwrap","permalink":"https://zhul.in/tags/Bwrap/"}]},{"title":"记录一次原创文章被抄袭","slug":"csdn-copied-my-article","date":"2021-09-20T16:00:00.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/09/21/csdn-copied-my-article/","link":"","permalink":"https://zhul.in/2021/09/21/csdn-copied-my-article/","excerpt":"","text":"今天在网站自搜的时候偶然间发现了一个叫「程序员宝宝」的站点转载了我去年在知乎专栏上发的一篇文章《Ubuntu下对deepin-wine的使用详解》。 转载的质量并不高，超链接都没有转载上去，只有干巴巴的图片和文字。翻到结尾处，我一口老血喷出。 我就纳闷了，我作为原创博主，自己都没有给这篇文章挂上CC的版权协议，怎么就有人自称是原创给我挂上了CC协议，要知道我知乎还明确勾选了「转载需要申请」呢。 抱着吃瓜的心态在谷歌上搜索，我发现了五篇抄袭我的文章。CSDN三篇，还有「程序员宝宝」和「程序员宅基地」使用相同UI的、被我怀疑是机器人搬运的站点。 CSDN那边，我在页面页脚处找到了「在线客服」，注册帐号后联系了客服，客服反应非常迅速，5分钟内就对抄袭文章进行了下架处理，这点值得表扬。 至于「程序员宝宝」和「程序员宅基地」这两个站点，在他们的版权申明中写得很清楚。 如果你是文章作者： 请通过邮件联系我们，邮件内容包括： 待删除的文章链接 发件人是待删除文章作者的证明（如果发件人邮箱地址能证明你是文章作者，此项内容可以为空） 我们会在收到邮件后7个工作日内进行处理。 但我找遍了整个网站，根本没有发现站点方的邮箱。 不知诸位有何解决方案？","categories":[],"tags":[{"name":"Blog","slug":"Blog","permalink":"https://zhul.in/tags/Blog/"}]},{"title":"使用AUR(Helper)安装软件时究竟发生了什么？对于常见的构建错误如何解决？","slug":"detailed-explanation-for-aur","date":"2021-09-11T11:22:29.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2021/09/11/detailed-explanation-for-aur/","link":"","permalink":"https://zhul.in/2021/09/11/detailed-explanation-for-aur/","excerpt":"","text":"虽然对于没有能力手动修改/编写PKGBUILD的Arch用户其实是不应该使用AUR中的包的，这些软件的PKGBUILD可以由个人随意发布，并不能保证安全性，但是作为Archlinux的特色，但随着AUR Helper的趋于便利，还是吸引了不少小白使用AUR。本文将主要讲一讲 AUR Helper 帮助我们安装软件时到底做了些什么事情，并提供一些使用AUR Helper构建时常见错误的解决方案。 PartⅠ基本原理makepkg是如何工作的？以钉钉举例，我们可以从AUR上使用 git clone https://aur.archlinux.org/dingtalk-bin.git 获取到由这个包的维护者为我们提前写好的构建脚本。他的目录大概是长成下面这个样子: 12345678dingtalk-bin├── com.alibabainc.dingtalk.desktop├── dingtalk.sh├── .git├── .gitignore├── PKGBUILD├── service-terms-zh└── .SRCINFO 其中，.git是git的工作目录，可以忽视。 .gitignore属于git的配置文件之一，我们也不用管。 PKGBUILD是这个目录下最重要的东西，是一个用于提供参数的脚本。makepkg通过执行PKGBUILD脚本来获取到参数，自动进行下载和构建过程。 service-terms-zh, com.alibabainc.dingtalk.desktop, dingtalk.sh是包里所需要用到的东西。 当我们cd到这个目录下执行makepkg时， makepkg会调用curl / git下载PKGBUILD中source=()部分中以http(s)协议头或者git+开头的链接，这些东西将会被下载到这个目录的src文件夹下。 对于curl下载的东西，makepkg会使用校验码核对下载到的文件是否完整、是否是当初这个包的维护者下载到的这一个。 校验通过后，makepkg会依次执行prepare()&#123;&#125;、build()&#123;&#125;、package()&#123;&#125;函数中的命令陆续完成准备、编译过程，并将最终要打进包里的文件放置到pkg文件夹下。 最后，makepkg将会将pkg文件夹的内容压缩成包。 AUR Helper 干了些什么我们还是以钉钉为例，看看我们执行yay dingtalk-bin时到底发生了什么。 PartⅡ常见错误解决方案如果有其他情况觉得可以完善的，欢迎在评论区留言。 1. base-devel 没有安装正如上面所说的，没有安装base-devel组，赶紧补上! 由于base-devel并不是一个具体的包，而是由多个包构成的包组，其实并没有很好的方法来检测你是否已经安装。 所以如果你不确定，你也可以执行下面的命令来确保自己已经安装。 1sudo pacman -S base-devel --noconfirm --needed 常见表现: 1ERROR: Cannot find the strip binary required for object file stripping. 1PKGBUILD: line XXX XXX: command not found 2. source源文件下载失败 网络问题国内的网络问题不用多说了，大多数情况下都是Github连接不上。 最简单的解决方案就是把source里下载失败的东西通过特殊手段（比如你浏览器设置下代理，或者找找fastgit这种反代）下载下来以后直接扔到PKGBUILD所在的路径，然后手动执行makepkg -si。 -s代表自动下载makedepend，-i表示构建成功以后自动安装 yay存放PKGBUILD的默认路径是在$HOME/.cache/yay/$pkgname下面，具体可以参考我的另一篇关于yay的用法详解的博客。 我在这里再讲一种使用 fastgit 作为反代加速github下载的方法。如果觉得fastgit帮助到了你，你可以考虑给fastgit项目打钱。 当你的yay出现这个询问菜单时，（也就是出现Diffs to show/显示哪些差异？字样时） 我们再开一个终端，输入 1sed -i &quot;s|github.com|hub.fastgit.org|g&quot; $HOME/.cache/yay/*/PKGBUILD 接着就下一步安装即可。 链接失效这种情况多见于维护者维护不到位，上游放出了新版本包并删除老版本包以后维护者没有及时跟进的。你可以去逛一逛AUR的评论区查看解决方案，或者去查找上游的最新版本是多少，尝试更改PKGBUILD中的pkgver参数和checksum以后尝试makepkg。 需要手动下载一般情况下是上游没有提供直链，makepkg无法自行下载，需要人工介入。解决方法同上面的网络问题 3. checksum 错误上文已经提到过，checksum用于判断你所下载到的软件和维护者当初下载到的是否一致。但是有些情况下，确实是维护者忘了更新checksum值了，因此我们需要做一个判断。 打开.SCRINFO，找到checksum报错的那个文件的链接。 使用wget/curl等工具将他下载下来，可以通过md5sum+文件名的方式获取他们的md5值。连续下载两次，核对两次的检验值是否一致。 如果结果一致，那么说明并不是网络波动导致的检验值不符，而是维护者没有及时跟进导致的，你可以使用yay -S $pkgname --skipchecksums的方式跳过验证校验值的过程，或者你可以修改PKGBUILD中的校验值为&quot;SKIP&quot;来跳过某一文件的校验后手动makepkg。 4. tuna反代受限tuna的服务器只有一个ip，但当使用他提供的AUR的反代服务时，全国的使用者都会被AUR认为是tuna这一个ip，过大的请求数量可能导致tuna的服务器超出AUR每天给每个ip限制的请求次数。 具体表现: 1Rate limit reached 解决方案，改回AUR的服务器，使用自己的ip进行请求 1yay --aururl &quot;https://aur.archlinux.org&quot; --save 写在最后关于AUR使用的更多细节可以阅读 《yay进阶》","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"}]},{"title":"使用fakehome方案暂时解决跑在KDE暗色主题下的程序使用亮色字体的问题","slug":"wrong-fonts-color-fix-under-kde-with-a-dark-theme","date":"2021-09-04T16:00:00.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/09/05/wrong-fonts-color-fix-under-kde-with-a-dark-theme/","link":"","permalink":"https://zhul.in/2021/09/05/wrong-fonts-color-fix-under-kde-with-a-dark-theme/","excerpt":"","text":"9月6日更新：AUR的wemeet-bin维护者sukanka已经将咱的运行指令直接打进了包内，故本文已经基本失去原本的应用意义，但仍可以作为一个案例来解决类似问题。 在使用腾讯最近推出的Linux原生腾讯会议的时候，咱遇到了个十分影响体验的问题。 我在使用KDE的暗色主题，腾讯回忆自作主张将字体颜色调成了白色。然而，字体背景是白色的没，因此导致对比度下降，字体难以辨认。效果大概是这个鬼样子: 然而我一时半会儿却找不到合适的变量在运行腾讯会议之前unset，无法指定它使用一个正确的字体颜色。 此时，我想到了fakehome的解决方案——bwrap。 关于bwrap，依云在ta的博客里讲过运行原理，我在这里直接摘一小段过来 bwrap 的原理是，把 / 放到一个 tmpfs 上，然后需要允许访问的目录通过 bind mount 弄进来。所以没弄进来的部分就是不存在，写数据的话就存在内存里，用完就扔掉了。 而我们要做的，就是开一个tmpfs作为$HOME/.config，让腾讯会议读取不到KDE的主题配置文件。 使用如下命令 1bwrap --dev-bind / / --tmpfs $HOME/.config wemeet 软件启动确认没有问题后，我们可以更改腾讯会议desktop中的启动命令 1sudo $EDITOR /usr/share/applications/wemeetapp.desktop 将Exec=后面的命令改成我们刚刚启动所使用的命令即可。 关键词: bwrap, linux, 暗色模式, 深色模式, 夜间模式, 白色字体, 亮色字体","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Bwrap","slug":"Bwrap","permalink":"https://zhul.in/tags/Bwrap/"}]},{"title":"来，从AUR给Fedora偷个包","slug":"build-a-rpm-package-from-aur-with-archlinux","date":"2021-07-22T17:50:09.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/07/23/build-a-rpm-package-from-aur-with-archlinux/","link":"","permalink":"https://zhul.in/2021/07/23/build-a-rpm-package-from-aur-with-archlinux/","excerpt":"","text":"前一阵子，某Q群里的某初中生居然跳上了Fedora这辆灵车，还一直缠着我要我给他整个打rpm包的教程，说什么要复兴FedoraCN之类的我听不懂的话。碰巧听说Fedora似乎还没有wechat-uos，于是我就寻思着给Fedora打一个，顺便熟悉一下dnf的操作。 事实上，Fedora和Archlinux的目录结构很相似，理论上来讲Archlinux的大部分包都可以直接解压后塞到Fedora里直接用，对于咱这种日常偷Deb包的Arch用户来说基本没什么难度，唯一的难点在于处理依赖关系。 Tips1: 使用电脑端的访客可以在页面左下角打开侧栏以获取目录。 下载链接如果你是为了wechat-uos这个包而非教程而来的，下载链接在这里。https://zhullyb.lanzoui.com/ikN55rqr7ah 偷包环境 Archlinux实体机(打包) Fedora虚拟机(依赖查询、测试) 准备好wechat-uos首先，咱们先在Archlinux上把我们的wechat-uos先打包好，这个老生常谈的问题我不多赘述了。 1yay -S wechat-uos --noconfirm 查找wechat-uos在Archlinux上所需的依赖再去查看wechat-uos所需要的依赖 1234567891011121314151617181920212223[zhullyb@Archlinux ~]$ yay -Si wechat-uos:: Querying AUR...Repository : aurName : wechat-uosKeywords : electron patched uos wechat weixinVersion : 2:2.0.0-1145141919Description : UOS专业版微信 (迫真魔改版)URL : https://www.chinauos.com/resource/download-professionalAUR URL : https://aur.archlinux.org/packages/wechat-uosGroups : NoneLicenses : MITProvides : NoneDepends On : gtk2 gtk3 libxss gconf nss lsb-release bubblewrapMake Deps : imagemagickCheck Deps : NoneOptional Deps : NoneConflicts With : NoneMaintainer : DuckSoftVotes : 16Popularity : 0.603501First Submitted : Wed 30 Dec 2020 12:21:51 PM CSTLast Modified : Sat 20 Feb 2021 06:53:24 AM CSTOut-of-date : No 查找Fedora上的对应依赖包名然后我们需要去Fedora上找一找这些依赖在Fedora上的包名都叫什么。 比如这个bubblewrap，我们需要的是他提供的bwrap，所以我们直接在Fedora上sudo dnf provides bwrap 再比如gconf并没有在/usr/bin路径下直接留下什么非常具有代表性的可执行文件，所以在Fedora里面寻找等效包就稍微复杂一些，但也并非不能找。 先在Archlinux下使用pacman -Ql gconf，输出结果有点长，我就截一小段上来。 12345678910111213141516171819[zhullyb@Archlinux ~]$ pacman -Qlq gconf/etc//etc/gconf//etc/gconf/2//etc/gconf/2/evoldap.conf/etc/gconf/2/path/etc/gconf/gconf.xml.defaults//etc/gconf/gconf.xml.mandatory//etc/gconf/gconf.xml.system//etc/xdg//etc/xdg/autostart//etc/xdg/autostart/gsettings-data-convert.desktop/usr//usr/bin//usr/bin/gconf-merge-schema/usr/bin/gconf-merge-tree/usr/bin/gconfpkg/usr/bin/gconftool-2...... 可以发现，gconf还是有不少文件是非常具有代表性的，比如这里的/usr/bin/gconf-merge-tree，我们在Fedora上使用sudo dnf provides gconf-merge-tree很容易就能找到对应的包是GConf2。 lsb-release这个依赖中，我们只是需要/etc/lsb-release这个文件存在让我们的bwrap可以顺利地伪装成uos的样子。Fedora中虽然有redhat-lsb-core这个包算是lsb-release的等效包，但是并不提供这个文件，因此我们只需要在待会儿打包的时候带一个/etc/lsb-release的空文件即可，不需要将redhat-lsb-core写进依赖。 最终我们可以确定下来需要的依赖为gtk2,gtk3,libXScrnSaver,nss,bubblewrap,GConf2。 准备打包安装rpm-tools1sudo pacman -S rpm-tools 生成工作路径1mkdir -pv $HOME/rpmbuild/&#123;BUILD,BUILDROOT,RPMS,SOURCES,SPECS,SRPMS&#125; 编写 spec 文件1234567891011121314151617181920212223242526272829303132333435Name: wechat-uosVersion: 2.0.0Release: 1Summary: A wechat client based on electron.License: NoneURL: https://www.chinauos.com/resource/download-professionalPackager: zhullybRequires: gtk2,gtk3,libXScrnSaver,nss,bubblewrap,GConf2AutoReqProv: no%description%prep%pre%post%preun%postun%files/etc/lsb-release/opt/wechat-uos//usr/bin/wechat-uos/usr/lib/license/libuosdevicea.so/usr/share/applications/wechat-uos.desktop/usr/share/icons/hicolor/128x128/apps/wechat.png/usr/share/icons/hicolor/16x16/apps/wechat.png/usr/share/icons/hicolor/256x256/apps/wechat.png/usr/share/icons/hicolor/48x48/apps/wechat.png/usr/share/icons/hicolor/64x64/apps/wechat.png 处理source 一般来说，我们需要配置各种奇奇怪怪的编译命令，但是我这里直接选择了打包二进制文件，一来是减少了对于spec的学习成本，二来是因为wechat-uos本来就不开源，也没什么好编译的。 创建我们wechat-uos的二进制文件所需要放入的文件夹。 1mkdir $HOME/rpmbuild/BUILDROOT/wechat-uos-2.0.0-1.x86_64 将我们的wechat-uos直接放入对应的文件夹中 补上我们的/etc/lsb-release 12mkdir $HOME/rpmbuild/BUILDROOT/wechat-uos-2.0.0-1.x86_64/etc/touch $HOME/rpmbuild/BUILDROOT/wechat-uos-2.0.0-1.x86_64/etc/lsb-release 正式打包1rpmbuild -bb --target=x86_64 SPECS/wechat-uos.spec --nodeps 安装测试1sudo dnf install ./wechat-uos-2.0.0-1.x86_64.rpm 写在最后rpm的打包工具是我近期最想吐槽的东西了，主要槽点有两个。 其一是：rpm在打包时的默认状态下，会使用 file 命令判断文件，如果是二进制的，用ldd判断依赖；如果是脚本，过滤文件中对应的 use/requires/import 语句，以此来找出内部依赖。这固然是个非常贴心的小善举，能够确保软件正常运行，但完全有可能造成比较奇怪的问题。比如我本次打包中rpm自作聪明地给我添加了一个libffmpeg.so的依赖，这东西整个Fedora自带的四个源里都不存在，在安装测试的时候出现了找不到依赖的情况。想我这种添加了找不到依赖的情况还算是运气好的，之前听说有人在使用opensuse的某个私人源的时候发现安装网易云音乐居然吧wps-office都给依赖上了，我想就是rpm自动检测到了网易云需要某个库，而wps恰好自带了这个库而导致的依赖误报。在Archlinux中，我们有一个叫namcap的小工具能够使用类似的方法检测软件运行时可能所需要的内部依赖，但他并不会默认启用，更不会自说自话的就直接把他添加为依赖，连一声也不吭。 其二是：rpm检测新增包内文件是否与系统已安装的软件包内的文件因为使用相同路径而冲突时，不仅会核对是否有冲突的同路径同名文件，他还会核对文件夹的文件占用情况。这说起来可能会有些抽象，我举个例子。在Fedora中，/usr/bin路径是被filesystem这个包所占有的，所以其他包在打包时是不能直接使用/usr/bin、/usr、甚至/来限定包内文件的范围的（也就是上面spec文件中的%files区域）。而我在第一次打包时，想要直接打包BUILDROOT下的所有文件，于是%files就直接填写了/作为限定，安装时提示/usr/bin和/usr/lib被filesystem这个包所占用，文件冲突。为此我还特意去仔细对比了Fedora自带的filesystem和我这个wechat-uos是否有冲突的文件，实则证明并没有，只是单纯这个检测机制过于死板罢了。而在Archlinux中，pacman安装时只会检测包内的文件是否与系统内的现有文件路径产生冲突，而不会非常无意义的去限定哪个文件夹是属于哪个包的。 附上本文的参考资料 为了避免源网页失效，我特意去互联网档案馆做了备份 「RPM打包原理、示例、详解及备查」 「Archive」 「在 Ubuntu 下直接将二进制文件制作成 rpm 包」 「Archive」 「解除RPM包的依赖的方法」 「Archive」 本文同时发布于「知乎专栏」，如果你恰好有知乎帐号的话或许可以考虑帮我点个赞？","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Fedora","slug":"Fedora","permalink":"https://zhul.in/tags/Fedora/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"RPM Package","slug":"RPM-Package","permalink":"https://zhul.in/tags/RPM-Package/"}]},{"title":"下载一份openharmony的源码","slug":"download-openharmony-source-code","date":"2021-06-06T08:47:34.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/06/06/download-openharmony-source-code/","link":"","permalink":"https://zhul.in/2021/06/06/download-openharmony-source-code/","excerpt":"","text":"不知道为什么，总是有人告诉我鸿蒙已经开源了，不信可以自己去看源码balabala，其实鸿蒙的手机端目前为止依然没有开源，或者说没有完整完整开源。本文我将介绍如何拉取一份openharmony开源的源码。 首先需要准备以下东西 一台装有类unix环境的电脑（wsl大概也行） 6G磁盘剩余空间 互联网（如果使用手机流量的话大概是1.5G） 安装git没什么好说的，不再赘述。 设置git用户名和邮箱 12git config --global user.email &quot;you@example.com&quot;git config --global user.name &quot;Your Name&quot; 下载repo（这个大多数发行版自己都有打包，但是都比较滞后，不如直接下载最新版的二进制文件设置好path变量直接用） 12345678910111213mkdir -p ~/bincurl https://storage.googleapis.com/git-repo-downloads/repo &gt; ~/bin/repochmod a+x ~/bin/repocat &gt;&gt; ~/.bashrc &lt;&lt;EOF# set PATH so it includes user&#x27;s private bin if it existsif [ -d &quot;\\$HOME/bin&quot; ] ; then PATH=&quot;\\$HOME/bin:\\$PATH&quot;fiEOFsource ~/.bashrc 新建一个文件夹以同步源码 1mkdir openharmony 进入这个文件夹 1cd openharmony 初始化repo 1repo init -u https://gitee.com/openharmony/manifest.git --depth=1 ​ 注: --depth=1是为了仅保留一层commit记录，防止过多的历史commit占用空间，如果你想保留历 史commit，那可以把这里的--depth=1去掉。 使用repo正式开始同步源码 1repo sync repo在sync的时候其实可以加很多选项，可以通过repo help自行研究，我自己常用的是repo sync --force-sync --current-branch --no-tags --no-clone-bundle --optimized-fetch --prune -j$(nproc --all) -f1 看到以下提示代表同步成功 1repo sync has finished successfully. 后话结果就当源码下载好并开始checkout后，出现了以下错误 1234567Garbage collecting: 100% (220/220), done in 1.204sUpdating files: 100% (35/35), done.Updating files: 100% (27/27), done.git-lfs filter-process --skip: line 1: git-lfs: command not foundfatal: the remote end hung up unexpectedlyerror.GitError: Cannot checkout device_hisilicon_modules: Cannot initialize work tree for device_hisilicon_moduleserror: Cannot checkout device_hisilicon_modules 看着error很容易可以发现是我的系统没有git-lfs的原因，看样子openharmony使用了git-lfs来储存了某个大文件。 1sudo pacman -S git-lfs #别的发行版请自行查找相关安装方法 于是乎，安装好git-lfs重新sync源码 oepnharmony目录下，.repo文件夹内是你从git服务器上下载下来的原始数据，repo将在所有数据下载完成以后将他们自动checkout成代码。 源码结构是下面这个样子 123456789101112131415161718192021222324.├── applications├── base├── build├── build.py -&gt; build/lite/build.py├── build.sh -&gt; build/build_scripts/build.sh├── developtools├── device├── docs├── domains├── drivers├── foundation├── .gn -&gt; build/core/gn/dotfile.gn├── interface├── kernel├── prebuilts├── productdefine├── .repo├── test├── third_party├── utils└── vendor18 directories, 3 files 我提供个参考数据，AOSP源码不含.repo原始数据的大小是40G，就openharmony这个代码量，恐怕很难让我相信这是一个兼容安卓应用的系统的完整代码。","categories":[],"tags":[]},{"title":"在Windows与Linux双系统下共享蓝牙鼠标","slug":"share-xiaomi-bluetooth-mouse-on-both-windows-and-linux","date":"2021-05-29T16:00:00.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/05/30/share-xiaomi-bluetooth-mouse-on-both-windows-and-linux/","link":"","permalink":"https://zhul.in/2021/05/30/share-xiaomi-bluetooth-mouse-on-both-windows-and-linux/","excerpt":"","text":"我自己使用的鼠标是一只小米的无线蓝牙双模鼠标。但是由于我的USB接口不是很充裕，我平时还是蓝牙鼠标用的比较多。 但是，每当我在Windows和Archlinux上切换时，我不得不重新配对我的蓝牙鼠标。原因我在翻译Archwiki上关于蓝牙鼠标相关叙述时已经解释得非常清楚了，我摘在下面： “首先，计算机保存蓝牙设备的 MAC 地址和配对密钥；然后，蓝牙设备保存计算机的 MAC 地址和配对密钥。这两步通常不会有问题，不过设备蓝牙端口的 MAC 地址在 Linux 和 Windows 上都是相同的 (这在硬件层面上就设定好了)。然而，当在 Windows 或 Linux 中重新配对设备时，它会生成一个新密钥，覆盖了蓝牙设备之前保存的密钥，即与 Windows 配对产生的密钥会覆盖原先与 Linux 配对的密钥，反之亦然。“ 先在Linux上连接蓝牙鼠标，再重启到Windows重新配对蓝牙蓝牙鼠标。 到微软官网下载PsExec.zip，解压后，记住你所解压的路径。 在Windows中，使用管理员权限打开cmd.exe cd到PsExec解压目录，使用如下命令将我们所需要的蓝牙密钥信息保存到C盘根目录下。 1psexec.exe -s -i regedit /e C:\\BTKeys.reg HKEY_LOCAL_MACHINE\\SYSTEM\\ControlSet001\\Services\\BTHPORT\\Parameters\\Keys 根目录的BTkeys.reg可以直接用记事本打开，内容大概是下面这个样子 为了方便后面的解说，我用各种颜色标注了起来。 在Linux下获取su权限以后，我们需要将Linux下随机分配给鼠标的蓝牙地址改成在Windows上获取的那个地址。上图中「红部分」划出来的就是Windows下获取的地址。 123456[zhullyb@Archlinux ~]$ suPassword: [root@Archlinux zhullyb]# cd /var/lib/bluetooth/E0\\:94\\:67\\:74\\:0D\\:5F/[root@Archlinux E0:94:67:74:0D:5F]# lsC6:2A:1B:33:2E:71 cache settings[root@Archlinux E0:94:67:74:0D:5F]# mv C6\\:2A\\:1B\\:33\\:2E\\:71/ C4\\:F6\\:B3\\:2C\\:BD\\:7E 再编辑/var/lib/bluetooth/&lt;本机蓝牙地址&gt;/&lt;鼠标蓝牙地址&gt;/info 原文件如下： 12345678910111213141516171819202122232425262728293031[General]Name=MiMouseAppearance=0x03c2AddressType=staticSupportedTechnologies=LE;Trusted=trueBlocked=falseWakeAllowed=trueServices=00001530-1212-efde-1523-785feabcd123;00001800-0000-1000-8000-00805f9b34fb;00001801-0000-1000-8000-00805f9b34fb;0000180a-0000-1000-8000-00805f9b34fb;0000180f-0000-1000-8000-00805f9b34fb;00001812-0000-1000-8000-00805f9b34fb;[IdentityResolvingKey]Key=067764BF59A7531E978AFDC6BB5EC8E1[LongTermKey]Key=E3C49B4F3256018192942EB0CDDEE6A3Authenticated=0EncSize=16EDiv=28209Rand=15970850852728832717[DeviceID]Source=2Vendor=10007Product=64Version=40[ConnectionParameters]MinInterval=6MaxInterval=9Latency=100Timeout=600 「黄色部分」LTK 对应 LongTermKey 下的 Key，把小写转换成大写并删去逗号即可。 「绿色部分」ERand 对应 Rand。这里比较特殊的是，我们必须先将 Windows 中的值倒转过来再转换为 10 进制。即c2,83,7f,8f,7c,76,b4,02-&gt;02,b4,76,7c,8f,7f,83,c2-&gt;194910961239294914 「蓝色部分」EDIV 对应 EDiv。把 16 进制转换成 10 进制即可，这里就不用倒转了。 具体的转换方法我不再赘述，我把我的转换过程放在下面，我相信各位读者能够看懂。 123456[zhullyb@Archlinux ~]$ echo &#x27;e3,c0,b2,8e,64,2b,12,16,d8,c2,d7,d4,59,55,92,cd&#x27; | tr a-z A-Z | sed &#x27;s/[[:punct:]]//g&#x27;E3C0B28E642B1216D8C2D7D4595592CD[zhullyb@Archlinux ~]$ echo $((16#02B4767C8F7F83C2)) #这里我是手动倒叙的194910961239294914[zhullyb@Archlinux ~]$ echo $((16#000055a3))21923 做完这些操作以后，sudo systemctl start bluetooth即可","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Windows","slug":"Windows","permalink":"https://zhul.in/tags/Windows/"}]},{"title":"选择最新的Archlinux镜像源","slug":"choose-the-last-archlinux-mirror-site-in-china","date":"2021-05-28T16:00:00.000Z","updated":"2022-08-22T15:42:13.000Z","comments":true,"path":"2021/05/29/choose-the-last-archlinux-mirror-site-in-china/","link":"","permalink":"https://zhul.in/2021/05/29/choose-the-last-archlinux-mirror-site-in-china/","excerpt":"","text":"找到最新的Archlinux镜像源我是testing+kde-unstable用户，平均每天更新4次，对于我而言，选择最新的Archlinux镜像是非常重要的。 Archlinux的主源并不开放给个人用户使用，仅开放给一级镜像站进行同步，因此我们需要手动寻找国内较新的镜像站。（理论上来说一级镜像站应该比二级镜像站更新，但是有些一级镜像站的同步频率并不高，同步延迟可能会比某些二级镜像站还要高） 一个archlinux的镜像目录大概是长下面这个样子 123456789101112131415161718archlinux/├── community├── community-staging├── community-testing├── core├── extra├── gnome-unstable├── images├── iso├── kde-unstable├── lastsync├── lastupdate├── multilib├── multilib-staging├── multilib-testing├── pool├── staging└── testing 其中的lastsync和lastupdate用unix时间戳记录着上一次同步时间和镜像的上一次变更时间。 因此，我们只需要对比各个镜像站的lastsync谁比较新就行了，我写了如下的辣鸡脚本 12345678910111213141516171819202122232425262728293031323334353637383940414243#!/bin/bashtuna=$(curl -s https://mirrors.tuna.tsinghua.edu.cn/archlinux/lastsync)bfsu=$(curl -s https://mirrors.bfsu.edu.cn/archlinux/lastsync)sjtug=$(curl -s https://mirror.sjtu.edu.cn/archlinux/lastsync)aliyun=$(curl -s https://mirrors.aliyun.com/archlinux/lastsync)ustc=$(curl -s https://mirrors.ustc.edu.cn/archlinux/lastsync)zju=$(curl -s https://mirrors.zju.edu.cn/archlinux/lastsync)cqu=$(curl -s https://mirrors.cqu.edu.cn/archlinux/lastsync)lzu=$(curl -s https://mirror.lzu.edu.cn/archlinux/lastsync)neusoft=$(curl -s https://mirrors.neusoft.edu.cn/archlinux/lastsync)dgut=$(curl -s https://mirrors.dgut.edu.cn/archlinux/lastsync)netease=$(curl -s https://mirrors.163.com/archlinux/lastsync)tencent=$(curl -s https://mirrors.tencent.com/archlinux/lastsync)hit=$(curl -s https://mirrors.hit.edu.cn/archlinux/lastsync)huaweicloud=$(curl -s https://mirrors.huaweicloud.com/archlinux/lastsync)sohu=$(curl -s https://mirrors.sohu.com/archlinux/lastsync)opentuna=$(curl -s https://opentuna.cn/archlinux/lastsync)pku=$(curl -s https://mirrors.pku.edu.cn/archlinux/lastsync)nju=$(curl -s https://mirrors.nju.edu.cn/archlinux/lastsync)njupt=$(curl -s https://mirrors.nju.edu.cn/archlinux/lastsync)echo &quot;&quot;&quot;$tuna #tuna$bfsu #bfsu$sjtug #sjtug$aliyun #aliyun$ustc #ustc$zju #zju$cqu #cqu$lzu #lzu$neusoft #neusoft$dgut #dgut$netease #netease$tencent #tencent$hit #hit$huaweicloud #huaweicloud$sohu #sohu$opentuna #opentuna$pku #pku$nju #nju$njupt #njupt&quot;&quot;&quot; | sort -r 其运行结果如下 123456789101112131415161718191622248120 #neusoft1622247879 #dgut1622247698 #hit1622246042 #zju1622246042 #tuna1622246042 #bfsu1622242426 #sjtug1622242426 #njupt1622242426 #nju1622240702 #ustc1622240522 #cqu1622238783 #netease1622235120 #lzu1622232241 #huaweicloud1622230871 #tencent1622217845 #aliyun1622217001 #pku1622203750 #sohu1622166379 #opentuna 通过不同时刻的多次测试可以看出，国内同步频率最高的是东软（neusoft）的镜像。顺手一查，没错，是个一级镜像站。通过unix时间戳得知，东软的archlinux镜像几乎是每分钟同步一次，恐怖如斯。。。 获得更好的下载速度我们已经得知东软是国内同步频率最高的Archlinux镜像站了，但是我用东软镜像站的下载速度并不太好看。此时，我们就要搬出依云大佬的神器——pacsync 在root用户下使用如下命令装载pacysnc后 12345678910echo &#x27;#!/bin/bash -eunshare -m bash &lt;&lt;&#x27;EOF&#x27;mount --make-rprivate /for f in /etc/pacman.d/*.sync; do filename=&quot;$&#123;f%.*&#125;&quot; mount --bind &quot;$f&quot; &quot;$filename&quot;donepacman -SyEOF&#x27; &gt; /usr/bin/pacsync 创建/etc/pacman.d/mirrorlist.sync指定我们用来同步pacman数据库（比如东软） /etc/pacman.d/mirrorlist中存放其他国内镜像源地址（按照同步速度从上到下） 以后的同步命令为 sudo pacsync &amp;&amp; yay -Su 觉得命令过长的话设置alias可以是个不错的选择。","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"}]},{"title":"请给 tuna/ustc 镜像站减压","slug":"relieve-the-pressure-of-tuna-mirror-site-please","date":"2021-05-27T13:25:48.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/05/27/relieve-the-pressure-of-tuna-mirror-site-please/","link":"","permalink":"https://zhul.in/2021/05/27/relieve-the-pressure-of-tuna-mirror-site-please/","excerpt":"","text":"不知道从什么时候开始，我总觉得tuna的镜像站提供的下载速度越来越慢，直到我前几天翻开tuna镜像站的「服务器状态」，我被眼前的景象给震惊到了。 我在这里大致观察了一下这张图：服务器流量主要是由四个部分组成，「http-ipv4」、「https-ipv4」、「http-ipv6」和「https-ipv6」。光是从过去24小时的平均出站流量来计算的话，大约就是2.4Gb/s，如果观察图中的流量高峰期的话，大概是4Gb/s的一个速率。这个流量大小是什么概念呢？根据我个人浅薄的建站经验来讲，这个流量可以让大部分供应商把你的网站判断为正在遭受攻击，你将被强制进入黑洞模式。然而对于tuna的镜像站而言，这个流量速率确是日常。换句话说，tuna的服务器都相当于每时每刻都在被来自全国的开发者“攻击”。 来自 2022 年的竹林: 我是真没想到去年 tuna 的网络负载只有这点的。2022 年的负载图在下面附上，已经翻了一倍不止了 因此，我们也就不难理解为什么tuna近些年来经常出现断流等一系列问题了。 客观上 TUNA 和 UTSC 是国内知名度和镜像项目数量以及同步速度都靠前的镜像站，但也因为如此，这两个镜像站每日的带宽负载是很大的；能跑满我的本地带宽速度是较理想的情况，但是那么大的负载，时间跨度长了体验到的波动差异也就多了起来。至少在我这里，长时间使用两个镜像站的速度波动挺大的。TUNA 也曾微言过带宽日益不堪重负，所以从道德情感和技术理论等角度上，尽管他们是理想的镜像站点，我个人不会优先使用这两个镜像站，也不会优先推荐别人使用。 ——WPlanck 国内的开源镜像站我大多都已经收集到这一篇博客中了，以下几个镜像站是我重点推荐的。 bfsutuna的姊妹站，通俗来讲就是tuna派人维护，北京外国语大学出钱。人少、稳定、涵盖项目较广。 sjtug上海交大的站点，也有不少项目，据说sjtug上的manjaro镜像是国内几个开源镜像站中同步最勤快的，用的人也不多。 opentunatuna那边用国内aws服务器搭的站点，速度超快，不过比较可惜的是现在同步的项目不多，同步频率低，大概是一天一次的样子。 pku是不是没想到北大也有镜像站？没记错的话是今年三四月左右刚开的，和opentuna情况差不多，用的人少、速度快、同步的项目不多。 hit哈尔滨工业大学的镜像站，速度我跑下来感觉一般，不是特别亮眼，不过同步频率高。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"镜像站","slug":"镜像站","permalink":"https://zhul.in/tags/%E9%95%9C%E5%83%8F%E7%AB%99/"}]},{"title":"我为什么选择Archlinux？","slug":"why-i-use-archlinux","date":"2021-05-22T16:00:00.000Z","updated":"2022-08-22T15:57:34.000Z","comments":true,"path":"2021/05/23/why-i-use-archlinux/","link":"","permalink":"https://zhul.in/2021/05/23/why-i-use-archlinux/","excerpt":"","text":"对于我而言，我用Archlinux主要的原因就是实用主义。我可以很负责的说，Arch真的是在我所有用过的发行版当中最符合实用主义的一个了。 很多大佬一提到Archlinux就扯些什么kiss原则，在我看来则不然。 整洁规范的系统规范代码为的不是为了什么Art of Code，而是可读性的提升；遵循kiss原则亦是如此。 配置文件的路径写好了，符合规范，我们就能一下子找到，我们是为了实用主义而遵守kiss原则。 同样的，我同样可以为了实用主义而破坏kiss原则。比如在我的archiso-zhullyb中，我添加了一个pacman的hook将我的定制内核重命名为linux以确保其能够正确被ventoy所识别，这也是为了实用主义。 那么，什么时候我会破坏kiss原则呢？当我认为破坏kiss原则所带来的利大于弊时，我就会考虑以一个并不规范但却有效的方法来处理问题。 但很有趣的是，由于Archlinux的官方总是将kiss奉为圣旨，这就给我们提供了一个非常nice的环境了——在一个非常规范的系统内，破坏kiss原则所带来的代价并不会很大，这就好比在一个布线整齐的机房内临时私拉两三根线并不会给维护带来多大的困难。 Archlinux对上游软件包的发行策略不同于apt在源内提供了统一软件的多个版本供用户选择，pacman剑走偏锋，默认用户系统内所有软件都是最新的。 由此带来了一个好处——不会出现由于版本过高/过低导致的依赖问题。只要我保证系统内的所有软件都是最新的，就不会出问题，非常的简单粗暴。 此外，不考虑依赖版本这一特点对于打包人来说也是一种解脱。 pacman简单的打包方式不同于deb以及rpm，pacman的软件包应该是所有发行版中最省事儿的。 打包软件时，我们只需要写（改）一份PKGBUILD，就可以仅仅通过在PKGBUILD所在的路径执行makepkg命令来完成一次打包，这相比起deb而言可谓是天差地别。如此简单有效的打包方式注定其将被实用主义者所青睐。 超低的社区贡献成本很多发行版社区开发与贡献其实并不容易参与进去，我拿Ubuntu来做个比较。 附: Archwiki是先斩后奏类型的文档，在你按下保存按钮的那一刻，wiki将立即被更新，所有访客都将看到你改动后的内容。wiki文档拥有变更记录，不担心有人恶意搞破坏，向wiki管理员提出举报后破坏者的账号会被及时封禁，wiki可以非常简单地回滚到之前的状态。 AUR同样也是，你可以随意上传自己的PKGBUILD，可以被别的用户及时看到。如果上传恶意脚本，在别的用户举报后你将迅速被封号。 Wiki方面Ubuntu其实是我第一个上手的Linux发行版，在为期半年的Ubuntu体验中，我对于社区做出的贡献为0。这倒也不是我不热衷于参与社区贡献，而是对Ubuntu社区的贡献成本太高了。去贡献文档翻译，需要等待漫长的审核过程，在第一篇汉化文章正式展现在别的用户眼前后，我一定会被激发出继续翻译第二篇的热情。然而，面对太长的审核周期，再高涨的热情恐怕也会被浇灭。 Arch的社区则不一样，他并不像别的社区那样严谨——只要注册个wiki的账号便可以开始贡献文档。你可以随意地编辑一篇文章或者是新增一篇自己的文章，编辑后的文章将能够立即被别的用户所阅读到，没有任何审核过程，有了这份热情，我便继续翻译别的文档，我想，这应该就是archwiki为何涵盖面如此之广的原因。 AUR方面同样也是拿Ubuntu对比。 在Archlinux下，我只需要简单的写一个PKGBUILD即可轻松构建一个软件包，同时，我也可以将这份有我攥写的PKGBUILD上传到AUR供别的用户使用。AUR作为一个公开的储存库，任何Arch用户都可以通过AUR Helper轻松得从AUR中获取我写的PKGBUILD并在本地打成自己的包。与此同时，我也可以创建一个私人源，直接发行我构建的二进制包。 Ubutnu则不然，他的打包方式则要麻烦得多，同时也没有类似PKGBUILD一样的东西便于用户分享自己的打包脚本。唯一能够分享自己的劳动成果的方式无非就是直接分享自己打出来的deb包，最多也不过是建立自己的ppa，这对于用户来说是极为麻烦的。用户需要处心积虑地寻找自己所需要的deb包或是含有目标包的ppa地址并手动添加，不像Archlinux有AUR这种东西能够让我们知道在哪里能够找到我们所需要的包。","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"}]},{"title":"使用vercel创建一个随机图片api","slug":"create-a-random-picture-api-with-vercel","date":"2021-05-20T16:00:00.000Z","updated":"2024-05-15T04:42:05.000Z","comments":true,"path":"2021/05/21/create-a-random-picture-api-with-vercel/","link":"","permalink":"https://zhul.in/2021/05/21/create-a-random-picture-api-with-vercel/","excerpt":"","text":"如果你的网络环境不算太差的话，你在访问我博客的时候应该可以看到顶部有一张背景图。假如你访问我的博客时留心观察，你或许会发现每次你访问我博客时的背景都是不一样的。如果你没玩够，或许你可以尝试点击这里，我总共搜集了20张壁纸供诸位赏玩。 是的，这是使用php实现的随机图片api，托管于vercel，你可以在aya的博客上找到我使用的代码。具体配置方式我不再赘述。 然而，我们还需要解决一个问题: php在哪里运行？ 如果你拥有自己的服务器，在国内访问速度毫不逊色，那就好办了，直接扔自己服务器上即可。然而，我并没有。我需要找到一个在国内访问速度给力的地方来部署我的api，以确保访客在打开我的博客时可以在第一时间获取到图片的真实链接并开始加载。 起初，我将其部署在我的好朋友(你可以猜猜他是谁)的国内vps上，访问速度自然不用说。然而，他的服务器不支持https，这就导致使用chrome访问的时候chrome不会自动访问我的api，博客顶部一片惨蓝。。。 随后，我使用的是000webhost提供的虚拟主机，国内访问起来也还不错，大概正常运行了半个月左右的时间，然后莫名开始502了。我懂，作为不交钱的白嫖用户应该自觉滚蛋了，这点觉悟咱还是有。 随后，我找到了目前的方案——vercel vercel是被我用来部署静态网页的，但我没想到他也能支持php。参考了vercel-php项目后，我大致了解了整个仓库结构。 1234project├── api│ └── index.php└── vercel.json php和附带的资源文件(如果有的话)一定要放到api文件夹下才能够正常被vercel识别。 以下附vercel.json 1234567&#123; &quot;functions&quot;: &#123; &quot;api/index.php&quot;: &#123; &quot;runtime&quot;: &quot;vercel-php@0.4.0&quot; &#125; &#125;&#125;","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"vercel","slug":"vercel","permalink":"https://zhul.in/tags/vercel/"}]},{"title":"禁止deepin-wine-tim使用simsun字体渲染","slug":"hide-simsun-from-deepin-wine-tim","date":"2021-04-26T16:00:00.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/04/27/hide-simsun-from-deepin-wine-tim/","link":"","permalink":"https://zhul.in/2021/04/27/hide-simsun-from-deepin-wine-tim/","excerpt":"","text":"本文中，我通过bwrap命令对运行Tim的wine程序屏蔽了simsun字体以获得了一个更为舒适的字体渲染效果。我所使用的Tim为deepin-wine-tim，至于deepin-wine-qq通过相同的方式应该也能达到相同的效果，spark商店的Tim我自己测试下来似乎是没法达到这样的效果，而使用其他方法安装simsun字体的网友们则需要注意灵活变通，不要照抄我给出的字体路径。 在Archlinux下，我们通常会使用deepin-wine5来运行QQ/Tim. 但是当我们在系统中倒入simsun字体时，无论使用什么奇迹淫巧似乎都无法阻止deepin-wine5找到simsun并优先使用它。于是，字体渲染就会变成如图这样奇奇怪怪的画风: 但是我并不喜欢这样的渲染效果，使用simsun渲染出来的字体总感觉有一种上世纪的风格，况且，在我的1080p小屏下显示并不清晰。 于是，在尝试了更改注册表、在wine容器的系统路径下直接塞入字体文件等等方式无果后，我选择了逃避——直接让wine程序读取不到simsun。 我的simsun是通过ttf-ms-win10-zh_cn这个包安装上去的，被安装在/usr/share/fonts/TTF/路径下。 使用pacman -Qo /usr/share/fonts/TTF/命令查找这个路径下所安装的字体包，我这里的输出如下: 1234567[zhullyb@Archlinux ~]$ pacman -Qo /usr/share/fonts/TTF//usr/share/fonts/TTF/ is owned by ttf-cascadia-code 2102.25-1/usr/share/fonts/TTF/ is owned by ttf-fira-code 5.2-1/usr/share/fonts/TTF/ is owned by ttf-hack 3.003-3/usr/share/fonts/TTF/ is owned by ttf-monaco 6.1-6/usr/share/fonts/TTF/ is owned by ttf-ms-win10-zh_cn 2019ltsc-1/usr/share/fonts/TTF/ is owned by ttf-opensans 1.101-2 可以看到，并没有什么对wine程序运行特别重要的字体包，于是我计划通过bwrap命令对运行Tim的wine程序直接屏蔽这个路径。 首先安装提供bwrap命令的bubblewrap程序: sudo pacman -S bubblewrap --needed 通过查找deepin-wine-tim的desktop文件发现Tim的启动命令是/opt/apps/com.qq.office.deepin/files/run.sh 在终端中输入命令进行测试bwrap --dev-bind / / --tmpfs /usr/share/fonts/TTF/ /opt/apps/com.qq.office.deepin/files/run.sh 出现如下界面，看来方法是可行的。 于是，我们进一步更改deepin-wine-tim的desktop文件，以方便我们不需要每次都在Terminal中执行这么一大长串命令。需要更改的地方如下图红色方框圈出部分 我这里附一下图中的命令方便诸位复制粘贴。 123456789101112131415[zhullyb@Archlinux ~]$ cat /usr/share/applications/com.qq.office.deepin.desktop #!/usr/bin/env xdg-open[Desktop Entry]Encoding=UTF-8Type=ApplicationX-Created-By=Deepin WINE TeamCategories=chat;Network;Icon=com.qq.office.deepinExec=bwrap --dev-bind / / --tmpfs /usr/share/fonts/TTF/ /opt/apps/com.qq.office.deepin/files/run.shName=TIMName[zh_CN]=TIMComment=Tencent TIM Client on Deepin WineStartupWMClass=tim.exeMimeType=","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Bwrap","slug":"Bwrap","permalink":"https://zhul.in/tags/Bwrap/"}]},{"title":"在系统使用暗色主题时禁用Firefox的夜间模式","slug":"disable-firefox-nightmode-when-your-system-is-using-that","date":"2021-04-22T16:00:00.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2021/04/23/disable-firefox-nightmode-when-your-system-is-using-that/","link":"","permalink":"https://zhul.in/2021/04/23/disable-firefox-nightmode-when-your-system-is-using-that/","excerpt":"","text":"在我使用Archlinux的时候经常会使用一些暗色主题，但是我并不希望我浏览网页时一些自作聪明的网页自动切换成夜间模式。 这个设置我找了好久，每次在谷歌上检索都会跳出来一堆教我改Firefox主题的、用插件开夜间模式的，却都不是我的目的。 我们所需要做的是在浏览器地址栏输入about:config进入高级设置 搜索并添加一个值 1ui.systemUsesDarkTheme 将这个选项的数值设置为0即可。 2021.12.13更新: Firefox 更新 95.0 以后，如果遇到原方案失效的问题，可以参考 CSL的博客。","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"记一次在Gitlab部署Jekyll博客时遇到的jekyll-github-metadata报错问题","slug":"fuck-jekyll-github-metadata-on-gitlab","date":"2021-04-15T16:00:00.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/04/16/fuck-jekyll-github-metadata-on-gitlab/","link":"","permalink":"https://zhul.in/2021/04/16/fuck-jekyll-github-metadata-on-gitlab/","excerpt":"","text":"我的博客是挂在GitlabPages上的，在为博客更换主题的时候遇到了一点点小麻烦。 报错如图： 当然，我这边也会附上详细的报错日志，以便后人能够通过关键词搜索到。 12345678910111213Configuration file: /builds/zhullyb/test/_config.yml Source: /builds/zhullyb/test Destination: public Incremental build: disabled. Enable with --incremental Generating... Jekyll Feed: Generating feed for posts GitHub Metadata: No GitHub API authentication could be found. Some fields may be missing or have incorrect data. GitHub Metadata: Error processing value &#x27;url&#x27;: ERROR: YOUR SITE COULD NOT BE BUILT: ------------------------------------ No repo name found. Specify using PAGES_REPO_NWO environment variables, &#x27;repository&#x27; in your configuration, or set up an &#x27;origin&#x27; git remote pointing to your github.com repository.Cleaning up file based variables 00:01ERROR: Job failed: exit code 1 经过了一番瞎折腾以后，我依然没有解决问题，而每次push都要等待gitlab的ci构建两三分钟，实在磨不动的我去看了jekyll-github-metadata的README，结合上文的报错，我一下子就看懂了。 jekyll-github-metadata可以通过github中的信息自动为jekyll提供site.github、site.title、site.description、site.url和site.baseurl。而由于我们在用的是Gitlab，所以jekyll-github-metadata就无法获取到这些信息，需要我们手动指定。报错中缺少的就是url 于是打开_config.yml，把url给补上，顺便把别的变量一同加上，如图：","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"我在Archlinux上的常用软件","slug":"the-software-i-use-on-archlinux","date":"2021-04-15T16:00:00.000Z","updated":"2022-08-22T15:57:34.000Z","comments":true,"path":"2021/04/16/the-software-i-use-on-archlinux/","link":"","permalink":"https://zhul.in/2021/04/16/the-software-i-use-on-archlinux/","excerpt":"","text":"最近基本固定了在Archlinux上的常用软件，也供各位参考一下。 我是KDE用户，所以KDE家的软件会用得比较多。 浏览器：Firefox，Chromium备用（主要是使用chromium的网页翻译功能，还有就是打开一些对Firefox不太友好的网站） 下载器：curl，wget，motrix 根据不同使用场景更换下载器 终端：konsole 输入法：fcitx5-chinese-addons 即时通讯：telegram，deepin-wine-tim，deepin-wine-wechat，electron-qq，wechat-uos，linuxqq 播放器：vlc 编辑器：nano，kate，visual-studio-code-bin，typora，wps 图形类：pinta，drawio-desktop-bin，imagemagick 文件管理器：dolphin 文件传输：sftp（命令行里的），filezilla 系统、网络工具：latte-dock-git，v2raya，htop，gtop","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"}]},{"title":"使用Chrome的同步api为chromium开启同步功能","slug":"login-chromium-with-the-api-of-chrome","date":"2021-04-14T16:00:00.000Z","updated":"2024-08-12T04:18:19.000Z","comments":true,"path":"2021/04/15/login-chromium-with-the-api-of-chrome/","link":"","permalink":"https://zhul.in/2021/04/15/login-chromium-with-the-api-of-chrome/","excerpt":"","text":"今年两三月的时候，Google限制了chromium的同步api次数，导致各个发行版内置的chromium将不再能继续使用Google的数据同步功能。 今天在翻 archlinuxcn 的群组的时候翻到了一段脚本: https://gist.github.com/foutrelis/14e339596b89813aa9c37fd1b4e5d9d5 大意就是说，由于Archlinux特殊的chromium启动方式导致我们可以在设置oauth2-client-id和oauth2-client-secret的情况下通过chrome的同步api继续使用Google的同步服务，说得太多了也没必要，毕竟原文就在那里，看不看取决于你，我这里直接给命令吧。 12echo &quot;--oauth2-client-id=77185425430.apps.googleusercontent.com--oauth2-client-secret=OTJgUOQcT7lO7GsGZq2G4IlT&quot; &gt;&gt; ~/.config/chromium-flags.conf 再次打开chromium,你就会发现你心心念念的同步功能回来了。 然而，并不是所有的发行版都像 Archlinux 这样考虑到 oauth，我们也不可能像 Archlinux 官方那样有这个闲情雅致为没一个 Chromium 去添加这个 patch 以后重新编译一遍，大部分人都是直接用发行版源里的。针对这种情况，我们可以直接手写一个脚本 1234#!/usr/bin/bashexport GOOGLE_DEFAULT_CLIENT_ID=77185425430.apps.googleusercontent.comexport GOOGLE_DEFAULT_CLIENT_SECRET=OTJgUOQcT7lO7GsGZq2G4IlTexec /usr/bin/chromium-browser &quot;$@&quot; # 我用的 Fedora 的启动命令是 chromium-browser，别的发行版用户还请自行调整 当我满心欢喜地把脚本扔进 $HOME/.local/bin 后，我却突然发现 Fedora 官方源中把 chromium 的启动命令写死在了 /usr/bin/chromium-browser，如果直接去改 /usr/bin/chromium-browser 的话，每次更新都会被覆盖。 正确的做法应该是把 desktop 文件复制一份到桌面，再去改内容。 123mkdir -p $HOME/.local/share/applications/cp /usr/share/applications/chromium-browser.desktop $HOME/.local/share/applications/sed -i &quot;s|/usr/bin/chromium-browser|GOOGLE_DEFAULT_CLIENT_ID=77185425430.apps.googleusercontent.com GOOGLE_DEFAULT_CLIENT_SECRET=OTJgUOQcT7lO7GsGZq2G4IlT /usr/bin/chromium-browser|g&quot; $HOME/.local/share/applications/chromium-browser.desktop","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"Appimage的文件储存在哪里","slug":"where-will-appimage-put-its-file","date":"2021-04-12T16:00:00.000Z","updated":"2022-08-22T15:57:34.000Z","comments":true,"path":"2021/04/13/where-will-appimage-put-its-file/","link":"","permalink":"https://zhul.in/2021/04/13/where-will-appimage-put-its-file/","excerpt":"","text":"我不饿： 有人知道怎么删除appimage的用户数据吗？ liolok | 李皓奇: 还是可以在用户的家目录下面乱写的吧 Lipis Apple: 不太讲武德：~/.local/share/(app) 算讲武德：~/.config/(app) 不讲武德：~/.(app)","categories":[],"tags":[{"name":"大佬对话笔记","slug":"大佬对话笔记","permalink":"https://zhul.in/tags/%E5%A4%A7%E4%BD%AC%E5%AF%B9%E8%AF%9D%E7%AC%94%E8%AE%B0/"}]},{"title":"使用Motrix接管Firefox的下载","slug":"use-motrix-install-of-firefox-to-download","date":"2021-04-10T16:00:00.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2021/04/11/use-motrix-install-of-firefox-to-download/","link":"","permalink":"https://zhul.in/2021/04/11/use-motrix-install-of-firefox-to-download/","excerpt":"","text":"本文是一篇个人笔记，不具有太强的技术性，仅仅是为后来者指个方向。 熟悉我的人都知道，我是一个Firefox的忠实用户，原因有二： ​ 一/ Firefox国际版同步功能国内可用 ​ 二/ moz://a（Firefox用户应该能在地址栏直接访问这个链接） 但是Motrix没有推出适用于Firefox的接管浏览器下载功能的插件，于是只能用aria2的插件。这个插件内置了AriaNG,对于aria2用户来说会比较实用，但是对于Motrix用户而言其实功能有些多余且不兼容，比如什么自动启动aria2什么的是无法实现的。 主要的配置过程我就图解了，退出前记得保存配置。","categories":[],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"yay进阶","slug":"yay-more","date":"2021-04-03T16:00:00.000Z","updated":"2022-08-24T10:07:11.000Z","comments":true,"path":"2021/04/04/yay-more/","link":"","permalink":"https://zhul.in/2021/04/04/yay-more/","excerpt":"","text":"yay是一个AUR Helper，他可以执行pacman的几乎所有操作，并在此基础上添加了很多额外用法。 我没有在网络上查找到关于yay的、除了pacman基础用法和安装AUR包以外的中文教程，英文的也几乎没有看到，这也是我写这篇文章的原因所在。 本文通篇详讲yay的每一个设置/选项（大概就是archwiki那种干涩的行文思路），最后会给出我自己的一些常用命令，但不会做解释。 写作时参考了yay的英文使用手册，如果你的arch安装了yay，那么即可通过man yay命令随时查阅它。 Tips1: 本文中出现的foo一般是指包名，标注*的表示该选项默认启用。 Tips2: 使用电脑端的访客可以在侧栏以获取目录。 基本用法yay的基本用法是yay &lt;operation&gt; [options] [targets]、yay foo和yay，yay &lt;operation&gt; [options] [targets]的用法可以讨论的点比较多，我会在后文中一一道来。 yay当我们仅执行yay，后面不跟任何参数时，yay会执行操作yay -Syu，他会先调用pacman更新源的数据库、更新所有从源内安装的软件包，并检查你的AUR包有没有更新。 yay foo通过yay后面直接跟包名的命令会让yay直接在源和AUR内搜索带有foo关键词的包（包名和简介中只要出现foo都会被一网打尽），以下是我执行yay dingtalk的输出 1234567891011125 aur/com.dingtalk.deepin 5.0.15deepin7-1 (+0 0.00) Deepin Wine dingtalk4 aur/deepin.com.dingtalk.com 5.1.28.12-2 (+1 0.12) DingTalk Client on Deepin Wine3 aur/dingtalk 2.1.3-1 (+3 0.00) 钉钉桌面版，基于electron和钉钉网页版开发，支持Windows、Linux和macOS2 aur/dingtalk-linux 3.5.5-1 (+6 0.12) May be the official Linux experimental version1 aur/dingtalk-electron 2.1.9-1 (+9 0.15) 钉钉Linux版本==&gt; Packages to install (eg: 1 2 3, 1-3 or ^4)== 输入每一项对应的序号即可进入相应的安装过程。 yay &lt;operation&gt; [options] [targets]在这里，&lt;operation&gt;每次只能有一个，[options]和[targets]可以有多个，且多个[options]可以合起来写在一起。比如yay -P -s -f可以直接写成yay -Psf，顺序也可以颠倒，-Psf和-sPf没区别。 -Y (--yay)-Y行为其实是yay的默认行为，当你没有加其他的行为参数时，yay就会执行-Y参数，可以跟--gendb和-c。 --gendb生成AUR数据库。仅当从另一个AUR Helper迁移到yay时，才应使用此选项。（根据我的个人理解，是根据你Arch内安装的源内找不到的包的包名去AUR里寻找对应的PKGBUILD，并且把能找到的PKGBUILD给clone到~/.cache/yay/目录下） 千玄子大佬说：“简单说来就是把在 AUR 的 PKGBUILD 下下来然后比对是否要更新。” -c（--clean）清除不再需要的、没有被依赖的包。（相当于apt中的autoremove） -P(--show)执行特定的Print操作。可以跟的[option]有-c、-f、-d、-g、-n、-s、-u、-w、-q -c(--complete)Print所有源内和AUR软件包的列表。这是给命令行操作提供的，并不打算由用户直接使用。（意思是启用了这个选项以后你的终端会出现一大串长常的列表来告诉你你的Arch到底可以从哪里安装哪些包，并不是直接给你用的，是作为数据留给别的命令来玩耍的） -f(--fish)在输出结果到终端时，会专门为fish用户做微调。（但是根据SamLukeYes大佬说他用fish体验下来并没有感知到加不加有什么区别，应该是属于感知不强的选项） -d(--defaultconfig)Print默认的yay配置。 -g(--currentconfig)Print当前的yay配置。 -n(--numberupgrades)数一数你现在还有多少AUR包待更新。yay作者不推荐你使用呢，他推荐你用yay -Qu或者wc -l来代替它。 -s(--stats)会展示一大堆信息，如下 1234567891011121314151617181920212223[zhullyb@Archlinux ~]$ yay -Ps==&gt; Yay version v10.2.0 #yay版本=============================================&gt; Total installed packages: 1240 #总共安装了多少包==&gt; Total foreign installed packages: 24 #多少包不是从源里安装的==&gt; Explicitly installed packages: 271 #有多少包是你自己主动安装的(而不是作为依赖安装的)==&gt; Total Size occupied by packages: 14.3 GiB #安装的所有包合在一起一共占了你多少空间=============================================&gt; Ten biggest packages: #十个体积最大的包wps-office-cn: 990.9 MiBttf-sarasa-gothic: 855.5 MiBlinux-firmware: 652.3 MiBbaidunetdisk-bin: 494.7 MiBcom.antutu.benchmark: 412.0 MiBwine: 402.2 MiBlinux-xanmod-cacule-uksm-cjktty: 324.4 MiBmicrosoft-edge-dev-bin: 316.4 MiBwine-mono: 316.2 MiBdeepin-wine5-i386: 259.5 MiB===========================================:: Querying AUR... -&gt; Missing AUR Packages: zhullyb-archlinux-git #AUR里找不到的包 -&gt; Flagged Out Of Date AUR Packages: xml2 #AUR中被人标注过期的包 -u(--upgrades)展示你所有待更新的包。 -w(--news)展示来自archlinux.org的新闻。需要注意的是，这里的新闻是具有时效性的，只有在你的Arch最后一次更新以后发出来的新闻才会被显示出来。如果你不想要yay判断新闻时效性，你可以通过yay -Pww（即两个w）来获取所有能获得的新闻。 -q(--quiet)在输出新闻的时候，仅输出新闻的标题。该功能需要与-w连用，即yay -Pwq。 -G(--getpkgbuild)后跟包名。需要注意的是，如果指定的包不存在于官方源，则无法输出，后跟-f、-p参数。 如果希望仅获取来自AUR（即排除第三方源的干扰）的PKGBUILD，后需跟-a参数。 -f(--force)强制下载AUR中的PKGBUILD，如果它在yay缓存目录已经存在了，那就覆盖它！ -p(--print)Print指定包的PKGBUILD。 pacman 拓展用法yay虽然可以使用pacman的所有&lt;operation&gt;，但是它远不仅于此。在这一段，我将向你介绍yay中包含的那些pacman不包括的pacman &lt;operation -S-S, -Si, -Sl, -Ss, -Su, -Sc, -Qu这些操作pacman都支持，而与pacman不同的是，yay的这些操作可以涵盖到官方源/第三方源和AUR中的所有包。 -Scyay将会清除AUR包构建时的缓存和没有被track的文件。没有被track的文件在这里指AUR包构建时下载的sources或者构建完成的pkg包，但是vcs sources会被保留（比如.git文件夹） 全局的[options]全局是指在所有&lt;operation&gt;下都可以加啦。 --repo假定你给出的包名只存在源里（忽视AUR的存在） -a(--aur)假定你给出的包名只存在AUR中（忽视源的存在） 配置设置原版的man手册排的比较混乱，我这里自己细分了几个类型，或许不是特别专业，但我希望能够帮助你们理解。 自定义调用命令型--editor &lt;command&gt;设置编辑时调用的编辑器。 --makepkg &lt;command&gt;设置makepkg时需要调用makepkg命令（一般情况下用不到） --pacman &lt;command&gt;设置运行pacman时需要调用pacman命令（一般情况下用不到） --tar &lt;command&gt;设置makepkg解压tar资源时调用的tar命令（一般情况下用不到） --git &lt;command&gt;设置makepkg clone git资源时调用的git命令（比如你可以安装AUR中的fgit-go，使用--git fgit参数来让fastgit代理clone的过程） --gpg &lt;command&gt;设置gpg验证资源时调用的gpg命令 --sudo &lt;command&gt;设置调用sudo获取su权限安装pkg时所调用的sudo命令。 自定义配置文件型--config &lt;file&gt;设置读取的pacman配置文件。 --makepkgconf &lt;file&gt;设置读取的makepkg配置文件。 --nomakepkgconf不读取系统中的makepkg.conf，仅使用Arch默认状态下的配置文件。 自定义路径类型--builddir &lt;dir&gt;设置build路径，默认路径为~/.cache/yay/ --absdir &lt;dir&gt; 设置abs路径，默认路径为~/.cache/yay/abs/ 参数传递型--editorflags &lt;flags&gt;后跟需要跟随传递给编辑器的参数。如果需要传递多个参数，可以使用引号。 --mflags &lt;flags&gt;后跟需要跟随传递给makepkg的参数。如果需要传递多个参数，可以使用引号。 这个用的人不多，但其实是非常好用的一个功能。在我们安装deepin-wine-tim等包的时候，很可能会遇到文件明明完整但checksum不通过的情况，这时我们可以跟一个--skipchecksums参数传递给makepkg以跳过checksum的过程。 --gpgflags &lt;flags&gt;后跟需要跟随传递给pgp的参数。如果需要传递多个参数，可以使用引号。 --sudoflags &lt;flags&gt;后跟需要跟随传递给sudo的参数。如果需要传递多个参数，可以使用引号。 菜单配置型clean菜单*--cleanmenu启用清除询问菜单。（询问你是否需要清除已存在的文件） --nocleanmenu禁用清除询问菜单。（不询问你是否需要清除已存在的文件） --answerclean 自动回答cleanmenu，后跟&lt;All|None|Installed|NotInstalled&gt;参数。 *--noanswerclean不设置自动回答。 diff菜单*--diffmenu启用对比询问菜单。（询问你是否需要对比本地文件和AUR文件） --nodiffmenu禁用对比询问菜单。（不询问你是否需要对比本地文件和AUR文件） --answerdiff自动回答cleanmenu，后跟&lt;All|None|Installed|NotInstalled&gt;参数。 *--noanswerdiff不设置自动回答。 edit菜单--editmenu启用修改询问菜单。（询问你是否需要修改PKGBUILD以及相关文件） *--noeditmenu禁用修改询问菜单。（不询问你是否需要修改PKGBUILD以及相关文件） --answeredit自动回答editmenu，后跟&lt;All|None|Installed|NotInstalled&gt;参数。 *--noansweredit不设置自动回答。 upgrade菜单*--upgrademenu启用更新询问菜单。（询问你是否需要更新AUR包） --noupgrademenu禁用更新询问菜单。（不询问你是否需要更新AUR包） --answerupgrade自动回答upgrademenu，后跟&lt;All|None|Installed|NotInstalled&gt;参数。 *--noanswerupgrade不设置自动回答。 removemake菜单*--askremovemake在编译结束后，询问是否删除make depend。 --removemake在编译结束后，删除make depend。 --noremovemake在编译结束后，不删除make depend。 provides菜单*--provides搜索AUR包时，一同寻找其在AUR上的依赖程序。 当找到多个提供该依赖的包时，将出现一个菜单，提示您选择一个。尽管这不会引起注意，但这会增加依赖项解决时间。 --noprovides搜索AUR包时，不在AUR上寻找其依赖程序。尽管yay不会再次弹出依赖菜单供你选择，yay调用pacman时依然会出现pacman的选择菜单让你选择。 pgpfetch菜单*--pgpfetch询问你是否从每个PKGBUILD的validpgpkeys字段导入未知的PGP密钥。 --nopgpfetch不自动导入陌生的PGP密钥。 useask选项*--useask调用pacman的–ask询问用户是否删除系统中与当前包冲突的软件包。 --nouseask不调用pacman的–ask询问用户是否删除系统中与当前包冲突的软件包，遇到冲突的软件包时直接报错，由用户来手动解决。 combinedupgrade菜单--combinedupgrade在系统更新期间，将源内包和AUR包的更新菜单合并到一起。 *--nocombinedupgrade在系统更新期间，先支持源内包的升级，完成后再进行AUR包的升级。 T or F 型devel--devel在系统更新期间，检查AUR的vcs包是否有更新，当前仅支持AUR的-git包。 devel查询是使用git ls-remote对比安装时和现在最新的commit_id完成的。 *--nodevel在系统更新期间， 不检查AUR的vcs包是否有更新。 timeupdate--timeupdate在系统更新期间，将已安装软件包的构建时间与每个软件包的AUR的最后修改时间进行比较。 *--notimeupdate在系统更新期间，不将已安装软件包的构建时间与每个软件包的AUR的最后修改时间进行比较。 redownload--redownload就算PKGBUILD已经存在，也要重新从AUR上获取一份新的PKGBUILD并覆盖原有PKGBUILD。 --redownloadall就算PKGBUILD已经存在，也要重新从AUR上获取所有AUR包的PKGBUILD并覆盖原有PKGBUILD。 *--noredownload当下载PKGBUILD时，，如果发现cache中的PKGBUILD版本＞＝AUR上的版本时，直接使用本地的PKGBUILD。 rebuild--rebuild即使在cache中有可用的二进制包的情况下，也始终要重新编译目标软件包。 --rebuildall即使在cache中有可用的二进制包的情况下，也始终要重新编译所有的AUR包。 --rebuildtree安装AUR包时，以递归方式重新编译并重新安装其所有AUR依赖包，即使已安装的依赖项也是如此。 该选项使您可以轻松地针对当前系统的库重新构建软件包，如果它们变得不兼容。（比如python3.8-&gt;3.9） *--norebuild构建软件包时，如果在缓存中找到该软件包并且该软件包与想要的软件包的版本相同，则跳过软件包的编译过程并使用现有的二进制程序。 sudoloop--sudoloop在后台循环调用sudo，以防止sudo授权在长时间构建期间超时。 *--nosudoloop不在后台循环调用sudo，可能会导致sudo授权在长时间构建期间超时。 batchinstall--batchinstall在构建和安装AUR包时，对每个软件包的安装进行排序，而并非在构建之后立刻安装每个软件包时。 需要注意的是，一旦构建了所有软件包，或者需要构建队列中的软件包作为构建另一个软件包的依赖项，应当在安装队列中安装所有软件包。 *--nobatchinstall在构建AUR包成功后立即安装。 clearafter--cleanafter在构建AUR包完成以后清除cache文件。 *--nocleanafter在构建AUR包完成以后不清除cache文件。 其他型--save把你这一次执行yay后面跟的配置参数永久保存下来。 --aururl更改aur源地址（默认为 https://aur.archlinux.org ），适用于中国用户，可以使用此参数将AUR的地址设置成清华的反代，具体的配置命令为 1yay --aururl &quot;https://aur.tuna.tsinghua.edu.cn&quot; --save TUNA 的反代已经取消，可以使用如下命令设置回 AUR 官方源 1yay --aururl &quot;https://aur.archlinux.org&quot; --save --sortby在搜索过程中，按特定条件对AUR结果进行排序，后跟&lt;votes|popularity|id|baseid|name|base|submitted|modified参数，默认为votes。 --searchby通过指定查询类型来搜索AUR软件包，后跟&lt;name|name-desc|maintainer|depends|checkdepends|makedepends|optdepends参数，默认为name-desc。 *--topdown优先展示源内包，其次才是AUR包 --bottomup优先展示AUR包，其次才是源内包 --requestsplitn &lt;number&gt;设置在每次向AUR的请求的最大数值（默认150）。数值越高，请求时间越短，但是单次请求的数值过大会导致error。当这个数值＞500时你应当特别注意这一点。 --completioninterval &lt;days&gt;刷新完成高速缓存的时间（以天为单位,默认为7）。 将此值设置为0将导致每次刷新缓存，而将其设置为-1将导致永远不刷新缓存。 我个人的常用命令12345678yayyay fooyay -Sa fooyay -Sccyay -Psyay -Pwwyay -Gpayay -Ga 本文同时发布于「知乎专栏」，如果你恰好有知乎帐号的话或许可以考虑帮我点个赞？","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"}]},{"title":"抛弃DisplayManager，拥抱startx","slug":"lets-fuck-dm-and-use-startx","date":"2021-03-13T16:00:00.000Z","updated":"2022-08-22T15:42:13.000Z","comments":true,"path":"2021/03/14/lets-fuck-dm-and-use-startx/","link":"","permalink":"https://zhul.in/2021/03/14/lets-fuck-dm-and-use-startx/","excerpt":"","text":"在正常情况下，我们会给Linux装上一个DisplayManager以方便我们输入账号密码来进入图形化系统，但是我不想要额外装一个DM来启动我的图形化系统（而且之前我一直用的sddm也出过一小阵子的问题） 首先卸载我的sddm 1sudo pacman -Rsnc sddm sddm-kcm 安装startx所在的软件包 1sudo pacman -S xorg-xinit 从/etc/X11/xinit/xinitrc拷贝一份.xinitrc 1cp /etc/X11/xinit/xinitrc ~/.xinitrc 注释掉最后5行 12345#twm &amp;#xclock -geometry 50x50-1+1 &amp;#xterm -geometry 80x50+494+51 &amp;#xterm -geometry 80x20+494-0 &amp;#exec xterm -geometry 80x66+0+0 -name login 然后需要在结尾处写上我们的配置。我用的桌面是Plasma，查询wiki To start Plasma with xinit/startx, append export DESKTOP_SESSION=plasma and exec startplasma-x11 to your .xinitrc file. If you want to start Xorg at login, please see Start X at login. 然后在xinitrx文件末尾处写上我们的配置 12export DESKTOP_SESSION=plasmastartplasma-x11 Ps: 在第二行中，wiki中让我们使用exec，代表当xorg桌面会话结束后自动退出当前用户，而我不想退出，所以没加 至此，我们的startx就已经配置完成了，重启后只需要在tty界面登录用户后输入startx并回车即可进入图形化界面。","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"}]},{"title":"竹林源","slug":"arch-source","date":"2021-03-11T16:00:00.000Z","updated":"2022-08-22T15:42:13.000Z","comments":true,"path":"2021/03/12/arch-source/","link":"","permalink":"https://zhul.in/2021/03/12/arch-source/","excerpt":"","text":"无力维护，现已将 arch.zhullyb.top 和 mirror.zhullyb.top 的所有请求分别转发到 Clansty 维护的 repo.lwqwq.com 和 pacman.ltd ，如果您凑巧看到本消息，建议立即访问 pacman.ltd 并按照其要求修改源配置文件。Hello，这里是竹林里有冰的私人源。 其实Archlinux已经有了一个打包了各种常用软件的第三方源叫archlinuxcn，国内拥有多个镜像站为其提供镜像服务。但是他们作为一个开源社区，显然会受到许多限制，诸如不能收录未经授权的商业软件等。目前已经有多个软件因为没有得到授权而不得不下架，详见 #1968、#2455、#2458、#2460、#2462。因此我创建了这样一个方便我自己使用的源。 主要收集了一些侵权软件、闭源软件、不清真的软件，目前主要是作为archlinuxcn源的补充。 目前源在OneDrive上，采用onemanager解析直链，速度取决于各位的网络供应商。 使用方法：在 /etc/pacman.conf 尾部添加 1234[zhullyb]SigLevel = NeverServer = https://mirror.zhullyb.topServer = https://arch.zhullyb.top 注，我这里将SigLevel指定为Never，是因为我认为我一个辣鸡的个人源没有必要验证keyring，况且由于OneDrive的直链解析会带来较高的延迟，再额外下载一个sig文件将会极大地破坏体验。 如果你坚持要验证，我这里也提供了zhullyb-keyring，请自行下载以后使用pacman -U进行安装。此外，由于pacman会通过拼接db跳转的链接来下载sig签名，会导致onedrive返回的报错信息被pacman误认为sig文件，这里可以使用由web-worker.cn站长提供的反代，使pacman尝试下载sig文件时接收到404状态码来跳过对db的验证。 1Server = https://pkg.web-worker.cn/zhullyb/ 现有软件列表 Removed.","categories":[],"tags":[{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"}]},{"title":"FireFox? IceDoge!!!","slug":"change-your-firefox-icon-into-a-bluedoge","date":"2021-02-26T16:00:00.000Z","updated":"2022-08-22T15:42:13.000Z","comments":true,"path":"2021/02/27/change-your-firefox-icon-into-a-bluedoge/","link":"","permalink":"https://zhul.in/2021/02/27/change-your-firefox-icon-into-a-bluedoge/","excerpt":"","text":"事情的起因是这样的。 Solidot Mozilla 强调 Firefox 的 logo 仍然包含小狐狸 2021-02-27 20:02 #Firefox 过去几天一个广泛流传的 meme 宣称，Firefox 著名的红色小狐狸 logo 正被逐渐简化直至消失。Mozilla 官方博客对此做出了回应，强调 Firefox 的 logo 将会始终包含小狐狸，他们没有消除狐狸的计划。作为反击这一 meme 行动的一部分，Mozilla 修改了Firefox Nightly 的 logo，将著名的网络 meme 狗币中的柴犬图像与红色小狐狸 logo 整合在一起。如果你下载安装 Nightly 版本，你会看到狗狗在看着你。 这只狗是非常可爱，大概是长下图这个样子。 但是我是一个将Firefox当成主浏览器的用户，咱不可能去用Nightly，所以我就打算把我这里这只稳定版的红色小狐狸 换成上面的那只狗。 通过直接写入用户目录下的icon可以在不覆盖浏览器原图标、不给包管理器惹麻烦的情况下实现我们的目标，所以，代码如下 12345678910111213141516171819#/usr/bin/sh# This script will change icon of you Firefox Browser into a bluedoge# Depend on imagemagickcd ~curl https://www.mozilla.org/media/img/logos/firefox/logo-nightdoge-lg-high-res.14f40a7985fe.png &gt; logo-nightdoge-lg-high-res.14f40a7985fe.pngfor _resolution in 16 22 24 32 48 64 128 192 256 384do mkdir -p ~/.local/share/icons/hicolor/$&#123;_resolution&#125;x$&#123;_resolution&#125;/apps/ convert -resize &quot;$&#123;_resolution&#125;x$&#123;_resolution&#125;&quot; &quot;logo-nightdoge-lg-high-res.14f40a7985fe.png&quot; &quot;firefox$&#123;_resolution&#125;.png&quot; mv &quot;firefox$&#123;_resolution&#125;.png&quot; ~/.local/share/icons/hicolor/$&#123;_resolution&#125;x$&#123;_resolution&#125;/apps/firefox.pngdonerm logo-nightdoge-lg-high-res.14f40a7985fe.png# If you want to change back your icons, run the command bellow# rm ~/.local/share/icons/hicolor/*/apps/firefox.png","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Fun","slug":"Fun","permalink":"https://zhul.in/tags/Fun/"}]},{"title":"在Archlinux上解包A/B机型的payload.bin","slug":"extract-payload-dot-bin-on-archlinux","date":"2021-02-06T16:00:00.000Z","updated":"2021-10-13T13:48:10.000Z","comments":true,"path":"2021/02/07/extract-payload-dot-bin-on-archlinux/","link":"","permalink":"https://zhul.in/2021/02/07/extract-payload-dot-bin-on-archlinux/","excerpt":"","text":"解包A/B机型的OTA更新包时，会发现zip文件中只有一个payload.bin文件 解包这个文件，我们需要用到这个叫payload_dumper的python脚本，同时需要安装依赖: community/python-google-api-core和python-bsdiff4，我解包的时候发现缺少python3版本的python-bsdiff4，因此已经打包上传至AUR 1234git clone https://github.com/vm03/payload_dumper.gitcd payload_dumpermv path/to/payload.bin payload_dumperpython payload_dumper.py payload.bin 然后就可以在该项目文件夹的output路径下找到解包后的img镜像","categories":[],"tags":[{"name":"Android","slug":"Android","permalink":"https://zhul.in/tags/Android/"},{"name":"Rom编译","slug":"Rom编译","permalink":"https://zhul.in/tags/Rom%E7%BC%96%E8%AF%91/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"}]},{"title":"如何解决adb未授权的问题","slug":"how-to-solve-the-adb-devices-unauthorized-problem","date":"2021-01-24T16:00:00.000Z","updated":"2021-10-13T13:48:10.000Z","comments":true,"path":"2021/01/25/how-to-solve-the-adb-devices-unauthorized-problem/","link":"","permalink":"https://zhul.in/2021/01/25/how-to-solve-the-adb-devices-unauthorized-problem/","excerpt":"","text":"在调试安卓设备的时候，我们经常会遇到adb未授权的问题，本方案适用于未开机时遇到以下两种情况。 当我们编译eng的时候，adb应该会默认授权所有设备，但是有部分Rom并不会。 当我们编译userdebug的时候，adb就不会授权给所有设备了，如果卡开机，使用adb抓取log将会是非常麻烦的事情。 此时我们需要手动导入我们的adbkey 手机重启到Recovery模式 找到你电脑的adbkey公钥，一般叫做adbkey.pub 1adb push $&#123;the/location/to/your/key&#125; /data/misc/adb/adb_keys 比如我就是 1adb push ~/.android/adbkey.pub /data/misc/adb/adb_keys 重启手机，愉快苦逼地去抓log","categories":[],"tags":[{"name":"Android","slug":"Android","permalink":"https://zhul.in/tags/Android/"},{"name":"Rom编译","slug":"Rom编译","permalink":"https://zhul.in/tags/Rom%E7%BC%96%E8%AF%91/"},{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"}]},{"title":"虚拟Python环境","slug":"python-virtualenv","date":"2021-01-19T16:00:00.000Z","updated":"2021-10-13T13:48:10.000Z","comments":true,"path":"2021/01/20/python-virtualenv/","link":"","permalink":"https://zhul.in/2021/01/20/python-virtualenv/","excerpt":"","text":"在python使用中，我们经常会遇到本地默认python版本与程序所需要的python版本不一致的问题，此时我们需要创建一个虚拟的python环境。 安装目标python版本Ubuntu系主程序参考https://www.cnblogs.com/m3721w/articles/10344887.html pip12sudo apt isntall python-pip #python2sudo apt isntall python3-pip #python3 Archlinux1yay -S python【xx】 #如yay -S python38 源码安装主程序:123456wget https://www.python.org/ftp/python/【x.x.x】/Python-【x.x.x】.tgztar xzvf Python-【x.x.x】.tgzcd Python-x.x.x./configuremakesudo make install pip123curl https://bootstrap.pypa.io/get-pip.py -o get-pip.pysudo python【x.x】 get-pip.py -i https://mirrors.bfsu.edu.cn/pypi/web/simplepip config set global.index-url https://mirrors.bfsu.edu.cn/pypi/web/simple #换源 安装virtualenv常规发行版12pip install virtualenv #python2pip3 install virtualenv #python3 Archlinux12sudo pacman -S python2-virtualenv #python2sudo pacman -S python-virtualenv #python3 使用virtualenv创建virtualenv环境常规发行版1virtualenv $(TRAGET_PATH) python=python【x.x】 Archlinux12virtualenv2 $(TRAGET_PATH) python=python2.【x】 #python2virtualenv $(TRAGET_PATH) python=python3.【x】 #python3 启用virtualenv环境1source $(TARGET_PATH)/bin/activate 退出virtualenv环境1deactivate 删除virtualenv环境1rm -rf $(TRAGET_PATH)","categories":[],"tags":[{"name":"Rom编译","slug":"Rom编译","permalink":"https://zhul.in/tags/Rom%E7%BC%96%E8%AF%91/"},{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"}]},{"title":"为什么我不推荐Manjaro","slug":"Why-I-dont-recommend-Manjaro","date":"2020-12-31T16:00:00.000Z","updated":"2024-08-12T07:22:18.000Z","comments":true,"path":"2021/01/01/Why-I-dont-recommend-Manjaro/","link":"","permalink":"https://zhul.in/2021/01/01/Why-I-dont-recommend-Manjaro/","excerpt":"","text":"说起Linux发行版，很多人都会去推荐Manjaro给新手使用，原因很简单——安装简单、有庞大的AUR和ArchlinuxCN提供软件、有丰富的ArchWiki以供新手查阅。那么，为什么大多数Archlinux用户（包括我）始终不推荐Manjaro作为自己使用的发行版呢。 首先来了解一下两款Linux发行版Archlinux Archlinux是一款滚动发行版，所有的软件全部都基于上游最新的源代码进行编译，源内也仅仅保留最新版本，是最为激进的发行版之一，甚至或许没有之一。 Manjaro Manjaro是一款基于Archlinux的滚动发行版，部分软件同样基于上游源代码编译，同时也有部分软件包直接从Archlinux源内直接拿二进制包。与Archlinux不同的是，Manjaro大部分软件更新相比Archlinux会滞后一个星期，一些比较重要的软件甚至会滞后两个星期以上（比如Python3.9就滞后了19天）以保证稳定性。（虽然我目前观察下来这个稳定性就是出现Bug和修复Bug都比Archlinux慢一个礼拜） 接下来就是正文Archlinux 和 Manjaro 都不适合Linux小白Archlinux和Manjaro都是激进的滚动发行版，作为一个滚动发行版都会有滚坏的风险，这就要求用户有一定的Linux使用基础，能够多关注更新动态，在系统罢工后有修复系统的能力，因此我不会给小白推荐Archlinux/Manjaro这样的发行版（虽说能够用纯cli界面安装Archlinux的用户其实已经有一定的水平了）。 ArchWiki 不是 ManjaroWikiManjaro官方为了最大限度地降低用户的使用门槛，为用户打造了一套开箱即用的环境，这听起来很好。 但是Manjaro官方为了降低用户使用门槛，不得不替用户去做一些选择，写上一些默认配置，在必要的地方对系统进行魔改。因此，ArchWiki上面的解决方案并非在Manjaro上能够100%适用，因此不要指望在系统使用过程中ArchWiki能够解决你所有的问题，有相当一部分问题你需要去查阅纯英文版的ManjaroWiki。 AUR(Archlinux User Repository)&amp;ArchlinuxCN 并不是为 Manjaro 准备的AUR和ArchlinuxCN源都是Archlinux用户为Archlinux打包的常用软件，因此所有的软件都是选择Archlinux最新的软件作为依赖来编译/打包的。上文中我们提到过，Manjaro源内的软件会滞后更新。因此AUR和ArchlinuxCN内一些对于依赖版本要求比较苛刻的软件会在Manjaro这个更新比较落后的发行版上不工作。 我知道这听起来会有些荒唐，不过我可以举出一个就发生在不久之前的生动的例子。 Archlinux在2020年10月17日将grpc从1.30更新到了1.32，qv2ray开发者反应迅速，在几个小时内直接更新了基于grpc-1.32的qv2ray，接着是仍然在使用grpc-1.30的Manjaro用户的一片哀嚎。。。 解决方法有很多，比如临时使用Archlinux源把grpc更新到1.32、通过AppImage安装qv2ray等等，但是如你所见，Manjaro用户使用AUR&amp;ArchlinuxCN确实容易出现问题。 附：AUR上需要下载源码的自己编译的包不会碰到依赖的版本问题，但是仍然有部分情况下PKGBUILD会直接因为依赖版本号被写死而编译出错。而ArchlinuxCN清一色是编译好的二进制包，所以Manjaro用户使用ArchlinuxCN相比AUR出问题的几率更加大一点。 此外，他们延迟两周，并不是在测试 Arch 包打包本身的质量，而是在测试他们拿来 Arch 的包和他们自己乱改的核心包之间的兼容性。以下内容来自于一位 Archlinux Trusted User manjaro 這個分三個 channel 延遲兩週的做法，原因出於兩點他們處理打包方面非常存疑的做法 他們想要自己打包一部分非常核心的包，包括 glibc 內核 驅動 systemd 他們不想重新打整個發行版所有包，想直接從 Arch 拿二進制來用。 這兩個做法單獨只做一個沒啥事，放一起做就很容易導致他們自己打包的核心包破壞了二進制兼容，以至於他們從 Arch 拿的二進制包壞掉。所以他們延遲兩週，並不是在測試 Arch 包打包本身的質量，而是在測試他們拿來 Arch 的包和他們自己亂改的核心包之間的兼容性。Arch 本身有一套機制保證 Arch 打包放出來的時候是測試好相互兼容的，被他們替換掉幾個核心包之後就不一定兼容了，他們也沒有渠道涉足 Arch 內部打包機制，從 Arch 組織內部了解什麼時候放出包之類的信息。綜合這些情況，對他們來說合理的做法就是延遲一陣子讓他們自己的人測試一下。 所以作為證據你看他們的打包者開發者很少會向 Arch 上游反饋測試打包遇到的問題…因為 manjaro unstable 和 manjaro testing 會遇到的問題大部分都是他們自己造成的問題而不是 Arch 的問題。 要是他們誠實地把這個情況傳達給他們用戶的話我不責怪他們。Arch整個滾動發布的生態也不利於下游發行版。Debian 這種上游打包時可以約定版本兼容性的範圍，可以鎖 abi ，Arch 打包本身就不考慮這些，作為Arch下游就的確很難操作。我反感 manjaro 的點在於他們把這種難看的做法宣傳成他們的優勢，還為了這個看起來是優勢故意去抹黑 Arch 作為上游的打包質量…做法就很難看了。 —— farseerfc Manjaro 没有 Archive 源Archlinux拥有一个archive源，通过Archive源，你可以将你的系统滚到任何一天的状态，比如在你不知道更新了什么滚炸了以后，你可以用Archive源回滚到三天前的状态，等bug修复完以后再用回正常的Archlinux源。况且，这个Archive源在国内拥有tuna和bfsu两个镜像源（虽然这两个镜像源并不是完整的镜像，而是每隔7天镜像一次），不会存在访问速度过慢的状况。有名的downgrade软件也是基于Archive源使用的。而Manjaro？很遗憾，没有。 写在最后如果你有一定的Linux基础，阅读了我上面的科普以后仍然要去使用Manjaro也没有关系，但是记得遵守以下几点以确保你在Arch社区不会被打死。 谨慎使用AUR和ArchlinuxCN 使用AUR和ArchlinuxCN时遇到问题请不要反馈 在Arch社区提问时请提前说明自己在使用Manjaro 不要根据Manjaro的使用经验随意编辑ArchWiki","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"}]},{"title":"UOS到底有没有Secure Boot签名/UOS引导怎么修复","slug":"Did-UOS-have-Secure-Boot-Signature","date":"2020-12-21T16:00:00.000Z","updated":"2022-08-22T15:29:12.000Z","comments":true,"path":"2020/12/22/Did-UOS-have-Secure-Boot-Signature/","link":"","permalink":"https://zhul.in/2020/12/22/Did-UOS-have-Secure-Boot-Signature/","excerpt":"","text":"以下内容来自2020年12月22日晚上的大佬对话，非本人原创。 吃瓜群众: 话说UOS到底有没有Secure boot签名啊 某dalao: 用的是ubuntu的 吃瓜群众: 哪来的签名？ 某dalao: 这就不得不讲到另一个槽点了s 吃瓜群众: ubuntu给他们签？ 某dalao: 不不不，用的是ubuntu签好名的那个binary 然后ubuntu的那个binary会在EFI分区的ubuntu目录找配置 于是他们在安装器里写了个逻辑 把deepin目录的内容复制一份到ubuntu目录 （而不是patch grub包，或者写在grub包的postinst之类的地方） 后果是用户只要搞坏了引导 用网上任何教程都恢复不了 因为没人会教你建一个ubuntu目录，然后把deepin目录的内容复制进去） 如果不做这一步，任你怎么grub-install啊，update-grub啊，引导就还是坏的","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"大佬对话笔记","slug":"大佬对话笔记","permalink":"https://zhul.in/tags/%E5%A4%A7%E4%BD%AC%E5%AF%B9%E8%AF%9D%E7%AC%94%E8%AE%B0/"},{"name":"deepin","slug":"deepin","permalink":"https://zhul.in/tags/deepin/"}]},{"title":"No Hello","slug":"NoHello","date":"2020-10-07T16:00:00.000Z","updated":"2022-08-22T15:42:13.000Z","comments":true,"path":"2020/10/08/NoHello/","link":"","permalink":"https://zhul.in/2020/10/08/NoHello/","excerpt":"","text":"Don’t Just Say “Hello” in Chat. 别在向别人问问题的时候问“在吗？” 英文原版请查阅这里，此处是我个人的翻译版。 123452010-07-19 12:32:12 你: 在吗？2010-07-19 12:32:15 我: 在的。## 我就这这里静静的等待你打字描述自己的问题2010-07-19 12:34:01 你: 我正在进行 [莫些事情] 然后我正尝试 [等等。。。]2010-07-19 12:35:21 我: 这样啊，你应该 [我的回答] 这就像是你在和某人打电话，你接起电话说了一声：”喂？“，然后放下手机打开免提等待着对方的提问，这很低效 请使用如下格式： 122010-07-19 12:32:12 你: 你好，我正在进行 [某些事情] 然后我正尝试 [等等。。。]2010-07-19 12:33:32 我: [我的回答] 这样做的原因是：你可以更快速地获得你想要的答案，而不是让对方在那边傻傻地等待你以龟速打字。 你的潜意识里试图不打断对方的回应，得到对方的回复以后再回答以显示你的礼貌，正如你在给别人打电话时那样。但是，网络聊天并不是打电话，通常情况下，打字要比说话慢得多。你的行为不是在彰显自己的礼貌，而是在浪费对方的时间。 其他的用语比如“你好，你在吗？”，“老王，问你个很简单的问题。”，“你有空吗？”都是很愚蠢的行为，在网络聊天中直接问问题就好。 如果你觉得直接问问题不礼貌，你可以采用以下的格式： 12010-07-19 12:32:12 你: 你好，如果你不介意的话我想问个问题，我正在进行 [莫些事情] 然后我正尝试 [等等。。。] 这样提问的另一个好处是：你的提问题同时具有即时性和留言性。如果对方不在，而你在对方上线之前就离开了，他们仍然可以回答您的问题，而不仅仅是盯着你发的“在吗”并为你究竟想要问什么问题而好奇。 （如果你使用的聊天软件支持查看对方的在线状态或者对方是否看到消息，你要做好被对方忽视的准备）","categories":[],"tags":[{"name":"翻译","slug":"翻译","permalink":"https://zhul.in/tags/%E7%BF%BB%E8%AF%91/"}]},{"title":"安卓解包笔记","slug":"AndroidUnpack","date":"2020-08-09T16:00:00.000Z","updated":"2021-10-13T13:48:10.000Z","comments":true,"path":"2020/08/10/AndroidUnpack/","link":"","permalink":"https://zhul.in/2020/08/10/AndroidUnpack/","excerpt":"","text":"123brotli -d system.new.dat.brsdat2img system.transfer.list system.new.datmount system.img &#123;known_path&#125; Get brotli here &amp; sdat2img here","categories":[],"tags":[{"name":"Android","slug":"Android","permalink":"https://zhul.in/tags/Android/"},{"name":"Rom编译","slug":"Rom编译","permalink":"https://zhul.in/tags/Rom%E7%BC%96%E8%AF%91/"},{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"}]},{"title":"git笔记","slug":"GitNotes","date":"2020-07-10T16:00:00.000Z","updated":"2022-08-22T15:42:13.000Z","comments":true,"path":"2020/07/11/GitNotes/","link":"","permalink":"https://zhul.in/2020/07/11/GitNotes/","excerpt":"","text":"git自动填入账号密码打开终端，输入 1git config --global credential.helper store 此时，我们就已经开启了git账号密码的本地储存，在下一次push时只要输入账号密码就可以一劳永逸了。 git设置默认的commit编辑器1git config --global core.editor $editor_name Ps: $editor_name指的是你选用的编辑器，一般为nano、vim等 pick一个仓库中连续的几个commit1git cherry-pick &lt;commit1_id&gt;..^&lt;cimmitn_id&gt; Ps: 和分别指第一个你想要pick的commit_id和最后一个你想要pick的commit_id pick失败时如何撤销此次pick1git cherry-pick --abort 踩坑记录发生背景： clone了一个内核仓库，大概是1.4G左右的大小，在github新建了一个repository，打算push上去，报错如下 1234567891011[zhullyb@Archlinux sdm845]$ git push -u origin masterEnumerating objects: 5724101, done.Counting objects: 100% (5724101/5724101), done.Delta compression using up to 4 threadsCompressing objects: 100% (983226/983226), done.Writing objects: 100% (5724101/5724101), 1.34 GiB | 2.46 MiB/s, done.Total 5724101 (delta 4693465), reused 5723950 (delta 4693375), pack-reused 0error: RPC failed; curl 92 HTTP/2 stream 0 was not closed cleanly: INTERNAL_ERROR (err 2)send-pack: unexpected disconnect while reading sideband packetfatal: the remote end hung up unexpectedlyEverything up-to-date 搜索互联网，最终使用的解决方案 1git config http.version HTTP/1.1 #原文中加了--global，不过我就临时遇到这种情况，不考虑加 最终应该可以使用如下命令设置回来 1git config http.version HTTP/2","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"repo笔记","slug":"RepoNotes","date":"2020-07-10T16:00:00.000Z","updated":"2022-08-22T15:42:13.000Z","comments":true,"path":"2020/07/11/RepoNotes/","link":"","permalink":"https://zhul.in/2020/07/11/RepoNotes/","excerpt":"","text":"清除同步过程中产生的不完整碎片文件在源码路径/.repo下搜索tmp_pack将搜索结果中出现的所有文件全部删除 以下命令仅供参考 1rm -rf */*/*/*/objects/pack/tmp_pack_* repo自动同步下载脚本123456789echo #!/bin/bashecho &quot;======start repo sync======&quot;repo sync --force-sync --current-branch --no-tags --no-clone-bundle --optimized-fetch --prune -j$(nproc --all)while [ $? == 1 ]; doecho &quot;======sync failed, re-sync again======&quot;sleep 3repo sync --force-sync --current-branch --no-tags --no-clone-bundle --optimized-fetch --prune -j$(nproc --all)done&gt; repo.sh 授予运行权限 1chmod a+x repo.sh 运行脚本1bash repo.sh","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"国内Linux镜像源列表","slug":"china-mainland-mirrorlist","date":"2020-07-10T16:00:00.000Z","updated":"2022-12-18T10:31:17.000Z","comments":true,"path":"2020/07/11/china-mainland-mirrorlist/","link":"","permalink":"https://zhul.in/2020/07/11/china-mainland-mirrorlist/","excerpt":"","text":"企业镜像阿里https://developer.aliyun.com/mirror/ 腾讯https://mirrors.cloud.tencent.com/ 网易http://mirrors.163.com/ 华为https://mirrors.huaweicloud.com/ 首都在线http://mirrors.yun-idc.com/ 搜狐http://mirrors.sohu.com/ 平安云https://mirrors.pinganyun.com/ 高校镜像清华大学https://mirrors.tuna.tsinghua.edu.cn/ https://opentuna.cn/ farseerfc: tuna 有兩個服務器互相負載均衡，這倆服務器之間不同步，就偶爾遇到版本回退。 中国科技大学http://mirrors.ustc.edu.cn/ 浙江大学https://mirrors.zju.edu.cn/ 北京外国语大学https://mirrors.bfsu.edu.cn/ 北京大学https://mirrors.pku.edu.cn/Mirrors 北京交通大学https://mirror.bjtu.edu.cn/ 北京理工大学https://mirrors.bit.edu.cn/web/ 上海交通大学https://mirrors.sjtug.sjtu.edu.cn/ 大连东软信息学院http://mirrors.neusoft.edu.cn/ 兰州大学http://mirror.lzu.edu.cn/ 南京大学http://mirrors.nju.edu.cn/ 哈尔滨工业大学https://mirrors.hit.edu.cn/ 南京邮电大学https://mirrors.njupt.edu.cn/ 山东大学https://mirrors.sdu.edu.cn/ 东北大学http://mirror.neu.edu.cn/ 大连理工大学http://mirror.dlut.edu.cn/ 南洋理工学院https://mirror.nyist.edu.cn/ 南方科技大学https://mirrors.sustech.edu.cn 重庆大学http://mirrors.cqu.edu.cn/ 西北农林科技大学https://mirrors.nwsuaf.edu.cn/ 山东女子学院https://mirrors.sdwu.edu.cn/","categories":[],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"镜像站","slug":"镜像站","permalink":"https://zhul.in/tags/%E9%95%9C%E5%83%8F%E7%AB%99/"}]},{"title":"在Windows下给cmd设置代理","slug":"set-proxy-for-cmd-under-windows","date":"2020-03-02T16:00:00.000Z","updated":"2022-09-29T06:57:32.000Z","comments":true,"path":"2020/03/03/set-proxy-for-cmd-under-windows/","link":"","permalink":"https://zhul.in/2020/03/03/set-proxy-for-cmd-under-windows/","excerpt":"","text":"cmd打开方法按住win+R键，调出一个运行框，接着输入cmd并回车即可 设置cmd代理一般性使用的如果是ShadowsockR的话，代理端口都是1080，v2ray的话则是10808 ShadowsocksR12set http_proxy=http://127.0.0.1:1080set https_proxy=http://127.0.0.1:1080 v2ray12set http_proxy=http://127.0.0.1:10808set https_proxy=http://127.0.0.1:10808 为git设置代理ShadowsocksR12git config --global http.proxy http://127.0.0.1:1080git config --global https.proxy http://127.0.0.1:1080 v2ray12git config --global http.proxy http://127.0.0.1:10808git config --global https.proxy http://127.0.0.1:10808","categories":[],"tags":[{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"Windows","slug":"Windows","permalink":"https://zhul.in/tags/Windows/"}]}],"categories":[],"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://zhul.in/tags/JavaScript/"},{"name":"Hexo","slug":"Hexo","permalink":"https://zhul.in/tags/Hexo/"},{"name":"Python","slug":"Python","permalink":"https://zhul.in/tags/Python/"},{"name":"Hardware","slug":"Hardware","permalink":"https://zhul.in/tags/Hardware/"},{"name":"IoT","slug":"IoT","permalink":"https://zhul.in/tags/IoT/"},{"name":"Linux","slug":"Linux","permalink":"https://zhul.in/tags/Linux/"},{"name":"Network","slug":"Network","permalink":"https://zhul.in/tags/Network/"},{"name":"mitmproxy","slug":"mitmproxy","permalink":"https://zhul.in/tags/mitmproxy/"},{"name":"Caddy","slug":"Caddy","permalink":"https://zhul.in/tags/Caddy/"},{"name":"Docker","slug":"Docker","permalink":"https://zhul.in/tags/Docker/"},{"name":"Archlinux","slug":"Archlinux","permalink":"https://zhul.in/tags/Archlinux/"},{"name":"Rustdesk","slug":"Rustdesk","permalink":"https://zhul.in/tags/Rustdesk/"},{"name":"Debian","slug":"Debian","permalink":"https://zhul.in/tags/Debian/"},{"name":"CDN","slug":"CDN","permalink":"https://zhul.in/tags/CDN/"},{"name":"图床","slug":"图床","permalink":"https://zhul.in/tags/%E5%9B%BE%E5%BA%8A/"},{"name":"Shell Script","slug":"Shell-Script","permalink":"https://zhul.in/tags/Shell-Script/"},{"name":"Bot","slug":"Bot","permalink":"https://zhul.in/tags/Bot/"},{"name":"Github Action","slug":"Github-Action","permalink":"https://zhul.in/tags/Github-Action/"},{"name":"SSL certificates","slug":"SSL-certificates","permalink":"https://zhul.in/tags/SSL-certificates/"},{"name":"Cloudflare","slug":"Cloudflare","permalink":"https://zhul.in/tags/Cloudflare/"},{"name":"Android","slug":"Android","permalink":"https://zhul.in/tags/Android/"},{"name":"笔记","slug":"笔记","permalink":"https://zhul.in/tags/%E7%AC%94%E8%AE%B0/"},{"name":"HomeServer","slug":"HomeServer","permalink":"https://zhul.in/tags/HomeServer/"},{"name":"Blog","slug":"Blog","permalink":"https://zhul.in/tags/Blog/"},{"name":"Fedora","slug":"Fedora","permalink":"https://zhul.in/tags/Fedora/"},{"name":"Experience","slug":"Experience","permalink":"https://zhul.in/tags/Experience/"},{"name":"Printer","slug":"Printer","permalink":"https://zhul.in/tags/Printer/"},{"name":"Router","slug":"Router","permalink":"https://zhul.in/tags/Router/"},{"name":"OpenSource Project","slug":"OpenSource-Project","permalink":"https://zhul.in/tags/OpenSource-Project/"},{"name":"Windows","slug":"Windows","permalink":"https://zhul.in/tags/Windows/"},{"name":"Virtual Machine","slug":"Virtual-Machine","permalink":"https://zhul.in/tags/Virtual-Machine/"},{"name":"RPM Package","slug":"RPM-Package","permalink":"https://zhul.in/tags/RPM-Package/"},{"name":"Vue.js","slug":"Vue-js","permalink":"https://zhul.in/tags/Vue-js/"},{"name":"uniapp","slug":"uniapp","permalink":"https://zhul.in/tags/uniapp/"},{"name":"deepin","slug":"deepin","permalink":"https://zhul.in/tags/deepin/"},{"name":"Apt","slug":"Apt","permalink":"https://zhul.in/tags/Apt/"},{"name":"PHP","slug":"PHP","permalink":"https://zhul.in/tags/PHP/"},{"name":"OneDrive","slug":"OneDrive","permalink":"https://zhul.in/tags/OneDrive/"},{"name":"crontab","slug":"crontab","permalink":"https://zhul.in/tags/crontab/"},{"name":"umami","slug":"umami","permalink":"https://zhul.in/tags/umami/"},{"name":"翻译","slug":"翻译","permalink":"https://zhul.in/tags/%E7%BF%BB%E8%AF%91/"},{"name":"Fun","slug":"Fun","permalink":"https://zhul.in/tags/Fun/"},{"name":"MiAI","slug":"MiAI","permalink":"https://zhul.in/tags/MiAI/"},{"name":"Privacy","slug":"Privacy","permalink":"https://zhul.in/tags/Privacy/"},{"name":"jinja2","slug":"jinja2","permalink":"https://zhul.in/tags/jinja2/"},{"name":"CSS","slug":"CSS","permalink":"https://zhul.in/tags/CSS/"},{"name":"selenium","slug":"selenium","permalink":"https://zhul.in/tags/selenium/"},{"name":"Azure","slug":"Azure","permalink":"https://zhul.in/tags/Azure/"},{"name":"nodejs","slug":"nodejs","permalink":"https://zhul.in/tags/nodejs/"},{"name":"siteproxy","slug":"siteproxy","permalink":"https://zhul.in/tags/siteproxy/"},{"name":"Z-Library","slug":"Z-Library","permalink":"https://zhul.in/tags/Z-Library/"},{"name":"vercel","slug":"vercel","permalink":"https://zhul.in/tags/vercel/"},{"name":"openssl","slug":"openssl","permalink":"https://zhul.in/tags/openssl/"},{"name":"KDE","slug":"KDE","permalink":"https://zhul.in/tags/KDE/"},{"name":"Lsky Pro","slug":"Lsky-Pro","permalink":"https://zhul.in/tags/Lsky-Pro/"},{"name":"electron","slug":"electron","permalink":"https://zhul.in/tags/electron/"},{"name":"Casual Talk","slug":"Casual-Talk","permalink":"https://zhul.in/tags/Casual-Talk/"},{"name":"Waydroid","slug":"Waydroid","permalink":"https://zhul.in/tags/Waydroid/"},{"name":"PicUploader","slug":"PicUploader","permalink":"https://zhul.in/tags/PicUploader/"},{"name":"Firefox","slug":"Firefox","permalink":"https://zhul.in/tags/Firefox/"},{"name":"Bwrap","slug":"Bwrap","permalink":"https://zhul.in/tags/Bwrap/"},{"name":"镜像站","slug":"镜像站","permalink":"https://zhul.in/tags/%E9%95%9C%E5%83%8F%E7%AB%99/"},{"name":"大佬对话笔记","slug":"大佬对话笔记","permalink":"https://zhul.in/tags/%E5%A4%A7%E4%BD%AC%E5%AF%B9%E8%AF%9D%E7%AC%94%E8%AE%B0/"},{"name":"Rom编译","slug":"Rom编译","permalink":"https://zhul.in/tags/Rom%E7%BC%96%E8%AF%91/"}]}